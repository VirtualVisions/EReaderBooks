{"metadata":{"title":"Test Title","author":"John Bookman","description":"John Bookman awsesxome book hell yeah!!!!!","tags":["Book","Awesome","Radical"]},"sections":[{"title":"Test Section Title","content":""},{"title":"Test Section Title","content":"A HACKER’S MIND\n\n\n\nHOW THE POWERFUL BEND SOCIETY’S RULES, AND HOW TO BEND THEM BACK\n\nBruce Schneier\n\n"},{"title":"Test Section Title","content":"To Tammy"},{"title":"Test Section Title","content":"Contents\n\nIntroduction\n\nPART 1: HACKING 101\n\n1.What Is Hacking?\n\n2.Hacking Systems\n\n3.What Is a System?\n\n4.The Hacking Life Cycle\n\n5.The Ubiquity of Hacking\n\nPART 2: BASIC HACKS AND DEFENSES\n\n6.ATM Hacks\n\n7.Casino Hacks\n\n8.Airline Frequent-Flier Hacks\n\n9.Sports Hacks\n\n10.Hacks Are Parasitical\n\n11.Defending against Hacks\n\n12.More Subtle Hacking Defenses\n\n13.Removing Potential Hacks in the Design Phase\n\n14.The Economics of Defense\n\n15.Resilience\n\nPART 3: HACKING FINANCIAL SYSTEMS\n\n16.Hacking Heaven\n\n17.Hacking Banking\n\n18.Hacking Financial Exchanges\n\n19.Hacking Computerized Financial Exchanges\n\n20.Luxury Real Estate\n\n21.Societal Hacks Are Often Normalized\n\n22.Hacking the Market\n\n23.“Too Big to Fail”\n\n24.Venture Capital and Private Equity\n\n25.Hacking and Wealth\n\nPART 4: HACKING LEGAL SYSTEMS\n\n26.Hacking Laws\n\n27.Legal Loopholes\n\n28.Hacking Bureaucracy\n\n29.Hacking and Power\n\n30.Undermining Regulations\n\n31.Jurisdictional Interactions\n\n32.Administrative Burdens\n\n33.Hacking Common Law\n\n34.Hacking as Evolution\n\nPART 5: HACKING POLITICAL SYSTEMS\n\n35.Hidden Provisions in Legislation\n\n36.Must-Pass Legislation\n\n37.Delegating and Delaying Legislation\n\n38.The Context of a Hack\n\n39.Hacking Voting Eligibility\n\n40.Other Election Hacks\n\n41.Money in Politics\n\n42.Hacking to Destruction\n\nPART 6: HACKING COGNITIVE SYSTEMS\n\n43.Cognitive Hacks\n\n44.Attention and Addiction\n\n45.Persuasion\n\n46.Trust and Authority\n\n47.Fear and Risk\n\n48.Defending against Cognitive Hacks\n\n49.A Hierarchy of Hacking\n\nPART 7: HACKING AI SYSTEMS\n\n50.Artificial Intelligence and Robotics\n\n51.Hacking AI\n\n52.The Explainability Problem\n\n53.Humanizing AI\n\n54.AI and Robots Hacking Us\n\n55.Computers and AI Are Accelerating Societal Hacking\n\n56.When AIs Become Hackers\n\n57.Reward Hacking\n\n58.Defending against AI Hackers\n\n59.A Future of AI Hackers\n\n60.Governance Systems for Hacking\n\nConcluding Thoughts\n\nAcknowledgments\n\nNotes\n\nIndex"},{"title":"Test Section Title","content":"A HACKER’S MIND"},{"title":"Test Section Title","content":"Introduction\n\nThey say that water, it never runs uphill.\n\nIt never has, and it never will.\n\nBut if you get enough money involved,\n\nThere’s bound to be a loophole in the natural law.\n\nAnd water, is gonna flow uphill.\n\n—“Water Never Runs Uphill,” Jim Fitting, Session Americana\n\nA company called Uncle Milton Industries has been selling ant farms to children\nsince 1956. The farms consist of two vertical sheets of clear plastic about a\nquarter inch apart, sealed at the sides, and with a top you can open up. The\nidea is that you fill the space with sand and put ants into the two-dimensional\nenvironment. Then, you can watch them dig tunnels.\n\nThe box doesn’t come with any ants. It would be hard to keep them alive while it\nsat on the store shelf, and there’s probably some child safety regulation about\ninsects and toys. Instead, the box comes with a card where you can write your\naddress, send it to the company, and receive back a tube of ants in the mail.\n\nWhen most people look at this card, they often marvel that the company would\nsend a customer a tube of ants. When I first looked at the card, I thought:\n“Wow, I can have this company send a tube of ants to anyone I want.”\n\nSecurity technologists look at the world differently than most people. When most\npeople look at a system, they focus on how it works. When security technologists\nlook at the same system, they can’t help but focus on how it can be made to\nfail: how that failure can be used to force the system to behave in a way it\nshouldn’t, in order to do something it shouldn’t be able to do—and then how to\nuse that behavior to gain an advantage of some kind.\n\nThat’s what a hack is: an activity allowed by the system that subverts the goal\nor intent of the system. Just like using Uncle Milton’s system to send tubes of\nants to people who don’t want them.\n\nI teach cybersecurity policy at the Harvard Kennedy School. At the end of the\nfirst class, I announce a surprise quiz for the next time we meet. I tell the\nstudents that they will be expected to write down the first hundred digits of pi\nfrom memory. “I understand that it is not realistic to expect you to memorize a\nhundred random digits in two days,” I tell them. “So I expect you to cheat.\nDon’t get caught.”\n\nTwo days later the room is buzzing with excitement. Most of the students don’t\nhave any new ideas. They’ve written the digits on a tiny scrap of paper, which\nthey hide somewhere. Or they record themselves reading the digits, and try to\nconceal their earbuds. But some are incredibly creative. One student used an\ninvisible ink and wore glasses that made the digits visible. One student wrote\nthem out in Chinese, which I don’t read. Another encoded the digits in\ndifferent-colored beads and strung them on a necklace. A fourth memorized the\nfirst few and the last few and wrote random digits in the middle, assuming that\nmy grading would be sloppy. My favorite hack was from a few years ago. Near as I\ncould tell, Jan was just writing the digits down in order—albeit very slowly. He\nwas the last one to finish. I remember staring at him, having no idea what he\nmight be doing. I remember the other students staring at him. “Is he actually\ncalculating the infinite series in his head?” I wondered. No. He programmed the\nphone in his pocket to vibrate each digit in Morse code.\n\nThe point of this exercise isn’t to turn my class into cheaters. I always remind\nthem that actually cheating at Harvard is grounds for expulsion. The point is\nthat if they are going to make public policy around cybersecurity, they have to\nthink like people who cheat. They need to cultivate a hacking mentality.\n\nThis book tells the story of hacking—one that’s very different from what’s\ndepicted in movies and TV shows, and in the press. It’s not the story you’ll\nfind in books teaching you how to hack computers or how to defend yourself\nagainst computer hackers. It tells the story of something much more endemic,\nsomething fundamentally human, and something far older than the invention of\ncomputers. It’s a story that involves money and power.\n\nKids are natural hackers. They do it instinctively, because they don’t fully\nunderstand the rules and their intent. (So are artificial intelligence\nsystems—we’ll get to that at the end of the book.) But so are the wealthy.\nUnlike children or artificial intelligences, they understand the rules and their\ncontext. But, like children, many wealthy individuals don’t accept that the\nrules apply to them. Or, at least, they believe that their own self-interest\ntakes precedence. The result is that they hack systems all the time.\n\nIn my story, hacking isn’t just something bored teenagers or rival governments\ndo to computer systems or that less ethical students do when they don’t want to\nstudy. It isn’t countercultural misbehavior by the less powerful. A hacker is\nmore likely to be working for a hedge fund, finding a loophole in financial\nregulations that lets her siphon extra profits out of the system. He’s more\nlikely in a corporate office. Or an elected official. Hacking is integral to the\njob of every government lobbyist. It’s how social media systems keep us on their\nplatforms.\n\nIn my story, hacking is something that the rich and powerful do, something that\nreinforces existing power structures.\n\nOne example is Peter Thiel. The Roth IRA is a retirement account allowed by a\n1997 law. It’s intended for middle-class investors, and has limits on both the\ninvestor’s income level and the amount that can be invested. But billionaire\nPeter Thiel found a hack. Because he was one of the founders of PayPal, he was\nable to use a $2,000 investment to buy 1.7 million shares of the company at\n$0.001 per share, turning it into $5 billion—all forever tax free.\n\nHacking is the key to why we often feel that government is unable to protect us\nagainst powerful corporate interests, or wealthy personal interests. It’s one of\nthe reasons we feel powerless against state authority. Hacking is how the rich\nand powerful subvert the rules to increase both their wealth and power. They\nwork to find novel hacks, and also to make sure their hacks remain so they can\ncontinue to profit from them. That’s the important point. It’s not that the\nwealthy and powerful are better at hacking, it’s that they’re less likely to be\npunished for doing so. Indeed, their hacks often become just a normal part of\nhow society works. Fixing this is going to require institutional change. Which\nis hard, because institutional leaders are the very people stacking the deck\nagainst us.\n\nAll systems can be hacked. Many systems are currently being hacked—and it’s\ngetting worse. If we don’t learn how to control this process, our economic,\npolitical, and social systems will begin to fail. They’ll fail because they’ll\nno longer effectively serve their purpose, and they’ll fail because people will\nstart losing their faith and trust in them. This is already happening. How do\nyou feel knowing that Peter Thiel got away with not paying $1 billion in capital\ngains taxes?\n\nBut, as I will demonstrate, hacking is not always destructive. Harnessed\nproperly, it’s one of the ways systems can evolve and improve. It’s how society\nadvances. Or, more specifically, it’s how people advance society without having\nto completely destroy what came before. Hacking can be a force for good. The\ntrick is figuring out how to encourage the good hacks while stopping the bad\nones, and knowing the difference between the two.\n\nHacking will become even more disruptive as we increasingly implement artificial\nintelligence (AI) and autonomous systems. These are computer systems, which\nmeans they will inevitably be hacked in the same ways that all computer systems\nare. They affect social systems—already AI systems make loan, hiring, and parole\ndecisions—which means those hacks will consequently affect our economic and\npolitical systems. More significantly, machine-learning processes that underpin\nall of modern AI will result in the computers performing the hacks.\n\nExtrapolating further, AI systems will soon start discovering new hacks. This\nwill change everything. Up until now, hacking has been a uniquely human\nendeavor. Hackers are human, and hacks have shared human limitations. Those\nlimitations are about to be removed. AI will start hacking not just our\ncomputers, but our governments, our markets, and even our minds. AI will hack\nsystems with a speed and skill that will put human hackers to shame. Keep the\nconcept of AI hackers in mind as you read; I will culminate the book with that\nin the final part.\n\nThat’s why this book is important right now. If there’s any time when we need to\nunderstand how to recognize and defend against hacks, it’s now. And this is\nwhere security technologists can help.\n\nOnce—I wish I could remember where—I heard this quote about mathematical\nliteracy. “It’s not that math can solve the world’s problems. It’s just that the\nworld’s problems would be easier to solve if everyone just knew a little bit\nmore math.” I think the same holds true for thinking about security. It’s not\nthat the security mindset, or a hacking mentality, will solve the world’s\nproblems. It’s that the world’s problems would be easier to solve if everyone\njust understood a little more about security.\n\nSo let’s go."},{"title":"Test Section Title","content":"PART 1\n\n\n\nHACKING 101"},{"title":"Test Section Title","content":"1\n\nWhat Is Hacking?\n\n“Hack,” “hacking,” “hacker”—these terms are overloaded with meaning and\ninnuendo. My definition is neither precise nor canonical. I’m fine with that. My\ngoal is to demonstrate that thinking in terms of hacking is a useful tool to\nunderstand a broad array of systems, how they fail, and how to make them more\nresilient.\n\nDef: Hack /hak/ (noun) -\n\n1. A clever, unintended exploitation of a system that (a) subverts the rules or\nnorms of the system, (b) at the expense of someone else affected by the system.\n\n2. Something that a system allows but which is unintended and unanticipated by\nits designers.\n\nHacking is not the same as cheating. A hack could also be a cheat, but it’s more\nlikely not. When someone cheats, they’re doing something against the\nrules—something the system explicitly prohibits. Typing someone else’s name and\npassword into a website without their permission, not disclosing all of your\nincome on your tax return, or copying someone else’s answers on a test are all\ncheating. None of those are hacking.\n\nHacks are not the same as improvements, enhancements, or innovations. Practicing\nyour tennis serve and returning as a better player is improving. When Apple adds\na new feature to its iPhone, it’s an enhancement. Figuring out a clever new way\nto use a spreadsheet can be an innovation. Sometimes a hack is also an\ninnovation or an enhancement—like when you jailbreak your iPhone to add features\nthat Apple doesn’t approve of—but it’s not necessarily one.\n\nHacking targets a system and turns it against itself without breaking it. If I\nsmash your car window and hotwire the ignition, that’s not a hack. If I figure\nout how to trick the car’s keyless entry system into unlocking the car door and\nstarting the ignition, that’s a hack.\n\nNotice the difference. The hacker isn’t just outsmarting her victim. She’s found\na flaw in the rules of the system. She’s doing something she shouldn’t be\nallowed to do, but is. She’s outsmarting the system. And, by extension, she’s\noutsmarting the system’s designers.\n\nHacking subverts the intent of a system by subverting its rules or norms. It’s\n“gaming the system.” It occupies a middle ground between cheating and\ninnovation.\n\n“Hack” is a subjective term. There’s a lot of “I know it when I see it” when it\ncomes to hacking. Some things are obviously hacks. Some things are just as\nobviously not hacks. And some things are in the grey area between the two.\nSpeedreading—not a hack. Hiding a microdot in a period on a page of printed\ntext—definitely a hack. Cliff Notes—maybe; I’m not sure.\n\nHacks are clever. A hack results in grudging admiration (possibly in addition to\nrighteous anger), and has some element of “Cool—I wish I’d thought of that,”\neven if it is something you would never do. This is true even if the hack is\ndone by evil, murderous people. In my 2003 book, Beyond Fear, I opened with a\nlong explanation of why the 9/11 terrorist attacks were “amazing.” Those\nterrorists broke the unwritten rules of airplane hijacking. Before them,\nhijackings involved forcing a plane to fly to somewhere, some number of\npolitical demands, negotiations with governments and police, and generally\npeaceful resolutions. What the 9/11 terrorists did was awful and horrific, but I\nalso recognized the ingenuity of their hack. They only used weapons that were\nallowed through airport security, transformed civilian jets into guided\nmissiles, and unilaterally rewrote the norms around airplane terrorism.\n\nHackers and their work force us to think differently about the systems in our\nworld. They expose what we assume or take for granted, often to the\nembarrassment of the powerful and sometimes at terrible cost.\n\nTerrorism aside, people love hacks because they’re clever. MacGyver was a\nhacker. Prison break and caper movies are filled with clever hacks: Rififi, The\nGreat Escape, Papillon, Mission Impossible, The Italian Job, Ocean’s 11, 12, 13,\nand 8.\n\nHacks are novel. “Is that allowed?” and “I didn’t know you could do that!” are\nboth common reactions to hacks. What is and isn’t a hack also changes over time.\nRules and norms change. “Common knowledge” changes. Because hacks tend to be\neventually either forbidden or allowed, things that were once hacks no longer\nare. You once had to jailbreak your smartphone to turn it into a wireless\nhotspot; now hotspots are standard features in both iOS and Android. Hiding a\nmetal file in a cake sent to a jailed confederate was initially a hack, but now\nit’s a movie trope that prisons will be on guard against.\n\nIn 2019, someone used a drone to deliver a cell phone and marijuana into an Ohio\nprison. At the time, I would have called that a hack. Today, flying a drone near\na prison is expressly illegal in some states, and I don’t think it’s a hack\nanymore. I recently read about someone using a fishing rod to cast contraband\nover a prison’s wall. And also about a cat, who was caught carrying drugs and\nphone SIM cards at a Sri Lanka prison (but later escaped). Definitely a hack.\n\nHacks are often legal. Because they follow the letter of the rules but evade the\nspirit, they are only illegal if there is some overarching rule that forbids\nthem. When an accountant finds a loophole in the tax rules, it’s probably legal\nif there is no more general law that prohibits it.\n\nThere’s even a word for this sort of thing in Italian: furbizia, the ingenuity\nthat Italians deploy towards getting around bureaucracy and inconvenient laws.\nHindi has a similar word, jugaad, which emphasizes the cleverness and\nresourcefulness of making do. In Brazilian Portuguese, the equivalent is\ngambiarra.\n\nHacks are sometimes moral. Some assume that just because a certain activity or\nbehavior is legal, it’s automatically moral, but of course the world is more\ncomplicated than that. Just as there are immoral laws, there are moral crimes.\nMost of the hacks we’ll be discussing in this book are technically legal, but\ncontravene the spirit of the laws. (And systems of laws are only one type of\nsystem that can be hacked.)\n\nThe word “hack” traces its origins to the MIT Tech Model Railroad Club in 1955,\nand quickly migrated to the nascent field of computers. Originally it described\na way of problem solving, implying cleverness or innovation or resourcefulness,\nwithout any criminal or even adversarial qualities. But by the 1980s, “hacking”\nmost often described breaking computer security systems. It wasn’t just getting\na computer to do something new, it was forcing it to do something it wasn’t\nsupposed to do.\n\nIn my way of thinking, it’s just one short step from hacking computers to\nhacking economic, political, and social systems. All of those systems are just\nsets of rules, or sometimes norms. They are just as vulnerable to hacking as\ncomputer systems.\n\nThis isn’t new. We’ve been hacking society’s systems throughout history."},{"title":"Test Section Title","content":"2\n\nHacking Systems\n\nHacks can be perpetrated on any system, but comparisons between these different\ntypes of systems can be useful in highlighting more features of how hacks\noperate—for example, the tax code versus computer code.\n\nThe tax code isn’t software. It doesn’t run on a computer. But you can still\nthink of it as “code” in the computer sense of the term. It’s a series of\nalgorithms that takes an input—financial information for the year—and produces\nan output: the amount of tax owed.\n\nThe tax code is incredibly complex. Maybe not for most of us as individuals, but\nthere are a bazillion details and exceptions and special cases for rich people\nand businesses of various kinds. It consists of government laws, administrative\nrulings, judicial decisions, and legal opinions. It also includes the laws and\nregulations governing corporations and various types of partnerships. Credible\nestimates of the size of it all are hard to come by; even experts had no idea\nwhen I asked. The tax laws themselves occupy about 2,600 pages. IRS regulations\nand tax rulings increase that to about 70,000 pages. The laws involving\ncorporate structures and partnerships are equally complicated, so I’m going to\nwave my hands and assume a total of 100,000 pages—or 3 million lines—for the US\ntax code. Microsoft Windows 10 takes up about 50 million lines of code. It’s\nhard to compare lines of text to lines of computer code, but the comparison is\nstill useful. In both examples, much of that complexity is related to how\ndifferent parts of the code interact with each other.\n\nAll computer code contains bugs. These are mistakes: mistakes in specification,\nmistakes in programming, mistakes that occur somewhere in the process of\ncreating the software, mistakes as pedestrian as a typographic error or\nmisspelling. Modern software applications generally have hundreds if not\nthousands of bugs. These bugs are in all the software that you’re currently\nusing: in your computer, on your phone, in whatever “Internet of Things” (IoT)\ndevices you have around your home and work. That all of this software works\nperfectly well most of the time speaks to how obscure and inconsequential these\nbugs tend to be. You’re unlikely to encounter them in normal operations, but\nthey’re there (like so many parts of the tax code that you never encounter).\n\nSome of those bugs introduce security holes. By this I mean something very\nspecific: an attacker can deliberately trigger the bug to achieve some effect\nundesired by the code’s designers and programmers. In computer security\nlanguage, we call these bugs “vulnerabilities.”\n\nThe tax code also has bugs. They might be mistakes in how the tax laws were\nwritten: errors in the actual words that Congress voted on and the president\nsigned into law. They might be mistakes in how the tax code is interpreted. They\nmight be oversights in how parts of the law were conceived, or unintended\nomissions of some sort or another. They might arise from the huge number of ways\ndifferent parts of the tax code interact with each other.\n\nA recent example comes from the 2017 Tax Cuts and Jobs Act. That law was drafted\nin haste and in secret, and passed without any time for review by legislators—or\neven proofreading. Parts of it were handwritten, and it’s pretty much\ninconceivable that anyone who voted either for or against it knew precisely what\nwas in it. The text contained an error that accidentally categorized military\ndeath benefits as earned income. The practical effect of that mistake was that\nsurviving family members were hit with surprise tax bills of $10,000 or more.\nThat’s a bug.\n\nIt’s not a vulnerability, though, because no one can take advantage of it to\nreduce their tax bill. But some bugs in the tax code are also vulnerabilities.\nFor example, there was a corporate tax trick called the “Double Irish with a\nDutch Sandwich.” It’s a vulnerability that arose from the interactions of tax\nlaws in multiple countries, finally patched by the Irish.\n\nHere’s how it worked: The US company transfers assets to an Irish subsidiary.\nThat subsidiary charges the US company huge royalties from sales to US\ncustomers. This dramatically lowers the company’s US taxes, and Irish taxes on\nroyalties are designed to be low. Then, using a loophole in Irish tax law, the\ncompany can shift the profits to entities in tax havens like Bermuda, Belize,\nMauritius, or the Cayman Islands—to ensure that these profits remain untaxed.\nNext, add a second Irish company, this time for sales to European customers,\nalso taxed at a low rate. Finally, use another vulnerability, this one involving\na Dutch intermediary company, to transfer the profits back to the first Irish\ncompany and on to the offshore tax haven. Tech companies are particularly\nwell-suited to exploit this vulnerability; they can assign intellectual property\nrights to subsidiary companies abroad, who then transfer cash assets to tax\nhavens.\n\nThat’s how companies like Google and Apple have avoided paying their fair share\nof US taxes despite being US companies. It’s definitely an unintended and\nunanticipated use of the tax laws in three countries, although Ireland purposely\npursued lax tax rules in order to attract American companies. And it can be very\nprofitable for the hackers. Estimates are that US companies avoided paying\nnearly $200 billion in US taxes in 2017 alone, at the expense of everyone else.\n\nIn the tax world, bugs and vulnerabilities are called loopholes. Attackers take\nadvantage of these; it’s called tax avoidance. And there are thousands of what\nwe in the computer security world would call “black-hat researchers,” who\nexamine every line of the tax code looking for vulnerabilities they can exploit:\ntax attorneys and tax accountants.\n\nWe know how to fix vulnerabilities in computer code. First, we can employ a\nvariety of tools to detect them before the code is finished. Second, and after\nthe code is out in the world, there are various ways we can find them and—most\nimportant of all—quickly patch them.\n\nWe can employ these same methods with the tax code. The 2017 tax law capped\nincome tax deductions for property taxes. This provision didn’t come into force\nuntil 2018, so someone came up with the clever hack to prepay 2018 property\ntaxes in 2017. Just before the end of the year, the IRS ruled about when that\nwas legal and when it wasn’t, patching the tax code against this exploit. Short\nanswer: most of the time, it wasn’t.\n\nIt’s often not this easy. Some hacks are written into the law, or can’t be ruled\naway. Passing any tax legislation is a big deal, especially in the US, where the\nissue is so partisan and contentious. It wasn’t until 2021 that the earned\nincome tax bug for military families started getting fixed. Congress didn’t fix\nthe actual 2017 bug; they fixed an even older bug that interacted with the 2017\nbug. And its fix won’t be complete until 2023. (And that’s an easy one; everyone\nacknowledges it was a mistake.) We don’t have the ability to patch the tax code\nwith anywhere near the same agility that we have to patch software.\n\nThere’s another option: that the vulnerability isn’t patched and slowly becomes\npart of the normal way of doing things. Lots of tax loopholes end up like this.\nSometimes the IRS accepts them. Sometimes the courts affirm their legality. They\nmight not reflect the intent of the tax law, but the words of the law allow\nthem. Sometimes they’re even retroactively legalized by Congress after a\nconstituency gets behind them. This process is how systems evolve.\n\nA hack subverts the intent of a system. Whatever governing system has\njurisdiction either blocks or allows it. Sometimes it explicitly allows it, and\nother times it does nothing and implicitly allows it."},{"title":"Test Section Title","content":"3\n\nWhat Is a System?\n\nA hack follows the letter of a system’s rules, but violates their spirit and\nintent.\n\nIn order for there to be a hack, there must be a system of rules to be hacked.\nSo I need to step back and define more precisely what the word “system” means,\nat least as I’m using it.\n\nDef: System /tǝm/ (noun) -\n\nA complex process, constrained by a set of rules or norms, intended to produce\none or more desired outcomes.\n\nThe word processor I wrote this paragraph on is a system: a collection of\nelectronic signals constrained by a set of software rules specific to producing\nwriting such that these words appear on the screen—my desired outcome. The\ncreation of this book is the product—outcome—of another system, with processes\nthat include designing the pages, printing them, binding them together in order,\nputting on a dust jacket, and boxing them for shipment. Each of those processes\nis completed according to a set of rules. And those two systems, plus several\nothers, result in the paper book you are holding in your hand, the electronic\nfile that you are reading on your e-reader, or the different electronic file\nthat is being played on whatever audiobook system you’re using. This idea is\ntrue whether the elements of the system are housed under one roof or distributed\naround the world. It is even true whether the outcome is real or virtual, free\nor overpriced, poorly produced, or unreliably available. One or more systems are\nalways involved.\n\nSystems have rules. Usually rules of law, but also rules of a game, informal\nrules of a group or process, or unspoken rules of society. Cognitive systems\nfollow laws, too—natural laws.\n\nNote that the hacks are something the system allows. And by “allows,” I mean\nsomething very specific. It’s not that it’s legal, or permitted, socially\nacceptable or even ethical—although it might be any or all of those. It’s that\nthe system, as constructed, does not prevent the hack from occurring within the\nconfines of that system. The system doesn’t allow these hacks deliberately, but\nonly incidentally and accidentally because of the way it was designed. In\ntechnical systems, this generally means that the software permits the hack to\noccur. In social systems, it generally means that the rules—often\nlaws—controlling the system do not expressly prohibit the hack. This is why we\nsometimes use the word “loophole” to describe these hacks.\n\nWhat this means is that hacks are conducted against systems in which\nparticipants have agreed in advance—either explicitly or implicitly—to abide by\na common set of rules. Sometimes the rules of the system aren’t the same as the\nlaws that govern the system. I get that that’s confusing, so let’s explain it by\nexample. A computer is controlled by a set of rules consisting of the software\nrunning on that computer. Hacking the computer means subverting that software.\nBut there are also laws that potentially govern what someone can legally do. In\nthe US, for example, the Computer Fraud and Abuse Act makes most forms of\nhacking a felony. (Notice what’s going on here. The computer system is what’s\nbeing hacked, but a more general legal system is protecting it.) There are a lot\nof problems with how general the law is, but precisely because of that\ngenerality it has become a catch-all that declares all computer hacking illegal.\n\nProfessional sports are hacked all the time, because they are governed by\nexplicit sets of rules. The law is often hacked, because law is nothing but\nrules.\n\nIn some systems, of course, the laws are the rules or, at least, provide many of\nthem. As we’ll see when we discuss hacking finances or the legal system itself,\nsimple typos or confusing language in a bill, contract, or judicial opinion can\nopen the door to endless exploits that were never intended by the original\ndrafters or judges themselves.\n\nNote something very important: the rules don’t have to be explicit. There are\nlots of systems in our world, particularly social systems, that are constrained\nby norms. Norms are less formal than rules; often unwritten, they nevertheless\nguide behavior. We are constrained by social norms all the time, different norms\nin different situations. Even politics is governed by norms as much as by law,\nsomething we repeatedly learned in the US in recent years as norm after norm was\nbroken.\n\nMy definition of system includes the word “intended.” This implies a designer:\nsomeone who determines the desired outcome of a system. This is an important\npart of the definition, but really it’s only sometimes correct.\n\nWith computers, the systems being hacked are deliberately created by a person or\norganization, which means the hacker is outsmarting the system’s designers. This\nis also true for systems of rules established by some governing body: corporate\nprocedures, rules of a sport, or UN treaties.\n\nMany of the systems we’ll be discussing in this book don’t have individual\ndesigners. No one person designed market capitalism; many people had their hand\nin its evolution over time. The same applies to the democratic process; in the\nUS, it’s a combination of the Constitution, legislation, judicial rulings, and\nsocial norms. And when someone hacks social, political, or economic systems,\nthey’re outsmarting some combination of the designers of the system, the social\nprocess by which the system evolved, and the societal norms that govern the\nsystem.\n\nOur cognitive systems have also evolved over time, with absolutely no designer\ninvolved. This evolution is a normal part of biologically based systems: new\nuses for existing systems emerge, old systems get repurposed, unneeded systems\natrophy. But we do speak about the “purpose” of a biological system: the purpose\nof the spleen or the purpose of the amygdala. Evolution is a way for a system to\n“design” itself without a designer. For those systems, we’ll start with a\nsystem’s function within a body or ecosystem—even if there was no one designing\nthat purpose.\n\nHacking is a natural outgrowth of systems thinking. Systems permeate much of our\nlives. These systems underpin most of complex society, and are becoming\nincreasingly complex as society becomes more complex. And the exploitation of\nthese systems—hacking—becomes ever more important. Basically, if you understand\na system well and deeply, you don’t have to play by the same rules as everyone\nelse. You can look for flaws and omissions in the rules. You notice where the\nconstraints the system places on you don’t work. You naturally hack the system.\nAnd if you’re rich and powerful, you’ll likely get away with it."},{"title":"Test Section Title","content":"4\n\nThe Hacking Life Cycle\n\nIn computer security speak, a hack consists of two parts: a vulnerability and an\nexploit.\n\nA vulnerability is a feature in a system that allows a hack to occur. In a\ncomputer system, it’s a flaw. It’s either an error or an oversight: in the\ndesign, the specification, or the code itself. It could be something as minor as\na missing parenthesis—or as major as a property of the software architecture.\nIt’s the underlying reason that the hack works. An exploit is the mechanism to\nmake use of the vulnerability.\n\nIf you’re logging into a website that allows your username and password to be\ntransmitted unencrypted over the Internet—that’s a vulnerability. The exploit\nwould be a software program that eavesdrops on Internet connections, records\nyour username and password, and then uses it to access your account. If a piece\nof software enables you to see the private files of another user, that’s a\nvulnerability. The exploit would be the software program that allows me to see\nthem. If a door lock can be opened without a key, that’s also a vulnerability.\nThe exploit would be whatever physical shim or tool is required to pry it open.\n\nLet’s take a computer example: EternalBlue. That’s the NSA code name for an\nexploit against the Windows operating system, used by the NSA for at least five\nyears before 2017, when the Russians stole it from that agency. EternalBlue\nexploits a vulnerability in Microsoft’s implementation of the Server Message\nBlock (SMB) protocol, which controls client–server communication. Because of the\nmanner in which the SMB was coded, sending a carefully crafted data packet over\nthe Internet to a Windows computer allowed an attacker to execute arbitrary code\non the receiving computer, and thereby gain control over it. Basically, the NSA\nwas able to exploit EternalBlue to remotely commandeer any Windows computer on\nthe Internet.\n\nSeveral types of people—each with different skill sets—can be involved with a\nhack, and the term “hacker” can confusingly refer to all of them. First, there’s\nthe creative hacker, who uses her curiosity and expertise to discover the hack\nand create the exploit. In the case of EternalBlue, it was a computer scientist\nat the NSA who discovered it. In the case of the Double Irish tax loophole, it\nwas some international tax expert who painstakingly studied the different laws\nand how they interact.\n\nSecond, there is the person who uses the resultant exploit in practice. In the\nNSA, it was an employee who deployed the exploit against a target. In an\naccounting firm, it was whichever accountant applied Irish and Dutch tax laws to\na particular corporation’s tax avoidance strategy. The hacker who performs that\nsort of hack makes use of someone else’s creativity. In the computer world, we\nderisively call them “script kiddies.” They’re not smart or creative enough to\nunearth new hacks, but they can run computer programs—scripts—that automatically\nunleash the results of someone else’s creativity.\n\nAnd finally, there is the organization or person in whose service this is all\nbeing done. So we can speak of the NSA hacking a foreign network, or Russia\nhacking the US, or of Google hacking the tax code.\n\nThis is all important, because we’re going to be talking repeatedly about how\nthe rich and powerful hack systems. I’m not saying that wealth and power makes\nsomeone a better technical hacker, it just gives that person better access. Like\nthe US or Russia or Google, it enables them to hire the technical expertise\nneeded to successfully hack systems.\n\nHacks are both invented and discovered. More specifically, the underlying\nvulnerability is discovered, then the exploit is invented. Both words are used,\nbut I prefer “discovered” since it reinforces the notion that the capability is\nlatent in the system even before anyone realizes that it’s there.\n\nWhat happens once hacks are discovered depends on who discovers them. Generally,\nthe person or organization that figures out the hack uses it to their advantage.\nIn a computer system, this might be a criminal hacker or a national intelligence\nagency like the NSA—or anything in between. Depending on who starts using it and\nhow, others may or may not learn about it, or others may independently discover\nit. The process might take weeks, months, or years.\n\nIn other systems, the utility of a hack depends on how often and how publicly\nit’s used. An obscure vulnerability in a banking system might be occasionally\nused by criminals, and remain undetected by the bank for years. A good hack of\nthe tax code will proliferate simply because whoever owns the discovery is\nlikely selling their knowledge of it. A clever psychological manipulation might\nbecome public once enough people talk about it—or it might be obscure and\nunknown for generations.\n\nEventually, the system reacts. The hack can be neutralized if the underlying\nvulnerability is patched. By this I mean that someone updates the system in\norder to remove the vulnerability or otherwise render it unusable. No\nvulnerability, no hack. It’s as simple as that.\n\nThis all implies that there’s someone who controls the target system and is in\ncharge of whatever processes update it. This is obvious if the system is the\nMicrosoft Windows operating system or any other large software package; the\ndeveloper is behind it. Companies like Microsoft and Apple have become very good\nabout patching their systems.\n\nThis also works for open-source and public-domain software; there’s usually a\nperson or organization behind it, and the code is there for all to see. It works\nless well for low-cost IoT software, much of which is designed abroad, at a\nminimal profit margin, by software teams that have long since disbanded. Even\nworse, many IoT devices can’t be patched at all. This isn’t a matter of not\nknowing how; many IoT devices embed their computer code in hardware and not\nsoftware, and are thus inherently unpatchable. This problem worsens as\nproduction lines are disbanded and companies go out of business, leaving\nmillions of orphaned Internet-connected devices behind.\n\nIn technical systems, hacks are often patched as soon as they’re discovered.\nThis process doesn’t work nearly as well with the social systems I’m discussing\nin this book. Updating the tax code, for example, requires a years-long\nlegislative process. The people benefiting from the hack might lobby against any\nchange in the law. There might be legitimate disagreement about whether the hack\nbenefits society or not. And, as we’ll see in much of the rest of the book, the\nwealthy and powerful have an outsized say in what is nominally the democratic\nprocess of figuring it out.\n\nIf the system isn’t patched, then the hack becomes integrated into the system’s\nrules. It becomes the new normal. So what starts out as a hack can quickly\nbecome business as usual. That’s the trajectory for many of the nontechnical\nhacks I’ll talk about in this book."},{"title":"Test Section Title","content":"5\n\nThe Ubiquity of Hacking\n\nNo matter how locked-down a system is, vulnerabilities will always remain, and\nhacks will always be possible. In 1930, the Austro-Hungarian mathematician Kurt\nGödel proved that all mathematical systems are either incomplete or\ninconsistent. I have a theory that this is true more generally. All systems will\nhave ambiguities, inconsistencies, and oversights, and they will always be\nexploitable. Systems of rules, in particular, have to thread the fine line\nbetween being complete and being comprehensible, within the many limits of human\nlanguage and understanding. Combine this with the natural human need to push\nagainst constraints and test limits, and with the inevitability of\nvulnerabilities, and you get everything being hacked all the time.\n\nClub Penguin was a Disney online kid’s game that operated from 2005 to 2017.\nChildren talking to strangers online is always a worry, so Disney created an\n“Ultimate Safe Chat” mode that prohibited free-form text by restricting players\nto a list of pre-scripted messages. The idea was to keep kids safe from\nunscripted chatting with real or imagined child predators. Kids being kids, they\nwanted to talk with each other. They hacked this restriction by using their\navatars’ body positions to communicate things like letters and numbers.\n\nChildren are natural hackers. They don’t understand intent and, as a result,\ndon’t see system limitations in the same way adults do. They look at problems\nholistically, and can stumble onto hacks without realizing what they’re doing.\nThey aren’t as constrained by norms, and they certainly don’t understand laws in\nthe same way. Testing the rules is a sign of independence.\n\nLike Club Penguin, many online games for children have tried to place\nrestrictions on speech, to prevent bullying, harassment, and predators. Kids\nhave hacked them all. Tricks to evade moderators and swear filters include\ndeliberate misspellings like “phuq,” separating out key information over several\nutterances so that no single utterance breaks the rules, and acrostics. Some\nsites prohibited users from typing numbers; kids responded by using words: “won”\nfor one, “too” for two, “tree” for three, and so on. Same with insults: “lose\nher” for loser, “stew putt” for stupid.\n\nSchools have tried to restrict the ways students use school-provided computers,\nand students have responded by hacking them. They pass successful hacks around\nto their friends. After one district limited the websites students were allowed\nto visit, students realized that if they used a VPN, the restrictions couldn’t\nbe detected or enforced. After another district blocked chat apps, the students\nfigured out that they could chat using a shared Google Doc.\n\nThat hack wasn’t new. It even has a name: foldering. In separate incidents, it\nwas used by General Petraeus, Paul Manafort, and the 9/11 terrorists. They all\nrealized that they could evade communications surveillance if they shared an\nemail account with their co-conspirators and wrote messages to each other,\nkeeping them as email drafts and never sending them.\n\nI remember hacks to get around phone system rules from my childhood. If you’re\ntoo young to remember how this works, I’ll explain. The caller would call a\nhuman operator and tell the operator who they were and that they wanted to make\na collect call. The operator would place the call, and ask whoever picked up the\nphone on the other end if they wanted to accept the collect call from the\nsender. Collect calls had a hefty surcharge. But because the operator initiated\nthe call, information could be transmitted before anything was charged. So, we\nwould call collect, the operator asking the other party—generally our parents—if\nthey would accept a collect call from us. Our parents would say no and then\nreturn the call at standard, less expensive, rates. This kind of thing could be\nmade more efficient. Some families had a list of names to tell the operator;\nthey were all coded messages of some sort: “Bruce” meant “arrived safely,”\n“Steve” meant “call back,” and so on. (The operator had no idea what the\ncaller’s real name was.) Even today, people have phone hacks to get around\nbilling rules. In Nigeria, it’s called “flashing”: calling someone and hanging\nup before they can pick up. This was also huge in India in the early 2010s,\nbecause costs for cellular and landline calls were so different. All of these\nhacks are intended to subvert the phone systems in order to exchange information\nwithout paying for the privilege.\n\nHomeschooling during the COVID-19 pandemic brought out the hacker in many\nstudents. One student renamed himself “Reconnecting . . .” and turned his video\noff, so it looked like he was having connectivity problems. In March 2020,\nduring the early months of the pandemic, the Chinese city of Wuhan went into\nlockdown. Schools started holding classes remotely, and students tried to flood\nthe DingTalk homework app with one-star reviews, hoping that it would be removed\nfrom app stores. (It didn’t work.)\n\nSystems tend to be rigid and rule-bound. Systems limit what we can do, and,\ninvariably, some of us want to do something else. So we hack. Once you’re\nfamiliar with what systems are and how they operate, you’ll see them everywhere.\nAnd then you’ll see hacking everywhere.\n\nThis doesn’t imply that all systems are broken. Recall Gödel. There’s a saying\namong lawyers: “All contracts are incomplete.” A contract works not because it\nrigidly prevents the parties from subverting its intent; it works because most\nloopholes are filled with trust and good intention—and there’s a system of\narbitration and adjudication available if things go badly. It might sound naive\nand idealistic, but systems of trust are what make society work. We don’t demand\nairtight protection in our agreements, because (1) that’s impossible to achieve,\n(2) any attempt will be too long and unwieldy, and (3) we don’t really need it.\n\nIt’s the same with more general systems. What makes a system work is not its\npresumed invulnerability. It’s that same combination of trust and adjudication.\nEven though I’m going to be talking about hacks and hacking, they are all\nlargely exceptions. Most people don’t hack systems, and those systems work\npretty well most of the time. We rightly trust that most people don’t hack\nsystems. And we have systems to deal with hacks when they occur. This is\nresilience. This is what makes society work. It’s how we humans have dealt with\nhacking for millennia.\n\nNot all systems are equally hackable. As we move through the book, we’ll see\nvarious characteristics of systems that make them more or less vulnerable to\nhacking. Complex systems with many rules are particularly vulnerable, simply\nbecause there are more possibilities for unanticipated and unintended\nconsequences. This is certainly true for computer systems—I’ve written in the\npast that complexity is the worst enemy of security—and it’s also true for\nsystems like the tax code, financial regulations, and artificial intelligence.\nHuman systems constrained by more flexible social norms and rules are more\nvulnerable to hacking, because they leave themselves more open to interpretation\nand therefore have more loopholes.\n\nOn the other hand, systems that are less critical, smaller-scale, and\nmarginal—and possibly more experimental and ill-defined—will cause less harm if\nthey’re disrupted, and it’s probably better to let those systems evolve through\nmore hacking than to worry about what might go wrong.\n\nThere’s not much value, and a lot of danger, in letting people hack the process\nof designing and building a bridge. Getting it wrong would be catastrophic.\nThere’s a lot more to be said for allowing the kind of hacking that results in\nwonderful, unanticipated ways to use the Internet.\n\nHacking is a natural part of the human condition. It’s ubiquitous and, as we’ll\nsee, an evolutionary process: constant, unending, and capable of creating, as\nDarwin would say, “forms most beautiful and most wonderful”—or most strange and\nterrible."},{"title":"Test Section Title","content":"PART 2\n\n\n\nBASIC HACKS AND DEFENSES"},{"title":"Test Section Title","content":"6\n\nATM Hacks\n\nTo start with, we’ll look at a variety of hacks against obviously constrained\nsystems. It’ll be an essential foundation for understanding hacks against\nbroader political, social, economic, and cognitive systems.\n\nAn ATM is just a computer with money inside. It’s connected to the banking\nnetwork by the Internet—a couple of decades ago it was a phone connection and a\nmodem—and runs on the Windows operating system. Of course, it can be hacked.\n\nIn 2011, an Australian bartender named Don Saunders figured out how to get free\nmoney from ATMs. He stumbled into the hack late one night. (It makes a better\nstory if we imagine he was drunk at the time.) He noticed a way that he could\ntransfer money he didn’t have from one account to another, then withdraw the\ncash without the system recording the transaction. The bonanza resulted from a\nvulnerability in the ATM’s software used to record transfers between accounts,\ncombined with another vulnerability in the time lag in how the various accounts\ncredited and debited when the ATMs went offline for the night. Saunders didn’t\nunderstand any of that, though. He found it by accident, and realized that he\ncould reproduce the result.\n\nOver the next five months, Saunders withdrew $1.6 million Australian—that’s\nroughly $1.1 million US. And he wasn’t so much caught as he eventually stopped\ndoing it, felt guilty about it, went into therapy over it, and then publicly\nconfessed. The bank had never figured out how it was losing so much money.\n\nLet’s pause for a second and talk about what’s being hacked here. Stealing money\nfrom a bank is always illegal. The hack isn’t of the banking system; the hack is\nof the ATM system and the bank’s software. Saunders found an unintended and\nunanticipated way to use those systems—to do things that the systems allowed—in\na way that subverted their intent. That’s the hack.\n\nThe decades-long evolution of ATM attacks and resultant security countermeasures\nnicely illustrates the arms race between hackers and defenders. More than that,\nit illustrates several themes that we’ll return to throughout the book. Systems\nnever exist in isolation. They’re made up of smaller systems, and they’re part\nof larger systems. ATMs are computer software, yes. But they’re also physical\nobjects. Their use involves customers, and a remote banking network. Hackers can\ntarget any of those aspects of ATMs.\n\nThe first ATM attacks were crude, more basic thievery than hacking. Criminals\nwould glue the cash dispenser doors shut, then pry them open after a frustrated\ncustomer gave up and left. They would find a way to “trap” cards in the slot,\nthen pull them out and use them later. They would rip entire machines out of\nwalls and cart them away, opening them up later in some safe location—as seen on\nthe television show Breaking Bad. Defenders responded. Subsequent ATM designs\ndidn’t have doors on the cash dispensers, so there was nothing to glue shut.\nThey were better secured to the wall, and their store of cash was refilled more\noften so there was less money inside to steal. (Smart attackers responded to\nthat by targeting machines the evening before a long holiday weekend, when there\nwas more money inside.) Modern ATMs have their own camera systems, not to\nprevent these sorts of attacks, but to better identify and hopefully arrest\ncriminals who perpetrate them.\n\nOther attacks directly targeted the customer’s perceptions of authority. Here’s\none example. A criminal dressed in a suit or company uniform interrupts a\ncustomer using an ATM. “This machine is out of order. Use that one over there.”\nThe customer obediently moves to the next machine, leaving the criminal to put\nan “out of order” sign on the first machine. The customer completes his\ntransaction and leaves, and the criminal completes the customer’s interrupted\ntransaction on that first machine to withdraw money.\n\nA string of thefts along those lines led to several more changes in ATM design.\nInitially, the machine would hold a customer’s card until the end of the\ntransaction, ensuring that the customer couldn’t be interrupted by\nofficial-looking strangers. Eventually, the back end was reengineered to prevent\nmultiple simultaneous ATM transactions. That didn’t prevent all hacks of\nauthority. A cruder version, reported in Indonesia, involved a fake bank manager\nconvincing a customer to give him his ATM card after he pretended to call the\nbank and cancel it.\n\nAnother family of hacks involves stealing information in order to create and use\na duplicate card. This is called “skimming,” and has become widespread and\nsophisticated over the years. The canonical hack involves placing a second\nmagnetic-stripe reading device over a card slot, so that the customer\nunwittingly slides his card through the malicious reader along with the ATM’s\nreal reader. Add a hidden camera or a sensor on the keypad, and a criminal can\nsteal the PIN as well. A variant involves putting a fake free-standing ATM in a\npublic location, like a shopping center. It looks like a legitimate ATM, but all\nit does is skim magnetic-stripe information and collect PINs—displaying an “out\nof order” message afterwards to shoo the cashless customers away.\n\nThese hacks exploit several vulnerabilities. First, the customer doesn’t have\nenough expertise to notice a skimmer or a fake ATM. Second, a magnetic-stripe\nATM card is easily duplicated. And third, the ATM authentication\nsystem—possession of the ATM card and knowledge of the PIN—just isn’t that\nsecure.\n\nOther ATM hacks target the software. In the hacking literature this is known as\n“jackpotting”: making the ATM spit bills out like coins from a slot machine, no\nstolen card or PIN required. A 2016 attack of this sort was hatched in Taiwan\nand then quickly spread across Asia, Europe, and Central America, resulting in\nlosses in the tens of millions of dollars. Another attack, exploiting a\ndifferent software vulnerability, started in Europe in 2020 and is still\nspreading worldwide.\n\nJackpotting has several steps. The first is figuring out the technical details,\nalmost certainly involving having access to a used ATM to disassemble and study.\nThat’s not hard; eBay has many for sale. Once the hackers figure out the\ndetails, they go after operational ATMs: opening a panel on the machine,\nconnecting to a USB port, downloading malware onto the ATM computer, and\ninstalling software to allow for remote access. Dressing the part helps; a\ncriminal who looks like a technician can do this without arousing suspicion.\nThen, with all of that in place, this individual can retreat to a safe location\nand have a compatriot approach the machine with a bag while the hackers remotely\ninstruct the machine to disgorge all of its cash.\n\nThere’s no good data on how much money is stolen this way—banks are loath to\nmake details of this sort of thing public—but the US Secret Service began\nwarning financial institutions about jackpotting in 2018. And that’s eight years\nafter security researcher Barnaby Jack demonstrated jackpotting at the DEF CON\nhacker conference in 2010. His attacks didn’t require anyone to physically\ntamper with the ATM; he found software vulnerabilities that he could remotely\nexploit to accomplish the same result."},{"title":"Test Section Title","content":"7\n\nCasino Hacks\n\nRichard Harris worked for the Nevada Gaming Control Board, where he inspected\nnew slot machines before they were installed on the casino floor. Because he had\naccess to the innards of the machines, he was able to replace the software chips\nwith his own. His modified software was programmed to pay the jackpot when coins\nwere inserted into a machine in a specified sequence. He modified over thirty\nmachines between 1993 and 1995, and won hundreds of thousands of dollars through\na group of associates that played his machines. Finally, one of his associates\ngot sloppy and was caught.\n\nLike an ATM, a slot machine is also just a computer with money inside. It was a\nmechanical device when invented in 1895, but since the 1980s, a computer\ncontrols the result and the wheels only serve a psychological function. Many\nslot machines don’t even have real wheels; it’s all simulated on a computer\ndisplay.\n\nAnd they’ve been hacked since the beginning. Some older machines could be\nphysically jostled to change where the results landed. Other machines could be\nfooled into spinning by a coin on a string. Many machines count the coins they\ndispense with an optical sensor; obscuring that sensor by slipping a device\ninside the machine up from the coin tray resulted in bigger payouts.\n\nEvery game on the casino floor has been hacked. Some of these hacks are now\nnormal. I don’t mean that they’re allowed, but that we’ve all heard about them\nand don’t consider them innovative or even interesting. Card counting in\nblackjack used to be a hack; now there are books on how to do it and rules\nagainst doing it successfully.\n\nThe idea of predicting the outcome of roulette dates from the 1950s. The wheel\nspins at a constant rate, the croupier tends to spin the ball the same way, and\nwith enough computation you can figure out which numbers the ball is more likely\nto land on.\n\nA 1960s cheating technique involved a wearable computer with toe switches and an\nearpiece. The wearer would input data with his toes: information that would\nenable the computer to calculate the speed of the wheel, the speed with which\nthe croupier habitually flicked the ball, and so on. The earpiece would tell the\nwearer which numbers were more likely to come up. Later designs improved on the\ndata input and speed, and in the 1970s a group of University of California,\nSanta Cruz, graduate students managed to turn a profit with their shoe computer.\n\nTheir hack wasn’t illegal. It wasn’t until 1985 that Nevada banned the use of\ndevices to predict the outcome of casino games. The real defense was to modify\nthe rules of the game so that croupiers stopped taking bets earlier.\n\nAs hacks go, card counting in blackjack is a tough one to pull off for those\nwithout the requisite savant skills. Basically, players have an advantage when\nthere are more tens remaining in the deck, and the house has an advantage when\nthere are fewer. So a card counter tracks that information and bets more when he\nor she has an advantage. It’s only a slight advantage—about 1% over the\nhouse—but it’s real. And it requires a lot of concentration on the part of the\nplayer.\n\nCasinos have responded in two different ways. The first is to make card counting\nmore difficult. Many casinos shuffle six decks of cards together—automatic\nshufflers do the work—and only deal two-thirds of the way through the decks to\nreduce the player’s probabilistic advantage. Or they shuffle after every hand.\nIn both Las Vegas and Atlantic City, pit bosses are known to come around and\nengage suspected card counters in conversation to both distract and intimidate\nthem.\n\nCasinos tried making card counting illegal, but the regulators weren’t convinced\nthat the strategy equaled cheating. (Laws were passed banning card-counting\ndevices.) All casinos can do is catch card counters and ban them from the\ncasino. Formerly, they did this by instructing casino staff to be alert for\ntypical card-counting behavior. More recently, casino cameras that track the\nmovement of every card do this automatically. Since casinos are private\nbusiness, they generally can (depending on the state) deny service to whomever\nthey want, as long as they don’t illegally discriminate while doing so.\n\nThe other response to card counting is to accept it as a cost of doing business.\nMore people think they can count cards than actually can. Casinos actually\nbenefit from the popular impression that blackjack is the one game where players\ncan beat the house, and they make more money from wannabe card counters than\nthey lose from actual ones. As an enticement, some casinos even advertise the\nfact that they deal blackjack from a single deck.\n\nThere are exceptions, of course. In the 1980s, a group of MIT and Harvard\nacademics invented an innovative card-counting hack. Casinos know how to detect\ncard counters; they look for people who (1) consistently win and (2) change\ntheir betting patterns in a way that implies strategic knowledge. The MIT group\ndivided the different card-counting tasks among different players to better\navoid detection. The counters sat at the tables and never changed their betting\npatterns. The large-money bettors also never changed their betting patterns and\nwere steered to “hot tables” by compatriots who received signals from the\ncounters. The group made an estimated $10 million before they gave up the\nbusiness. Indeed a great hack."},{"title":"Test Section Title","content":"8\n\nAirline Frequent-Flier Hacks\n\nIn 1999, David Phillips bought over 12,000 Healthy Choice pudding cups. Why? To\nhack an airline frequent-flier program.\n\nAirline frequent-flier plans became popular in 1981, when American, United, and\nDelta unveiled their programs. Now, everyone has one. They’re loyalty programs,\nrewarding customers who consistently fly an airline and making them less likely\nto switch to another one. Before COVID-19, I flew all the time. I know all the\nins and outs of those programs. They’ve all been hacked since the beginning.\n\nOne of the early hacks was called “mileage runs.” Miles, which fliers earn on\nthe basis of the distance traveled, are basically a private currency that can be\nredeemed for tickets. A clever hacker will look for ways to arbitrage the two\ncurrencies: instances where you can get a lot of miles for not a lot of money.\nSo, for example, flying nonstop from New York to Amsterdam is 3,630 miles, but\nconnecting through Istanbul is 6,370 miles. If the two tickets cost the same,\nand you have nothing better to do with your time, that’s a great deal.\n\nMileage runs were definitely an unanticipated subversion of these plans. Then\nthe hacks got weirder. The programs include reward tiers, which means that\nflying—for example—at least 50,000 miles in a year is valuable to a frequent\ntraveler. Travelers would sometimes fly complicated yet cheap round-trip\nitineraries, with six or more stops, just to accrue the miles. They wouldn’t\neven bother leaving the airports.\n\nAirlines ignored these hacks for years. But in 2015, airlines started changing\ntheir frequent-flier programs to make mileage runs less useful. They imposed\nminimum spending requirements for elite statuses, and eventually changed the\ndefinition of “frequent-flier mile” so that it depended on dollars spent rather\nthan miles flown.\n\nOther hacks involved ways to accrue points other than by flying. Airlines have\nlong had affiliations with credit cards. These cards offer miles with every\npurchase, but often also large mileage bonuses when signing up. The hack is\nobvious: sign up for a lot of credit cards, and cancel before any fees accrue.\nOne man opened a credit card and immediately bought $3,000 worth of Amazon gift\ncards to qualify for a sign-up bonus. Another filled his garage with blenders\nfor a promotion offering extra points on appliances. A third boasted that she\nhad “taken out over forty-six credit cards in five years and earned 2.6 million\nmiles just in sign-up bonuses.”\n\nThe harm, of course, is that the banks end up paying billions of dollars in\nflights and other rewards for customers who are not paying fees or interest on\ntheir cards, and that these costs are passed on to consumers as higher ticket\nprices. Some credit cards have tried to clamp down on these hacks. In 2016,\nChase instituted a rule that a consumer won’t be approved for most Chase credit\ncards if that person has opened five or more credit card accounts across all\nbanks in the past twenty-four months. American Express now revokes miles of\npeople who have “engaged in abuse, misuse or gaming in connection with earning\nor using points,” giving it a broad ability to penalize customers it believes\nhave abused the system.\n\nWhich brings us back to the Pudding Guy. Infamous among airline-program hackers,\nPhillips found a vulnerability not in any particular airline’s program but in a\n1999 Healthy Choice tie-in. By then, most airlines had affiliate programs, where\ncompanies could buy frequent-flier miles in bulk and offer them to their\ncustomers as a reward. In this particular program, customers could earn miles on\nthe airline of their choice for buying Healthy Choice products. Phillips\nsearched for the cheapest qualifying product he could find, and ended up buying\n12,150 single pudding cups at 25 cents each, giving him 1.2 million miles for\n$3,150—and lifetime Gold frequent-flier status on American Airlines. (Then he\ndonated the pudding to charity for an additional $815 tax write-off.) Definitely\nnot the outcome Healthy Choice was expecting, but since Phillips didn’t break\nany rules, the company paid up."},{"title":"Test Section Title","content":"9\n\nSports Hacks\n\nSports are hacked all the time. I think it’s a combination of the intense\npressure—and, at the professional level, money—and the necessarily incomplete\nrulebooks.\n\nSome random stories:\n\nAmerican baseball, 1951. The St. Louis Browns snuck a 3-foot 7-inch tall player\nnamed Ed Gaedel onto their roster. He made one appearance at bat. It was a walk,\nof course, because his strike zone was so small it was impossible to throw\naccurately. The league had no official height requirement, so the hack was\ntechnically legal. Even so, the league president voided the player’s contract\nthe next day.\n\nBasketball, 1976. It was double overtime in the NBA finals. The Phoenix Suns\nwere down by one point, and there was less than a second on the clock. The Suns\nhad the ball at the far end of the court, with no time to get it to the basket\nand shoot. At that moment Suns player Paul Westphal hacked the rules. He called\na time-out, even though his team had none remaining. The refs called a foul,\nwhich meant that the Boston Celtics got a free throw. But the extra Boston point\nmade no difference. What was important was that the Suns would get the ball\nmidcourt after the free throw, which gave them a chance to score a two-point\nbasket and force a third overtime. Which they did. The next year, the NBA\nchanged the rules, preventing a team from advancing the ball to midcourt by\ncausing a technical foul.\n\nSwimming, 1988. Both America’s David Berkoff and Japan’s Daichi Suzuki hacked\nthe backstroke, swimming most of the length of the pool underwater and clocking\namazingly fast times. This technique was soon adopted by other top-flight\nswimmers, until the International Swimming Federation stepped in and limited the\ndistance a backstroke swimmer could remain submerged.\n\nAmerican football, 2015. The New England Patriots used a novel hack against the\nBaltimore Ravens, shifting players around at the scrimmage line to manipulate\nthe complicated rules governing which players were eligible receivers. Two\nmonths later, the league amended its rules to make the hack illegal.\n\nIt doesn’t always go this way. Many hacks aren’t declared illegal; they’re\nincorporated into the game because they improve it. Many aspects of sports that\nare normal today were once hacks. In football, the forward pass was once a hack.\nSo was the run-and-shoot offense, and the fast snap while the other team is\nchanging players. In baseball, the sacrifice fly and the intentional walk were\nonce hacks. None of those were against the rules. It’s just that the players and\nteams didn’t think of them. Once someone did, they became part of the game.\n\nThe process isn’t always smooth. In basketball, dunking was once a hack. No one\nimagined that someone could jump high enough to push the ball into the basket.\nIn the early decades of basketball, the move was both hailed and decried.\nVarious leagues tried to ban dunking, but it’s been a mainstay of the sport\nsince the mid-1970s because the fans liked it.\n\nIn cricket, unlike baseball, you can score by hitting the ball in a 360-degree\ncircle from the batter. For over a century, the conventional way to score has\nbeen to hit the ball back roughly towards the bowler, like in baseball, or to\nglance the ball off the edge of the bat at an angle behind the batter. In the\nearly 2000s, a few cricketers realized they could perilously “scoop” or “ramp”\nthe ball over their own head. This shot was entirely within the rules, requiring\nonly extra courage and the hacker mentality (one claimed to have developed it\nplaying on narrow Sri Lankan streets). Some famous victories were won using this\ntechnique in exhilarating fashion, and it is now a standard shot in the game.\n\nSign stealing is allowed in baseball, with numerous restrictions and caveats in\nresponse to continued hacks of this system. The second baseman and the\nthird-base coach are allowed to try to read the catcher’s signs. The batter is\nnot. Cameras in the outfield are prohibited. When the Houston Astros stole signs\nwith a camera in 2017 and 2018, they were cheating rather than hacking, since\nthat rule was already in place.\n\nMost sports hacks are obvious after they’re used. There’s no hiding swimming\nunderwater, or scooping the cricket ball over your head. As soon as the first\nplayer or team does it, everyone knows about it. Exceptions involve sports where\nthings can be hidden. Two areas where this occurs are varieties of mechanical\nracing (automobile, yacht, and so on) and doping (of both humans and animals).\n\nFormula One racing is full of hacks. First, members of one team find a loophole\nin the existing regulations to enhance their car’s efficiency. Then, the other\nteams eventually learn about it and either copy the idea or protest the\ninnovation. Finally, the Fédération Internationale de l’Automobile (FIA) steps\nin and either bans the hack or incorporates it into the next season’s\nengineering specifications.\n\nFor example, in 1975, the Tyrell team built a six-wheeled car: two in the back\nand four in the front. The hack increased performance but decreased reliability.\nOther teams built prototypes in response, but in 1983 the FIA ruled that all\ncars could have no more—and no fewer, just to be on the safe side—than four\nwheels. In 1978, the Brabham team skirted the rule that no car could have\nmovable aerodynamic features like fans by putting one near the radiator and\ncalling it a cooling device. That car was voluntarily withdrawn from\ncompetition, and no rules were changed as a result. In 1997, the McLaren team\ndeveloped a car with two brake pedals, the second controlling the rear wheels\nonly. I don’t know enough about automobile racing to understand the details, but\nit gave the driver an advantage. This was initially allowed, but then banned\nafter other teams complained.\n\nIn 2010, McLaren hacked the ban on movable aerodynamic features by adding a hole\nin the cockpit that the driver could cover or uncover with his leg. The argument\nwas made that there were no moving parts involved with the hole, so it was\nallowed by the rules. But the driver moving his leg had the same effect, and the\ntechnique was promptly banned. In 2014, Mercedes redesigned its Formula One\nengine’s turbocharger, splitting the turbine and compressor and locating them on\neither side of the engine. The design tweak was never declared illegal, and its\nuse is the reason why the Mercedes team dominated the sport for the next six\nyears. In 2020, Mercedes added a feature to the steering wheel: pushing or\npulling on the column changed the alignment of the front wheels. It’s against\nthe rules to add any functionality to the steering wheel; the legality of that\nparticular hack depends on the precise definition of a steering system, and\nwhether the feature is viewed as a steering aid or a suspension device. The FIA\nclosed this loophole in 2021.\n\nOne final example, which we will return to elsewhere in the book. Hockey sticks\nused to be flat. Then someone discovered that with a curved stick, players could\nhit slap shots at speeds not possible before. Now curved sticks are the norm,\nand there are precise limits on stick curvature. During a 1993 championship\ngame, Los Angeles Kings player Marty McSorley was famously caught with an\nillegally curved stick."},{"title":"Test Section Title","content":"10\n\nHacks Are Parasitical\n\nA SARS-CoV-2 virion is about 80 nanometers wide. It attaches itself to a protein\ncalled ACE2, which occurs on the surface of many of our body’s cells: in the\nheart, gut, lungs, and nasal passages. Normally, ACE2 plays a role in regulating\nblood pressure, inflammation, and wound healing. But the virus has a tip that\ncan grab it, thereby fusing together the membranes around the cell and the\nvirus, and allowing the virus’s RNA to enter the cell. The virus then subverts\nthe host cell’s protein-making machinery, hijacking the process to make new\ncopies of itself, which go on to infect other cells. Other parts of the virus’s\nRNA create different proteins that stay in the host cell. One prevents the host\ncell from sending out signals to the immune system that it’s under attack.\nAnother encourages the host cell to release the newly created virions. And a\nthird helps the virus resist the host cell’s innate immunity. The result is the\ndisease that has dominated our lives since 2020: COVID-19.\n\nCOVID-19 is a hacker. Like all viruses, SARS-CoV-2 is a clever exploitation of\nour body’s immune system, subverting the normal operation of that system at the\nexpense of our general health and the lives of over 6 million people worldwide.\nHIV is another hacker. It infects T-helper white blood cells in our body,\ninserting its own DNA into the cell’s normal DNA, and then replicating inside\nthe cell. Eventually the infected cell releases more HIV into the bloodstream,\ncontinuing the multiplication process.\n\nIn general, hacking is parasitical. Both HIV and SARS-CoV-2 are parasites:\nhosted by another species and benefiting from that arrangement, usually at the\nhost’s expense. A system exists to further a set of goals, usually put forth by\nthe system’s designers. A hacker hijacks the same system for a different set of\ngoals, one that may be contrary to the original ones.\n\nThis is obvious in the hacks of ATMs, casino games, consumer reward plans, and\nlong-distance calling plans. The goal of whoever managed the ATM is to dispense\ncash to account holders and deduct the appropriate money from their accounts.\nThe goal of the hacker is to receive cash without having money deducted from\ntheir account (or without even having to have an account at all). Similarly, the\ngoal of a casino is to be fair (which means equal opportunity between players,\nnot equal opportunity between players and the house). The goal of the hacker is\nto tilt that advantage in their favor.\n\nIt’s less obvious in sports and online games. The goals of a sports league might\nbe to make money, entertain and satisfy fans, highlight human competition, be\nfair in some sense of that term, and provide a “good game”—whatever that means.\nThe goal of the athlete is to win the games they play in, either individually or\nas a team, at the expense of fairness—and possibly to make money.\n\nThe goals of Club Penguin were to provide a safe and entertaining experience for\nits users, follow all applicable laws, and enhance the Disney Corporation’s\nbottom line. The goal of the Club Penguin hacker was to communicate more freely\nwith other players—and this was true whether the hacker was a six-year-old\nwanting to have a conversation or a child predator trolling for victims. Both of\nthose hackers were parasites, albeit drastically different kinds.\n\nSpam is an email hack. No one thought of it, let alone tried to prohibit it,\nwhen setting up the Internet protocols and the email system (even though junk\nsnail mail is a long-standing American tradition). Sending unsolicited emails,\nand especially commercial unsolicited emails, just hadn’t been done. The idea of\nspam started in the 1990s, both in email and in the then-popular Usenet\nmessaging service, and became a serious problem in the early 2000s. In those\nyears, an estimated 90% of all email was spam. It’s a parasitical hack of a\ncommunication system.\n\nNot all parasitical relationships come at the expense of the host, and not all\nhackers are evil. Usually they’re behaving rationally, in their own\nself-interest. They might be acting in their financial self-interest, like most\nof the examples in this book. But they could also be acting in their emotional,\nmoral, ethical, or political interests; they might be trying to better the world\nthrough their hacking. Sometimes they’re just looking for opportunities.\nSometimes, if the systems are stacked against them, they’re acting out of\nnecessity—just trying to survive. Think of someone trying to get healthcare or\nfood for himself or his family.\n\nLike any parasite, hacking can’t be too effective at subverting a system; it\nneeds the system to exist in order to work. So while ATM hacking can be a\nprofitable criminal enterprise, it depends on there being ATMs to hack. If ATM\nhacking were too successful, banks would stop installing these oh-so-convenient\ncash machines. If too many people had hacked Club Penguin to have conversations\nthat ran afoul of local child safety laws, Disney would have shut the system\ndown earlier than it did. Spam would have destroyed email if it weren’t for\nanti-spam programs. A hack that is too effective can end up making itself\nobsolete, by destroying the underlying system it depends on."},{"title":"Test Section Title","content":"11\n\nDefending against Hacks\n\nSpectre and Meltdown are two hardware vulnerabilities in Intel and other\nmicroprocessors; they were discovered in 2017 and announced in 2018. Basically,\nsome of the performance optimizations adopted over the years turned out to have\nsecurity vulnerabilities. Defending against the vulnerabilities was hard because\nthey were in hardware rather than software. While software patches had been\ndeveloped to fix some of the vulnerabilities, often with considerable\nperformance penalties, there were none for others. Replacing vulnerable systems\nwasn’t a viable option: the computer chips in question are found in something\nlike 100 million computers. And while future microprocessors can be designed\nwithout these vulnerabilities, existing microprocessors can’t be retroactively\nfixed. Probably the best defense was the difficulty of exploiting the\nvulnerabilities. Many computers were vulnerable, but in ways that weren’t\nobviously useful to hackers.\n\nDefending against hacks can be hard. Countermeasures range from patching to\nsecure systems design, and we’ll talk about each of them in turn.\n\nI’ll be first to admit that my taxonomy is sloppy. Passing a law that makes card\ncounting in blackjack illegal renders the tactic ineffective, but only if you\nget caught. Does that remove the vulnerability, or does it reduce the hack’s\neffectiveness? Similarly, an anti-theft dye tag attached to an expensive dress\nmakes the stolen garment less useful (reducing the attack’s effectiveness) while\nalso making the theft less likely (disincentivizing the thief). I’m okay with\nthese ambiguities. In general, I am less concerned with precise categories of\ndefenses, and more with establishing a working knowledge of the different\ndefenses that we can employ against hacks and hackers.\n\nThe first and most obvious defense is to remove the enabling vulnerability.\n\nIn the computer world, the primary defense against hacking is patching. It’s a\nstraightforward technique: update the computer code to eliminate the\nvulnerability. No vulnerability, no exploit. No exploit, no hacking.\n\nHow well patching actually works depends a lot on the type of system we’re\ntalking about. Systems that are owned or controlled by a singular entity can, if\nthey want to—that is, if it makes economic sense for them to—be quickly patched\nin the face of hacks.\n\nIssuing the patch is just the first step of the process; next, the patch needs\nto be installed on the vulnerable systems. Historically, there has been a large\ndisconnect between companies issuing patches and users installing them. Software\nvendors would issue patches, and users would install them or not, and if they\ndid install them they would take weeks or months to get around to it. These\nunpatched systems would still be vulnerable, of course.\n\nThis scenario assumes that the singular owning entity has the ability to write\nthe patch and cares enough to do so, and that the system can be patched. If that\ncompany has enough engineers on staff to write patches, and if there is an\nupdate system to quickly push the new software out to every user, then patching\ncan be a very effective security technique. If one of those two things doesn’t\nexist, then it isn’t. (Remember that there are many IoT devices whose code is in\nfirmware and can’t be patched.) That’s why your computer and phone are\nconstantly patched, and generally stay secure despite all the hacking out there.\nThat’s also why your home router is rarely patched, despite its vulnerabilities.\n\nLots of high-profile hacks have occurred because of unpatched systems. China\nhacked Equifax in 2017 through a vulnerability in the Apache Struts\nweb-application software. Apache patched the vulnerability in March; Equifax\nfailed to promptly update its software and was successfully attacked in May.\n\nAlso in 2017, the WannaCry worm spread to over 200,000 computers worldwide and\ncaused as much as $4 billion in damage, all to networks that hadn’t yet\ninstalled the patch for a Microsoft Windows vulnerability.\n\nThis illustrates a major downside of patching: it occurs after the fact. The\nvulnerability is already in the system. Hackers may be actively exploiting it at\nthe time of the patch. And even if they aren’t, the very act of patching calls\nattention to the vulnerability and exposes all of the systems that have not yet\nbeen patched.\n\nFor most individual users of computers and mobile devices, patching usually\nhappens automatically. Your Microsoft computer is likely configured to\nautomatically update itself once a month on Patch Tuesday, which can include\npatches for over 100 different vulnerabilities every month. Your iPhone nags you\nwith increasingly dire warnings if you don’t install your patches. (If you have\nnot yet internalized this lesson, let me say it explicitly: Turn automatic\nupdates on for both your computer and phone. Patch everything else as soon as\nyou get an update. Always.)\n\nLarge organizational networks have to deal with patching in a slower, cautious\nmanner. Because a bad patch can cause all sorts of problems by the way it\ninteracts with other critical software, patches are generally installed\ndeliberately and methodically. This often means that they’re installed late, or\nnot at all. We can blame Equifax for not patching Apache Struts, but that\nsoftware had a reputation for buggy patches that were incompatible with other\nsoftware built around Struts. Lots of organizations take great care when\napplying those patches.\n\nPatching works differently with social systems than with technological systems.\nWith the latter, the patch makes the latest hack no longer possible. This is\nobviously true for software, but extends to other technological systems as well.\nATM manufacturers can patch their machines so that a particular jackpotting hack\nsimply doesn’t work anymore. A casino can deal blackjack from a six-deck shoe\nthat continuously shuffles the cards. Financial exchanges can restrict trading\nto ten-second intervals, making hacks like high-frequency trading impossible. We\ncan do this because the technology effectively determines the affordances of the\nsystem.\n\nWith social, economic, or political systems that don’t directly involve\ncomputers, it’s not as clean. When we talk about “patching” the tax code or the\nrules of a game, what we mean is changing the laws or rules of the system so\nthat a particular attack is no longer permitted. So while it still might be\npossible to use a computer to predict roulette or to curve your hockey stick\nmore than three-quarters of an inch, anyone caught doing it will experience the\nconsequences. The only “installation” necessary is education: making sure that\nevery casino pit boss and hockey referee knows the new rules and how to spot\ncheaters—and then punish them accordingly. Similarly, a legal tax avoidance\nstrategy becomes illegal tax evasion, and is prosecuted if discovered (or so one\nwould hope).\n\nThis points to another problem: cheaters can be tough to spot. Recall that\nroulette was vulnerable until the betting system was changed so that the hacks\nwere no longer effective. This problem will come up repeatedly in the systems we\ntalk about in this book. If you update computer code, the hack is no longer\npossible. If you update the tax code, the hack is still possible—it’s just no\nlonger a legal loophole (and by my definition, no longer a hack). That means you\nhave to update the detection system as well, so that the now-illegal cheaters\nget caught and prosecuted.\n\nPatching is also less effective when the governing body functions slowly, or\nwhen the governing body doesn’t have a unified vision of whether a patch is even\nnecessary. That is, when the system doesn’t have a clear goal. What, for\nexample, does it mean to “patch” the tax code? In most cases, it means passing\nanother law that closes the vulnerabilities from the original law. That’s a\nprocess that can take years, because the tax code is created in the political\nrealm, which is characterized by competing visions of what public policy should\naccomplish. Also, the very people who take advantage of the vulnerability will\nattempt to hack the legislative systems to ensure that the law continues to\npermit their actions. Imagine if blackjack card counters were in charge of\ncasino rules. Blackjack card counting would be celebrated as a clever, honest\nway to win the game in the same way tax avoidance is celebrated as smart.\n\nIn the absence of legislative patches, a court can quickly target a very\nspecific patch. In the computer world, this is known as a hotfix: a fast\nsoftware update designed to fix a particular bug or vulnerability. The term\ncomes from the fact that, traditionally, these updates were applied to systems\nthat were up and running: hence “hot.” It’s more risky; the software could\ncrash, with whatever problems could result from that. Hotfixes are normal\ntoday—updates to your operating systems are applied while they are running, and\na lot of stuff is running in the cloud—but when the term was coined, that wasn’t\nthe case."},{"title":"Test Section Title","content":"12\n\nMore Subtle Hacking Defenses\n\nReducing a hack’s effectiveness is a second defense.\n\nBusiness email compromise is a social engineering attack, in that it exploits a\nvulnerability in people rather than a vulnerability in technology. In this scam,\nthe victim receives an email from a normally trusted source, making a normally\nlegitimate request but asking him or her to do it differently than usual, often\nagainst established protocol. So, a bookkeeper might receive an email from a\nvendor who asks to be paid into a new bank account. Or a home buyer might\nreceive an email from his title company, with instructions on how to wire a down\npayment. Or the financial head of a company might receive an email from the CEO,\nasking for an emergency multimillion-dollar wire transfer to a specific account.\nThe receiving accounts are owned by the scammer, and the victim often never sees\nhis money again. These types of scams cost billions.\n\nSometimes email accounts of legitimate vendors are hacked in this scam, which\nincreases the likelihood that the target will trust the sender. More often, the\nscam emails are slight variations of legitimate addresses:\nperson@c0mpanyname.com instead of person@companyname.com, for example. (If you\ncan’t tell or are listening to this as an audiobook, the “o” in “companyname” is\nactually a zero.) The vulnerability here is human inattentiveness, or misplaced\ntrust.\n\nThere are many reasons why a vulnerability can’t be patched. In the policy\nworld, the legislative process that needs to patch the vulnerability may not be\nfunctional. Or there may be no governing body that can mandate the patch. In the\ncase of the social engineering hack I just described, the hacks subvert how the\nhuman brain works—and that isn’t patchable at anything shorter than evolutionary\ntime.\n\nWhen we can’t patch a vulnerability, we have three options. The first is to\nredesign the system so that the hack is too difficult, too expensive, less\nprofitable, or generally less damaging. This also works when outlawing a hack\nisn’t enough, and we want to make it harder as well.\n\nThe second is foreknowledge. If I can teach you about business email compromise\nand how it works, you will become better able to recognize when you are being\ntargeted by it, and—hopefully—less likely to fall for it. This is how we defend\nagainst email and phone scams that slip through automated filters. This is how\npotential victims can resist effective “cognitive hacks” that play on universal\nhuman biases like fear and deference to authority.\n\nThe final option is to employ an additional system to somehow secure the\nvulnerable system. For business email compromise, a company might institute a\nrequirement that any large wire transfers have two people approve them. This\nmeans that even if the hack is successful and the employee is fooled, the hacker\ncan’t profit from the successful deception.\n\nThis option is often discussed as a solution to the problem of insecure IoT\ndevices. The worry is that in a few years, we will have all sorts of vulnerable\nIoT devices in our homes and on our networks, with no way to secure them. One\nsolution is to have systems on networks that detect the presence of these\ndevices and limit their behavior in ways that reduce the hacking threat. So you\ncould imagine your home router being smart enough to recognize IoT devices and\nblock them when they try to do things they’re not supposed to do—like when your\nrefrigerator starts sending spam emails, mining cryptocurrency, or participating\nin a denial-of-service attack.\n\nA third defense is detecting and recovering from a hack after the fact.\n\nIn 2020, the Russian SVR—that’s its foreign intelligence service—hacked the\nupdate servers belonging to a network management software developer named\nSolarWinds. SolarWinds boasted over 300,000 customers worldwide, including most\nof the Fortune 500 and much of the US government. The SVR installed a backdoor\ninto an update to one of the company’s products, Orion, and then waited.\n\nStop for a second. Just a few pages ago I explained that the computer industry’s\nprimary defense against hacking is patching. The SVR hacked the company’s\npatching process, and then slipped a backdoor into one of the product’s updates.\nOver 17,000 Orion customers downloaded and installed the hacked update, giving\nthe SVR access to their systems. The SVR subverted the very process we expect\neveryone to trust to improve their security. This is akin to hiding combat\ntroops in Red Cross vehicles during wartime, although not as universally\ncondemned (and prohibited by international law).\n\nThe hack was not discovered by the NSA or any part of the US government.\nInstead, the security company FireEye found it during a detailed audit of its\nown systems.\n\nOnce the SolarWinds hack was discovered, it became immediately clear how\ndisastrous (or successful, depending on your point of view) this operation was.\nThe Russians breached the US State Department, Treasury Department, the\nDepartment of Homeland Security, Los Alamos and Sandia National Laboratories,\nand the National Institutes of Health. They breached Microsoft, Intel, and\nCisco. They breached networks in Canada, Mexico, Belgium, Spain, the UK, Israel,\nand the UAE.\n\nAfter getting into all of these systems, SVR agents were able to establish new\nmeans of access unrelated to the SolarWinds vulnerability. So even after target\ncompanies patched their software and fixed the problems in their update process\nthat allowed the Russians to introduce the vulnerability in the first place, all\nof those penetrated networks were still vulnerable in probably multiple unknown\nways. The only way to really regain security would have been to throw away all\nthe hardware and software and start again from scratch. No organization did\nthat, and my guess is that those networks can still be manipulated from Moscow.\n\nThere are a bunch of lessons here. First, detection can be hard. Sometimes you\ncan detect hacks while they’re happening, but mostly you detect them after the\nfact during things like audits. Second, the hack can be so devastating that no\nresponse will suffice. And finally, it can be impossible to recover from a\nparticular hack, in which case recovery primarily involves securing the system\nfrom the next hack.\n\nNow for a final defense: finding vulnerabilities before they’re used.\n\nRed-teaming means hacking your own systems. There are companies that specialize\nin this sort of analysis; or a development team can do it themselves as part of\nthe quality control process. The red team approaches the system as if they were\nexternal hackers. They find a bunch of vulnerabilities—in the computer world,\nthey always do—and then patch them before the software is released.\n\nThis concept comes from the military. Traditionally, the red team was the\npretend enemy in military exercises. The cybersecurity community has generalized\nthe term to mean a group of people trained to think like the enemy and find\nvulnerabilities in systems. This broader definition has been incorporated into\nmilitary planning, and is now part of the military’s strategic thinking and\nsystems design. The US Department of Defense—particularly the national security\nsector—has long integrated red-teaming into its planning process. The Defense\nScience Board wrote:\n\nWe argue that red teaming is especially important now for the DoD. . . .\nAggressive red teams are needed to challenge emerging operational concepts in\norder to discover weaknesses before real adversaries do.\n\nUnless you red-team, you have to rely on your enemies to find vulnerabilities in\nyour systems. And if others are finding the vulnerabilities for you, how do you\nensure that those vulnerabilities get fixed and not exploited? In the computer\nworld, the primary means of ensuring that hackers will refrain from using the\nfruits of their efforts is by making computer hacking a crime. If you’re a\nhacker and you discover a new vulnerability, you can use it, but you’re risking\njail time. But you can also sell it to other criminals, either on the black\nmarket or the grey market.\n\nThe counterincentive is bug bounties, which are rewards paid by software\ncompanies to people who discover vulnerabilities in their products. The idea is\nthat those researchers will then inform the company, which can then patch the\nvulnerability. Bug bounties can work well, although a hacker can often make a\nlot more money selling vulnerabilities in widely used computer systems to either\ncriminals or cyberweapons manufacturers.\n\nIn either case, finding new vulnerabilities is easier the more you know about a\nsystem, especially if you have access to the human-readable source code and not\njust to the computer-readable object code. Similarly, it’s easier to find\nvulnerabilities in a rule book if you have a copy of the rule book to read, and\nnot just information about rulings."},{"title":"Test Section Title","content":"13\n\nRemoving Potential Hacks in the Design Phase\n\nAutoRun was a feature introduced in Windows 95. Before AutoRun, you would buy\nsoftware on a CD-ROM, then manually run an installation script to install it on\nyour computer. With AutoRun, you could just pop the disk into your computer, and\nthe system would automatically search for and run the install script. This made\nsoftware installation much easier for the average, technically naive user.\n\nUnfortunately, the feature was also used by virus writers to install malware\nonto systems. The virus would reside on an innocuous CD-ROM or—in later years—a\nUSB thumb drive, and would automatically execute as soon as an unsuspecting user\ninserted it into his computer. This is where that old security warning against\nplugging random USB sticks into your computer came from.\n\nNotice that the vulnerability isn’t due to a mistake. It was an attempt to\nbalance security with usability, and was a design trade-off that might have been\nsmart in 1995 but was not so smart a decade later. Responding to mushrooming\nreports of bad system behavior enabled by AutoRun, Microsoft finally redesigned\nthe system in 2011 for Windows Vista, disabling AutoRun for thumb drives,\nnetwork drives, and other media—and only enabled it for increasingly obsolete\nmedia like DVDs.\n\nThe point here is that the design process can’t perfectly defend against hacks,\nbecause (1) security is only one of the properties that a system design has to\noptimize for, and (2) the techniques hackers use and their targets and\nmotivations are constantly evolving as society and technology change. Designers\nneed to revisit their basic assumptions about how they organize and run systems.\nGood design today is bad design tomorrow, and hackers will always find ways to\nexploit bad design.\n\nBetter than finding vulnerabilities in a system before they’re hacked, we can\ndeliberately try to create systems with fewer vulnerabilities; that is, make\nsure vulnerabilities don’t exist in the first place. In computer security, this\nis called secure systems design, or security by design.\n\nThis is much easier said than done. Computer code is complex, and it’s\nimpossible to find all of the vulnerabilities that lurk within it. Mere mortals\ncan’t produce bug-free, or even vulnerability-free, software. We don’t have a\ntheory of secure software design, let alone a secure design methodology. But the\nmain reason we don’t do a lot better is that writing secure and reliable code is\nslow, hard, and expensive, and there mostly isn’t the economic incentive to do\nit. With notable exceptions like airplane avionics and the Space Shuttle, most\nsoftware is written quickly and shoddily. Still, we have design principles that\nminimize both the number of vulnerabilities and their exploitability.\n\nSimplicity: The more complex a system, the more vulnerable it is. The reasons\nfor this are myriad, but basically, a complex system has more things that can go\nwrong. There are more potential vulnerabilities in a large office building than\nin a single-family house, for example. The antidote for this is simplicity. Of\ncourse, many systems are naturally complex, but the simpler a system can be\ndesigned, the more secure it is likely to be.\n\nDefense in Depth: The basic idea is that one vulnerability shouldn’t destroy the\nwhole system. In computer systems, the place you encounter this the most is\nmultifactor authentication. Instead of just a username and a password—a single\npoint of failure—better systems also employ multiple methods of authentication.\nMy email, for example, is additionally secured by Google Authenticator. This is\nan app tied to something I own and carry with me wherever I go: my smartphone. I\nhave to unlock the phone, open the app, and type an additional time-varying code\nto access my account. Other multifactor systems might include a biometric such\nas a fingerprint, or a small USB device you have to plug into your computer.\n\nFor noncomputer systems, defense in depth is anything that prevents a single\nvulnerability from becoming a successful hack. It might be a deadbolt on your\ndoor in addition to the lock on the door handle, or two barbed-wire fences\nsurrounding a military base, or a requirement that financial transactions over a\ncertain amount must be approved by two people. A hack that overcomes one of\nthose defenses is not likely to overcome the other as well.\n\nCompartmentalization (isolation/separation of duties): Smart terrorist\norganizations divide themselves up into individual cells. Each cell has limited\nknowledge of the others, so if one cell is compromised the others remain secure.\nThis is compartmentalization, which limits the effects of any particular attack.\nIt’s the same idea behind different offices having their own key, or different\naccounts having their own password. You’ll sometimes hear this called “the\nprinciple of least privilege”: giving people only the access and privileges\nnecessary to complete their job. It’s why you don’t have a master key to all the\noffices in your building: you don’t need it.\n\nIn computer networks, this is called “segmentation,” and involves separating\nparts of the network from each other, so a hack against one part doesn’t result\nin a hack against the entire network—just like the protective measures taken by\nterrorist cells. Segmentation is the first thing an attacker tries to violate\nonce they penetrate a network. For example, good segmentation would have\nprevented the Russian SVR from using its initial access in the SolarWinds hack\nto access different parts of the network and install additional malware and\nbackdoors.\n\nThis concept easily extends to social systems. It’s reflected in the idea that\ngovernment regulators should not have any financial interest in the industries\nthey oversee (a principle regularly violated in the US via the revolving door\nbetween the government and industry). Or that election districts shouldn’t be\ncreated by elected officials who could benefit from gerrymandering them.\n\nFail-Safe/Fail Secure: All systems fail, whether due to accident, error, or\nattack. What we want is for them to fail as safely and securely as possible.\nSometimes this is as simple as a dead man’s switch on a train: if the driver\nbecomes incapacitated, the train stops accelerating and eventually coasts to a\nstop. Sometimes this is complex: nuclear missile launch facilities have all\nsorts of fail-safe mechanisms to ensure that warheads are never accidentally\nlaunched.\n\nSocial systems can have fail-safes as well. Many of our laws have something to\nthat effect. Murder is illegal, regardless of the means used; it doesn’t matter\nif you figure out some clever way to hack a system to accomplish it. The US\nAlternative Minimum Tax (AMT) was supposed to serve as a fail-safe as well: a\nminimum tax that a citizen is required to pay, no matter what sort or how many\nloopholes they’ve discovered. (That the AMT didn’t work as intended is a\ndemonstration about how hard this can be.)\n\n\n\nOf course, all of these countermeasures also reduce a hack’s effectiveness.\n\nNothing in these chapters is new. I covered much of this terrain in my 2000\nbook, Secrets and Lies. Others have written about it before me, and since. But\nunderstanding the tenets of secure design is critical to limiting the\neffectiveness of hacking. The more you can incorporate fundamental security\nprinciples into your system design, the more secure you will be from hacking.\n\nWhether companies use those techniques or not depends on the economics of their\nindustry. You’d imagine that a company like Apple or Microsoft would spend a lot\nmore money on the security of its software than would a developer that makes a\ngame for your phone. Similarly, you’d expect a company that makes software for\nairplanes, cars, and medical devices to spend significantly more money and\neffort on security than does a company that makes software for programmable\ntoys. And while there are exceptions, that intuition is largely correct."},{"title":"Test Section Title","content":"14\n\nThe Economics of Defense\n\nIn 1971, someone who bought a ticket under the name “Dan Cooper” hacked the\nBoeing 727, using the aft staircase in a clever and unintended way: to parachute\nout of a flying airplane with $200,000 in cash after a successful\nhijacking—never to be seen again. Many copycats followed, and Boeing eventually\nredesigned the 727 to remove those under-tail stairs and thereby eliminate the\npossibility of jumping out of a commercial aircraft in flight. This was an\neffective, but expensive, patching of the vulnerability. But why did the\nvulnerability exist in the first place? Boeing might not have anticipated the\nthreat, or it may have thought the threat was too remote to defend against.\n\nThreat modeling is a systems design term for enumerating all the threats to a\nsystem. If the system were your home, you might start by listing everything of\nvalue in the house: expensive electronics, family heirlooms, an original\nPicasso, the people who live there. Then you would list all the ways someone\ncould break in: an unlocked door, an open window, a closed window. You would\nconsider all the types of people who might want to break in: a professional\nburglar, a neighborhood kid, a stalker, a serial killer. You would consider\nthreats from people who don’t have to break in: intimate partner violence is an\nexample. And finally you would use all of that information to build a model\ndetailing which threats are worth worrying about and which can be ignored, how\nmuch effort to spend mitigating particular threats, and so on. Your home\nsecurity will be specific to the threat of art theft if you own an original\nPicasso. It will be different if you are the president of a country. It will be\ndifferent if you live in a war zone.\n\nEconomic considerations like these are essential to understanding how to think\nabout hacking defenses. Determine the cost of a hack. Determine the cost and\neffectiveness of a particular defense. And perform cost-benefit analysis to\ndecide whether the defense is worth it. In some cases it isn’t. For instance,\nmany ATM security measures can reduce hacking and fraud, but are not implemented\nbecause they annoy legitimate customers. They could require fingerprint scans or\nemploy facial recognition, which many customers would find invasive. If the\nmeasures sufficiently reduce the rate at which people use ATMs, they would be\nless profitable even though they would be more secure.\n\nAnother concept from economics that is essential to understanding hacking and\ndefenses against it is that of an “externality.” In economics, an externality is\nan effect of an action not borne by the person deciding to perform it. Think of\na factory owner deciding to pollute a river. People downstream might get sick,\nbut she doesn’t live there so she doesn’t care.\n\nOf course, this isn’t precisely true. The owner’s employees might live\ndownstream. Her customers might live downstream. Environmental activists might\nexpose her pollution, the press might write critical articles about it, and\npublic opinion might turn against her. Still, in our systems way of thinking,\nriver pollution is an externality of the factory.\n\nHacking causes externalities. It has a cost, but that cost is borne by the rest\nof society. It’s a lot like shoplifting: everyone has to pay higher prices to\ncompensate for losses or to pay for antitheft measures at stores.\n\nWe know how to solve problems caused by externalities: we need to convert them\ninto problems that affect the person who owns the system and is making the\ndecision. To do this, we impose rules from outside the system to bring those\ncosts inside the system.\n\nIn an ideal world this works well. In reality, it depends on enforcement and\npenalties. It depends on lawyers and on the outcome of litigation. It depends on\nthe actions of regulatory agencies, which are shaped by the people in charge, by\nlobbyists seeking to water down regulations, and by campaign donors and their\nagendas. It depends on the results of research funded by industry and academia,\nwhich may or may not skew the policy debate. It depends on citizens knowing that\nthe costs exist, knowing who to blame for the cost, and knowing how to make them\npay for it.\n\nTechnical systems become insecure when the threat model changes. Basically, a\nsystem is designed according to the realities of the time. Then, something\nchanges at some point during its use. Whatever the reason, the old security\nassumptions are no longer true and the system drifts into insecurity.\nVulnerabilities that were once unimportant or irrelevant become critical.\nVulnerabilities that used to be critical become unimportant. Hacks become easier\nor harder, more or less profitable, more or less common.\n\nMaybe the most obvious example of this is the Internet itself. As ridiculous as\nit sounds today, the Internet was never designed with security in mind. But back\nin the late 1970s and early 1980s, it wasn’t used for anything\nimportant—ever—and you had to be a member of a research institution in order to\nget access to it. And the multiuser mainframe computers that were connected to\nthe Internet had their own security. For those reasons, the original designers\nof the Internet deliberately ignored security in favor of simpler protocol\ndesign, and left security considerations to the endpoints.\n\nWe all know how this story ends. Things changed. More specifically, single-user\npersonal computers with no security started being connected to the Internet, and\nthe network designers assumed that these computers had the same level of\nmultiuser security that the old mainframes did. Then, everything about use of\nthe Internet changed. Its speed changed. Its scale changed. Its scope changed.\nIts centrality changed. Hacks that weren’t even worth thinking about back then\nsuddenly became critical. The threat model changed. And that meant any\ncost-benefit analysis changed.\n\nIn computer security, we know all about dynamic environments. Every few years,\nit seems, things change—and security has to change with it. Email spam is a\nproblem in a way that paper junk mail is not because the economics of each is\ndifferent: it’s much cheaper to send someone email than paper.\n\nMaintaining security in this dynamic environment requires staying ahead of\nhackers. That’s why we engage in research on computer security: conferences,\njournals, graduate programs, hacking competitions. We exchange information on\nwhat hackers are doing, and the best ways to defend ourselves. We try to\nunderstand where new vulnerabilities will appear before they do, and how hackers\nwill respond.\n\nIf laws are to keep up with hackers, they need to be general rules that give\nregulators the flexibility to prohibit new hacks and punish new hackers. The\nComputer Fraud and Abuse Act was passed in 1986, an outcome of concern that\nexisting laws were insufficiently broad enough to cover all computer-related\ncrimes. For example, it makes it a crime, among other things, to access\nanother’s computer system without authorization or to exceed one’s existing\nauthorized access. That broad language covers a large swath of computer-related\nhacks, so broad that the US Supreme Court scaled it back in 2021. But the point\nof the law is to allow the prosecution to say: “Yes, the system allowed it. But\ngive me a break. It might have been permitted by the system, but it was\nobviously not intended and you knew it was wrong. And therefore it’s illegal.”\n\nMany of our social systems have both the ability to patch systems and these more\ngeneral rules, at least to some degree. It’s an open question: How do we perform\nlife-cycle management of noncomputer systems? How often should we review\nsomething like our democratic institutions and check that they’re still fit for\npurpose? And what do we do if they’re not? Every few years we buy a new laptop\nand smartphone, and those newer devices are more secure. How can we do the same\nfor social institutions?"},{"title":"Test Section Title","content":"15\n\nResilience\n\nSystems of norms are different from systems of rules. It is in the nature of a\nnorm that you aren’t supposed to hack it; hacking a norm is just another term\nfor violating a norm. On the other hand, because norms are informal and not\ncodified, there’s more room for interpretation. This translates into a greater\npotential for a motivated person to push against the boundaries of the norms or\noptimize their actions for a certain outcome. And because those systems require\nhumans to respond in order to defend against attacks, it is easier for the norms\nto evolve to allow the hacks.\n\nRecent politics serves as an example of this, in the way Donald Trump was able\nto successfully push against social and political norms. I have largely avoided\nusing him as an example in this book, because he’s so politically charged. But\nthe example he provides here is too illustrative to ignore. Society has a\nmechanisms to repair soft violations of its norms—public shaming, political\npushback, journalism, and transparency—and they largely work. Trump overwhelmed\nthose mechanisms. Too many scandals emerged too quickly. The mechanisms that\nmight have reinforced the norms of behavior for public servants were ineffective\nin the face of a candidate like Trump. Norms only work if there are consequences\nfor violations, and society couldn’t keep pace with the onslaught. Trump was\nthereby able to push the boundaries in many directions all at once. And in many\ncases, it destroyed the underlying norms.\n\nOn the other hand, challenges to systems of norms can also make them resilient.\nNorms are implicit and flexible, and the easiest system to change. A system of\nnorms doesn’t require money, legal knowledge, or technology to challenge and\nchange, though all those things help; our social behaviors and implicit\nexpectations can be contested by anyone who’s willing to speak up about them—and\nhas the platform to do so. And that challenge provides more input to help those\nnorms bend and improve instead of breaking.\n\nResilience is an important concept, one that applies to everything from the\nhuman body to the planetary ecosystem, from organizational systems to computer\nsystems. It’s the ability of a system to recover from perturbations, including\nhacks.\n\nResilience is why suspension bridges are built from stranded cables and not\nsolid rods: solid rods fail suddenly and catastrophically, while stranded cables\nfail slowly and noisily. It’s why our brains and bodies have so many different\nways to adapt to whatever circumstances we find ourselves in, and why good taxi\ndrivers know four different ways to drive between popular landmarks. It’s why\nOrange County, California, has a functioning county government, even after it\nwas forced to declare bankruptcy in 1994.\n\nIn security, resilience is an emergent property of a system, one that can\ncombine such aspects of properties as impenetrability, homeostasis, redundancy,\nagility, mitigation, and recovery. Resilient systems are more secure than\nfragile ones. Many of the security measures we discussed in the previous few\nchapters are all about increasing a system’s resilience from hacking.\n\nThere’s one more point that’s worth mentioning here. We’ve been talking about\nhacking defenses largely in the abstract; however, any discussion of defense\nneeds to address the question, who is defending against whom? Who gets to decide\nwhether the hack is beneficial or not? And—most importantly—who is in charge of\ndefense, and how much defense is worth the effort and expense?\n\nThe examples I’ve provided have been pretty straightforward so far. There is\nsome person or organization in charge of the system, and they’re in charge of\ndefense. For example, Microsoft’s management gets to decide whether a particular\nWindows hack is a problem, and how to mitigate it. Mostly, they patch. If they\ncan’t easily patch, they live with the vulnerability for a while. (AutoRun is an\nexample of that.) We have examples of hacks being quickly patched. We have\nexamples of hacks never being patched. And we have examples of hacks being\nallowed to persist because defending against them is too expensive. If losses\ndue to the fraud are less than the cost to patch the system, the credit card\ncompanies will allow the fraud to persist. Stores often allow shoplifters to\nwalk out with stolen goods because retail staff who try to stop them may be\nphysically harmed, and because falsely accusing people of shoplifting could lead\nto expensive lawsuits.\n\nAs we try to build social and political systems that can defend themselves\nagainst hacks, we should think about the balance between having lawmakers write\nlaws and having regulators implement them. On the one hand, regulators are not\ndirectly accountable to the people in the same way that legislators are. On the\nother hand, we don’t want legislators to have to consider all the implementation\ndetails before passing needed laws. The more legislatures can delegate the\nimplementation of laws to regulators, the more agile the resultant system will\nbe against hacking—and the more resilient.\n\nDefending society’s systems against hacking isn’t just an issue for the\ndesigners of a particular system. It’s an issue for society itself, and for\nthose who care about social change and progress more generally."},{"title":"Test Section Title","content":"PART 3\n\n\n\nHACKING FINANCIAL SYSTEMS"},{"title":"Test Section Title","content":"16\n\nHacking Heaven\n\nOne of the central tenets of medieval Catholicism was penance and redemption.\nThe idea was that if you sinned, you could atone and receive forgiveness. Big\nsins required not only contrition but also big acts of penance that were out of\nthe reach of many. If the only road to atonement for a lifetime of sin involved\na pilgrimage to Jerusalem, most people just wouldn’t be able to achieve\nabsolution. The next logical step was to donate money so that others could do\nthe work on your behalf. It was a reasonable compromise, and a means for the\nChurch to encourage charitable giving. So if the city church needed a new roof,\na wealthy sinner could be directed to pay for roof repairs as penance. In\nexchange, the sinner received forgiveness in the form of an “indulgence,”\nbasically a document that attested before God and man that the sin was absolved.\nSo far, so good.\n\nThe vulnerability in this scheme lay in the fact that indulgences are a\nlimitless commodity; the exploit was that people in the Church started using\nthat commodity as currency. The whole system was loosely regulated, which meant\nthat no one could effectively limit the manner in which indulgences were sold.\nThe Church could print as many indulgences as it could sell, and the wealthy\nrealized that they could buy as much forgiveness as they needed. Middlemen\nappeared, paying corrupt bishops for the right to resell indulgences. What\nstarted as a system of redemption became a system of profit and power. In 1517,\nthe practice of selling indulgences led Martin Luther to post his “Ninety-five\nTheses,” or Disputation on the Power and Efficacy of Indulgences, on the door of\nthe Castle Church in Wittenberg, Germany, kicking off the Protestant Reformation\nand sparking over a century of religious warfare.\n\nWherever there’s money to be made, there’s hacking. And those who can figure out\nprofitable hacks can make a lot of money. This makes financial systems uniquely\nsuitable—that is, profitable—to be hacked. Johann Tetzel, a Dominican friar of\nthe early sixteenth century, invented two innovative indulgence products. First,\nhe marketed the idea that you could buy indulgences for deceased friends,\n“upgrading” their status in the afterlife from purgatory to heaven. And second,\nhe sold indulgences that purported to offer absolution for future sins and not\njust sins of the past. Kind of like a “get out of hell free” card.\n\nDespite substantial protests from Catholic theologians and reformers like Martin\nLuther, the Vatican was unable to clamp down on the practice. The Church came to\ndepend on the enormous profits that resulted from the sale and resale of\nindulgences, and that paralyzed any response. Tetzel’s indulgence sales were a\nsignificant source of funding for St. Peter’s Basilica, for example.\n\nMany of the hacks we’ve already discussed were disabled by whoever governed the\nsystem. Airlines updated the rules to their frequent-flier plans. Sports updated\nthe rules to the game. But once in a while, a hack was allowed—declared legal,\neven—by the governing system. A curved hockey stick makes for a more exciting\ngame. The lure of card counting is profitable for casinos, even if competent\ncard counters are not.\n\nThis normalization of a hack is common in the financial world. Sometimes new\nhacks are shut down by regulators, but more often they’re permitted—and even\ncodified into law after the fact. This is one of the mechanisms by which\nfinancial systems innovate. Instead of new ideas coming from the regulators in\nthe form of new permissions, they come from actual users in the form of hacks.\n\nWhile the obvious solution is to patch the system, it’s often not politically\npossible. Power and money translate into lobbyist muscle, which tilts the board.\nThis doesn’t mean that hacks of financial systems are never patched, just that\nit might take a while. It wasn’t until 1567 that Pope Pius V revoked permission\nto grant any indulgences that involved financial transactions, patching the\nsystem and eliminating the hack.\n\nThe moneyed are powerful hackers, and profit is a powerful motivation for\nhacking—and for normalizing hacking."},{"title":"Test Section Title","content":"17\n\nHacking Banking\n\nMany procedures we recognize as a normal part of banking today started out as\nhacks, as various powerful players tried to skirt regulations that limited their\nbehavior and their profit. This isn’t meant as a criticism; hacking is a way of\nforcing government to review and update new regulations.\n\nFor most of the twentieth century, the Federal Reserve regulated banking in the\nUS through something called Regulation Q. First promulgated in 1933 after the\nGreat Depression, Regulation Q controlled things like interest rates on\ndifferent sorts of accounts, and rates for individual and corporate customers.\n\nRegulation Q is a security measure. Prior to its enactment, banks competed with\none another to offer the highest interest rates on customer deposits. This\ncompetition encouraged banks to engage in risky behaviors to make good on those\nrates. Regulation Q’s limitations were designed to reduce systemic banking risk.\n\nThis worked for over forty years. As interest rates ballooned in the 1970s,\nbanks desperately wanted to bypass Regulation Q and offer higher interest rates\nto compete with other investments. One early 1970s hack was the NOW account. NOW\nstands for “Negotiable Order of Withdrawal,” a product designed to exploit the\ndistinction between demand deposit accounts, which allow the account holder to\nwithdraw their money at will, and term deposit accounts, which tie up the\naccount holder’s money for a predetermined period of time. NOW accounts looked\nfor all the world like interest-bearing demand deposit accounts, but were\ntechnically term deposit accounts.\n\nWe know the hacker who invented the NOW account: Ronald Haselton, president and\nCEO of the Consumer Savings Bank in Worcester, Massachusetts. Haselton is said\nto have overheard a customer asking why she couldn’t write checks from her\nsavings account. He began to wonder the same thing, and hacked the Regulation Q\nrules to create what was in effect the first interest-bearing checking account.\n\nModern certificates of deposit, or CDs, were another example of an innovative\nbanking hack. The hack involved recruiting a securities dealer to create a\nsecondary market in CDs and thereby make them attractive to corporate accounts.\nThe hackers who dreamed up the scheme were employed by First National City Bank,\nnow Citicorp. In 1961, the bank introduced negotiable certificates of deposit,\nwhich paid a higher interest rate than that allowed for interest-bearing\naccounts, and five years later introduced them to the London market. Shortly\nthereafter, First National City Bank reorganized as a holding company in order\nto avoid bank regulations that would prevent it from issuing CDs at higher\nrates. Congress fixed the hack by amending the Bank Holding Company Act of 1956,\nwhich put the Federal Reserve Board in charge of oversight and regulation of\nbank holding companies.\n\nOther banking hacks of the mid-twentieth century include money market funds and\nEurodollar accounts, both designed to circumvent regulatory limits on interest\nrates offered on more traditional accounts.\n\nThese hacks all became normalized, either by regulators deciding not to close\nthe loopholes through which they were created or by Congress expressly\nlegalizing them once regulators’ complaints began to pile up. For example, NOW\naccounts were legalized, first in Massachusetts and New Hampshire, then in New\nEngland in general, and finally nationwide in 1980. Many of the other\nlimitations imposed by the Bank Holding Company Act were repealed with the\npassage of the Riegle-Neal Interstate Banking and Branching Efficiency Act of\n1994. This was all part of a huge wave of banking deregulation that continued\nwell into the 2000s.\n\nThat’s the basic model, and we’ll see it again and again. The government\nconstrains bankers through regulation to limit the amount of damage they can do\nto the economy. Those regulations also reduce the profit bankers can make, so\nthey chafe against them. They hack those regulations with tricks that the\nregulators didn’t anticipate and didn’t specifically prohibit and build\nprofitable businesses around them. Then they do whatever they can to influence\nregulators—and government itself—not to patch the regulations, but instead to\npermit and normalize their hacks. A side effect is expensive financial crises\nthat affect the populace as a whole.\n\nThe hacking continues today. The 2010 Dodd-Frank Wall Street Reform and Consumer\nProtection Act was passed in the wake of the 2008 Global Financial Crisis, and\nwas intended to be a sweeping overhaul of the financial regulatory system.\nDodd-Frank included a variety of banking regulations intended to create more\ntransparency, reduce systemic risks, and avoid another financial meltdown.\nSpecifically, the act regulated derivatives, which were often abused and were a\nmajor contributing factor to the 2008 financial crisis.\n\nDodd-Frank was filled with vulnerabilities. Banks immediately set their lawyers\nto work searching for hacks that could bypass the intent of the law—risk to the\neconomy be damned. First, they seized on the specific wording that exempted\nforeign activities unless they had “a direct and significant connection with\nactivities in, or commerce of” the United States. Once that vulnerability was\nclosed, they split hairs on the definition of an overseas “branch” versus an\noverseas “affiliate.” That didn’t work for long, either. Finally, they zeroed in\non the word “guarantee.” Basically, all of these foreign derivatives were\nguaranteed by the US parent company, meaning they would cover the losses if\nsomething happened to the overseas affiliates. By simply removing the word\n“guarantee” and other equivalent terms from their contracts, they could avoid\nregulation.\n\nBy the end of 2014, banks had moved 95% of their swap trades offshore, to more\nlenient jurisdictions, in another hack to escape Dodd-Frank regulation. The\nCommodities Futures Trading Commission tried to close this loophole in 2016. It\nruled that swaps couldn’t be sent abroad to evade Dodd-Frank, and that both\nguaranteed and nonguaranteed swaps would be covered by the parent company. But\nthe new rule wasn’t finalized before President Trump came into office, and his\nappointed chair to the commission never bothered.\n\nOther hacks centered around the Volcker Rule, another part of Dodd-Frank that\nprohibits banks from carrying out certain investment activities with their own\naccounts and simultaneously limits their interactions with hedge funds and\nprivate equity funds. Banks quickly realized they could flout this rule if the\nmoney didn’t originate from their own accounts. This meant they could establish\nvarious partnerships and invest through them. This rule was rescinded during the\nTrump administration—making many of the hacks no longer necessary. Finally,\nbanks realized that they could avoid all of the Dodd-Frank rules around “trading\naccounts” by claiming they were for something called “liquidity management.”\n\nBanking hacks illustrate another thing we’ll see repeatedly. Banks and\nregulators play an unending game of cat and mouse. Regulators are tasked with\nlimiting irresponsible, aggressive, corrupt behavior. Banks are motivated to\nmake as much money as possible. Those two goals are opposed to each other, so\nbanks hack the regulatory system wherever and whenever possible. Any bank that\nchooses not to do so will be overtaken by those that do.\n\nThe obvious security fix—patching—is stymied by the industry’s aggressive push\nfor normalization. This is accomplished through lobbying and also through\nregulatory capture: the common tendency for a regulatory agency to become\ndominated by the industry it is regulating, and to begin functioning in ways\nthat benefit the industry rather than the public interest. The banking industry\nalso does this by hacking the legislative process itself. The financial services\nindustry spent $7.4 billion on lobbying between 1998 and 2016, with banks alone\nspending at least $1.2 billion.\n\nIf patching isn’t a viable solution, we have to find vulnerabilities before\nthey’re hacked—and, more importantly, before they become entrenched in the\nunderlying system and lobbyists start pushing for them to be normalized. In\nfinancial systems, government agencies could engage in red-teaming by hiring\naccountants and attorneys to study the systems as they evolve, and to improve\nregulations while they are still in draft.\n\nSome countries—including the United States, at least for some agencies at some\ntimes—already do this sort of thing, with public comment processes for proposed\nregulations. The idea is to look for ways in which the rules can be hacked or\nways in which near-term technological advancements could change how the rules\ncould be hacked, then patch the text right away. This doesn’t completely\neliminate the problems of regulatory capture or legislative lobbying, but at\nleast these powerful hackers aren’t losing something when a loophole is closed.\n\nOn the other hand, lobbyists can abuse the comment process to pressure\nregulators to leave loopholes alone, or even to create new loopholes where there\nweren’t any before. Creating a governing system like the comment process just\nshifts hackers’ attention from the target itself to the target’s governing\nsystem, which must be wary and nimble to avoid becoming just another soft\nunderbelly for attackers to exploit."},{"title":"Test Section Title","content":"18\n\nHacking Financial Exchanges\n\nStock markets, commodities exchanges, and other financial trading systems are\nalso ripe for hacking. This has been true since their beginning, and it’s even\nmore so as those systems have become computerized and automated.\n\nHackers in this domain target information. When a financial exchange is working\nproperly, traders with better information get better results because they buy\nlower and sell higher. Hacks subvert this mechanism in two basic ways. First,\nthey leverage not-yet-public information to make lucrative trades before anyone\nelse. Second, they disseminate false information that drives the market, then\nmake profitable trades before everyone else realizes that they’re being duped.\nBoth of these hacks subvert market fairness: the notion that investors have\nequal access to information about the market.\n\nThe most obvious hack of the first type is insider trading, illegal for so long\nthat it’s not even a hack anymore. Generally, insider trading involves buying or\nselling a security on the basis of nonpublic information. The trader could be a\nCFO who knows his company’s sales figures before they’re disclosed, the PR\nperson writing the financial report, or the printer who reads that report before\nit’s published. The harms of insider trading are twofold: (1) it comes at the\nexpense of everyone else who doesn’t have the critical information, and (2) it\nleads people to mistrust the fairness of the market system.\n\nIn the US, insider trading was criminalized by the Securities Exchange Act of\n1934, affirmed and refined over the years in US Supreme Court rulings. In 2021,\nthree people were charged with insider trading for buying stock in the Long\nIsland Iced Tea Co. just before it changed its name to the Long Blockchain Co.\nfor no other reason than to ride the then-frenetic blockchain hype. A rule that\nhas lasted for this long is a clear example of a successful systems patch.\n\nIt’s actually impressive that these prohibitions have survived almost ninety\nyears of hacking and regulatory inertia. If there’s a general lesson here, it’s\nthat a broad rule enables a more robust, adaptable, and resilient regulatory\nregime. The simplicity of a rule minimizes vulnerabilities in the law’s design.\n(We saw how vulnerable the complex Dodd-Frank law is.) According to former\nSecurities and Exchange Commission (SEC) chairman Arthur Levitt, “greater\nspecificity would give the legal fraternity various ways of getting around those\nspecifics. [The SEC and Justice Department] want these laws purposely vague to\nsee to it they have the maximum leverage in terms of bringing cases.” The\ninsider trading rules are deliberately broad to prevent further hacking\nattempts.\n\nFront running is yet another hack that leverages secret information. If you’re a\nbroker, and you know about a big trade that’s about to happen, you can make a\nsmaller trade for yourself immediately beforehand. Then you execute your\nclient’s trade. It moves the market, and you make an instant profit for\nyourself. Like insider trading, this has been declared illegal.\n\nSome hacking of financial markets and networks will target informational systems\nsurrounding those networks. For example, in 2015, the SEC indicted two Ukrainian\nhackers who broke into Business Wire and PRNewswire’s networks and stole more\nthan 100,000 unreleased press releases for publicly traded companies. These were\nthen distributed to a network of traders, who used the advance knowledge to\nplace informed bets on the authoring companies’ stocks, much like an insider\ntrading scheme.\n\nThe second type of hack involves the creation of disinformation. An old example\nis the pump-and-dump. Perpetrators buy a stock, preferably an obscure one. (The\npenny stock market is notorious for pump-and-dumping.) Then, they recommend the\nstock to others, using false and misleading statements about the potential\nprofit to be made. If others fall for the scam and purchase the stock, it\ninflates the price and the perpetrators sell. Traditionally, this scheme\ninvolved calling potential investors on the telephone. Today, it more often\ninvolves online trading message boards, social media groups, and spam emails.\nWhether it’s ringleaders on the Reddit finance forum r/WallStreetBets pushing\nretail investors to send GameStop’s price “to the moon” or Elon Musk tweeting\nabout his bitcoin buys to millions of online followers, investors can use online\ncommunications to manipulate investor expectations and produce asset bubbles for\ntheir own profit (and others’ loss) with unprecedented speed and scale. The\nadvent of online trading has made this particular hack even more profitable.\nMostly, pump-and-dump is illegal, and there are heavy fines if you get caught.\nOn the other hand, prosecution can be difficult. Neither Musk nor anyone\ninvolved with the 2021 GameStop trading frenzy has been prosecuted.\n\nSpoofing is another hack that involves the dissemination of disinformation.\nHere, a trader places millions of dollars of orders, then cancels them after\nother traders have noticed and reacted to them. This, too, is illegal, and a few\npeople have been convicted of it.\n\nFake news—that is, deliberately deceptive reports masquerading as journalism—is\nanother increasingly prevalent method of hacking the market through\ndisinformation. This hack is most often used to misrepresent companies’\nvaluation, allowing hackers to profit from fluctuations in their share prices.\nIn 2015, for example, a fake version of Bloomberg.com was used to spread news of\na $31 billion offer to buy Twitter, causing Twitter’s stock to surge as the\nstory spread, and hackers in the know sold Twitter shares at artificially\ninflated prices. The fake site was designed similarly to the real Bloomberg.com\nsite, and used a similar URL. Fake press releases, fake reporters, fake tweets,\nand even fake SEC filings have also been used with similar success. The SEC\nviews all of this behavior as illegal.\n\nIf you stop to think about it, disinformation is less a hack of the financial\nnetwork and more a hack of other traders. It’s an attempt to influence behavior.\nThese are really hacks of our cognitive systems.\n\nOther hacks of financial changes involve finding new ways to reduce risk, often\ninvolving loopholes in financial regulations. Hedge funds have been doing this\nsince their inception in the 1960s, first by “hedging”—or offsetting—risks\nagainst each other, then by using diverse investment strategies, then by\nengaging in computer-assisted trading.\n\nThe very existence of hedge funds relies on hacking the financial regulatory\nsystem. Since their inception, hedge funds have been protected by a series of\nlegislative loopholes that exempt them from SEC oversight. Because they only\naccept high-net-worth and institutional investors as clients, hedge funds are\nexempt from oversight under the Securities Act of 1933, which is designed to\nprotect individual buyers in the market. By toeing the line on criteria outlined\nin the Investment Company Act of 1940, hedge funds exempt themselves from bans\non investment techniques that are applied to registered investment\ncompanies—most notably, shorting. In 2010, the Dodd-Frank Act brought hedge\nfunds under the oversight of the SEC, but they remain largely unregulated. Hedge\nfunds have become a normal part of the financial system.\n\nOver the decades, hedge funds have taken advantage of one legal loophole after\nanother. Sometimes the loopholes are closed after their discoverer makes a lot\nof money. Sometimes the rules are changed to legitimize the hack. Most of the\ntime they are just used, and eventually accepted as normal. The people who run\nhedge funds aren’t necessarily smarter than everyone else. They just understand\nthe system better, and are able to find vulnerabilities and craft exploits to\ntake advantage of them. Since the people who understand the system best are the\npeople profiting from the hacks, it’s unlikely there will be much patching done\nanytime soon.\n\nThis is all relatively complex hacking, against multiple systems at multiple\nlevels of generality. Some hacks operate at the technical level: spoofing and\nfront running are hacks that make use of computer speed and automation. Some\noperate at the level of the financial markets. Some operate at the legislative\nlevel: vulnerabilities in securities laws, for example. This is all a microcosm\nof the hacks that will be described in chapters to come."},{"title":"Test Section Title","content":"19\n\nHacking Computerized Financial Exchanges\n\nToday, financial exchanges are all computerized, and the rise of computerization\nhas led to all sorts of novel hacks. Front running, for example, is now much\neasier to implement and much harder to detect. Tying automated trading to\n“sentiment analysis”—so that trading programs buy when a stock becomes a meme or\nsell when bad news goes viral—can make pump-and-dumps and smear campaigns much\nmore profitable. But the most virulent of all modern exchange hacks is\nhigh-frequency trading, or HFT. Instead of making use of true, albeit secret,\ninformation or disseminating disinformation, HFT exploits public information at\nlightning speed.\n\nHFT is a form of algorithmic trading that exploits the price differentials that\noccur when large trade orders are placed, usually by pension funds or insurance\ncompanies. (These massive orders can have a significant impact on stock prices.)\nHFT algorithms detect these orders, as well other events that are likely to\naffect stock prices, and then profit from them. These trades are called “high\nfrequency” because they try to “buy low and sell high” on minuscule price\nfluctuations at lightning speed. Often trades are made in milliseconds or\nmicroseconds, and firms vie for server space physically close to exchanges to\nmaximize Internet speed. Just as dogs can hear frequencies that are too high for\nhumans to hear, high-frequency trading algorithms can recognize and react to\npatterns far too subtle for humans to notice.\n\nThis is a hack. If we assume that the intent of a market is for buyers and\nsellers to exchange money and goods at prices each finds individually\nbeneficial, then HFT hacks that intent. If we believe that all agents in a\nmarket should have equal access to market information in order to make their\ninvestment decisions, then HFT is a hack. Basically, HFT uses inhuman reflexes\nto make tiny bits of money on the random noise of the system as it operates.\nIt’s an artifact of the computer systems used to facilitate trading. It is\ndefinitely unintended and unanticipated by the market’s designers. It definitely\nsubverts the goals of the system for private gain. It is definitely parasitical.\n\nEven worse than its inherent unfairness, HFT introduces new risks and new\nvolatility into the system. In 2010, the US stock markets crashed rapidly,\nlosing over a trillion dollars in value over the course of thirty-six minutes\nbefore rebounding. No cause was ever discovered, but the magnitude of the crash\nwas exacerbated by HFT. In 2012, the Knight Capital Group lost $440 million\nthrough a flaw in new software that controlled HFT. As these events show, HFT\nand autonomous trading systems can be more risky than typical trading by human\ntraders simply because of their speed and volume. And HFT clearly disadvantages\nthose who don’t have access to algorithmic trading systems.\n\nUnlike some of the other hacks in this section, and in spite of its gross\nunfairness, HFT has been normalized. In the US, the Financial Industry\nRegulatory Authority has imposed some basic regulations designed to increase\ndisclosure of the methods underlying algorithmic trading systems; the EU has\nsimilar rules. Neither is doing much to slow the practice. At its high point in\n2009–2010, 60% to 70% of US trading was attributed to high-frequency trading.\nAnd while individual humans can contract with an HFT broker to have their own\ncomputer algorithms run for them, professional HFT traders will do it faster and\nbetter—to the disadvantage of others. HFT firms can pay extra to see pending\norders a split second before the rest of the market does—another unfair\nadvantage.\n\nTaking advantage of typos is yet another market hack that operates at computer\nspeeds. Typos are not uncommon in computerized trading systems. The large\nfailures make the news, like the time that a Japanese company, Mizuho Securities\nCo., lost $225 million on a stock trade when an employee accidentally made a\n“transposition error,” listing 610,000 shares at 1 yen apiece instead of one\nshare for 610,000 yen. Or the time a junior trader at Deutsche Bank accidentally\nsent a hedge fund $6 billion in what’s known as a “fat-finger error.” Or the\ntime that a trader on the Tokyo Stock Exchange lost $617 billion in stocks by\npressing the wrong button and canceling forty-two separate transactions at\nonce—more fat fingers at work.\n\nNone of those are hacks; they’re just mistakes. The hack lies in deliberately\nplacing crazy buy and sell orders in the hope of profiting from others’ clerical\nerrors. It costs nothing to make an offer, so a hack might involve continually\nflooding the market systems with wildly unrealistic offers. Almost all of them\nwill expire unfulfilled, but once in a very great while one gets paired with\nsomeone else’s mistake, resulting in an enormous profit.\n\nOkay, so what about defenses? The flexibility of financial rules means that\npatching is a viable solution. That’s because financial rules are deliberately\ndrafted broadly and provide a lot of room for enforcement discretion. Courts and\nregulators can quickly and easily ban or regulate new practices just by\nreinterpreting or clarifying existing law. Even so, the ability of hackers to\nnormalize their practices limits patching’s effectiveness.\n\nHere is probably a good place to employ secure systems design. We can design our\nfinancial systems to reduce the volatility that comes from high-frequency\ntrading. Already many markets have “circuit breakers” that automatically halt\ntrading temporarily if stock prices change by a certain percentage. We could do\na lot more. For example, we could require all trades to be executed once per\nsecond—or ten seconds—and all at the same time. Or we could build systems that\nautomatically detect dangerous HFT trades, and either delay their execution or\ncancel them entirely. But any design changes require regulators to go against\nwhat powerful investors want. It took fifty years for the pope to redesign\nindulgences after Martin Luther’s theses; surely we don’t have to wait that\nlong."},{"title":"Test Section Title","content":"20\n\nLuxury Real Estate\n\nIn London, New York, Vancouver, and many other major cities worldwide, the\nluxury real estate market doesn’t behave like it used to. It’s not about rich\npeople buying homes, or even second homes. It’s a money-laundering machine.\n\nHere’s the hack: If you’ve got millions of shady dollars (or rubles), you can’t\njust deposit it in a checking or investment account. The government requires\nthose institutions to ask you too many nosy questions and to file a Suspicious\nActivity Report if your answers don’t make sense. But there’s a vulnerability,\nand that’s in real estate. In many countries, regulations surrounding real\nestate purchases are nowhere near as onerous as those pertaining to banks and\nfinancial markets. Banks are required to screen customers to help prevent fraud\nand money laundering, but those rules don’t apply to foreign shell corporations\nthat engage in real estate transactions. Brokers and sellers don’t question your\nquestionable cash, because the government doesn’t require it. Once you notice\nthe vulnerability, the hack is obvious.\n\nFirst, you purchase a superexpensive condo in a city where you have no intention\nof living. You make the purchase through a shell company to obscure your\npersonal involvement (technically called “beneficial ownership”). You then use\nthat property as collateral to qualify for bank loans. The money you borrow is\nclean, and you can invest it more conventionally, in the stock market or\nelsewhere, without running afoul of the regulations surrounding those systems.\nYou really don’t care if the condo appreciates, since you didn’t buy it for that\npurpose. Still, it’s a plus if prices rise, since that creates more against\nwhich to borrow. You don’t rent the property, since that would devalue the\nproperty, no matter how good your tenants might turn out to be.\n\nThis is how Andrey Borodin, having fled Russia on charges of defrauding his own\nbank, ended up owning a £140 million flat in London. He’s not alone. A 2015\nreport from Transparency International identified 160 UK properties, together\nworth £4.4 billion, all owned by what they called “high-corruption-risk\nindividuals.” Cities like New York and Miami are filled with untenanted luxury\ncondominiums. One luxury building examined by the New York Times had 80% of its\nunits owned by shell corporations in 2014.\n\nThis same trick works even if you’re not trying to launder your money, albeit\nnot as well. Real estate is still a good way to park money and acquire\ncollateral, and rising real estate prices still increase the property owner’s\nborrowing power.\n\nAll of this explains a seemingly odd feature of the luxury real estate market:\nwhy so many sellers choose to not sell their properties instead of lowering\ntheir asking prices to something the market can more reasonably bear. As long as\nthere’s no actual sale at the lower price, the asset doesn’t have to be\ndevalued. Pretty much everyone involved in luxury real estate prefers that\noutcome.\n\nThis directly damages the real estate market for people who want to live in the\nneighborhoods where this is prevalent. It also destroys the commercial real\nestate market in these neighborhoods, because there are fewer people around.\nRetail stores in neighborhoods like Mayfair in London have collapsed, because\n30% of the homes are vacant due to offshore money launderers.\n\nThe fixes are as obvious as the vulnerability: regulatory changes that bring\nreal estate in line with other financial systems. In 2016, the US Treasury\nDepartment implemented a pilot program in twelve cities (known as a “geographic\ntargeting order”) requiring LLCs to reveal their beneficial owners when they are\ncreated. This resulted in a 70% drop in cash purchases of real estate by LLCs.\nThis requirement could be made permanent and nationwide; in fact, geographic\ntargeting orders have recently been renewed and expanded to encompass new real\nestate markets. The federal government could extend the banking “Know Your\nCustomer Rule” to include shell companies’ beneficial owners. And the federal\ngovernment could get rid of the “temporary exemption” from detailed customer\nscrutiny for real estate that lobbyists were able to insert into the 2001\nPATRIOT ACT, as it now seems to be permanent.\n\nThere is, however, no political appetite to change the regulations—although\nRussia’s invasion of Ukraine may change that in the UK. The reason for inertia\nin this field, of course, is power. There are a whole slew of industries—real\nestate development, construction, and so on—that benefit from the unregulated\nsale of luxury real estate. And there are few people in power who would benefit\nfrom the change. Raising tax revenue, improving housing affordability,\nincreasing available stock of existing housing, and reducing money-laundering\ncapability: those are all things the rest of us want.\n\nToday, money laundering through real estate is so much business-as-usual that it\nbarely qualifies as a hack anymore. And I could tell a similar story about\nexpensive art. There’s a hack that involves buying a piece of art cheaply,\ngetting it appraised very highly, then donating it to a museum for the tax\nwrite-off. And society is harmed by the loss in tax revenue."},{"title":"Test Section Title","content":"21\n\nSocietal Hacks Are Often Normalized\n\nWhen we think of hacks, we imagine that they’re quickly blocked—that is,\npatched—by the system designers. This is what generally happens with computer\nhacks. I’m writing this paragraph in May 2022, and here are three\nvulnerabilities that recently appeared in the press:\n\n•Cisco announced multiple vulnerabilities in its Enterprise NFV Infrastructure\nSoftware. One vulnerability could allow an attacker to jump from a guest virtual\nmachine to the host machine, and thereby compromise the entire host network.\n\n•Cloud security company F5 warned its customers of forty-three vulnerabilities\naffecting four of its products. One “may allow an unauthenticated attacker with\nnetwork access to the BIG-IP system through the management port and/or self IP\naddresses to execute arbitrary system commands, create or delete files, or\ndisable services.”\n\n•AVG Corporation announced details of two high-severity vulnerabilities in its\nantivirus products that had been lurking in the code since 2012. Both flaws\ncould enable attackers to disable security software or tamper with a client’s\noperating system.\n\nIn every case, the vulnerability was discovered by researchers or the\nmanufacturer itself, privately disclosed to the system designers, patched by the\ndesigners, and only afterwards published along with the fact that the system was\nno longer vulnerable.\n\nIn computer security, we have a name for this: “responsible disclosure.” The\nopposite of that is a “zero-day vulnerability.” This is a vulnerability that is\nfirst discovered in secret, by criminals, governments, or hackers that sell to\ncriminals or governments—and the organization in charge of the system doesn’t\nlearn about it until it’s used in the wild. No one receives any advance warning\nin those cases.\n\nThere was no responsible disclosure with any of the hacks we discussed in\npreceding chapters, nor with most of the other examples throughout this book. In\nnoncomputer systems, that’s more normal. When a hedge fund manager discovers a\nprofitable hack against a financial system, he doesn’t alert the regulator so it\ncan get fixed. He uses it to his advantage until a government body forces him\nnot to.\n\nThis is the process more generally. First, a vulnerability is discovered, and\nused in an exploit to hack the system. Eventually, it becomes more popular. This\ncan happen slowly or quickly, depending on the hack and what it does and how\nprofitable it can be, the pervasiveness of the system being hacked, how quickly\nknowledge of the hack spreads, and so on. At some point, the system’s governing\nbody learns about the hack. That governing body can do one of two things. One,\nit can modify the rules of the system to prevent the hack, patching the system.\nOr two, it can incorporate the hack into the system, essentially normalizing it.\nAfter normalization, the hack sometimes dies a natural death once everyone does\nit and any competitive advantage is lost.\n\nThe history of financial hacks is a history of normalization. Someone invents a\nhack and makes a huge amount of money. Others copy that individual and also reap\nwindfalls. Then the regulators notice and step in. Sometimes they declare the\nhack illegal and convict the hackers. But most of the time, they retroactively\napprove the hacks. At that point, they’re no longer hacks but just a normal part\nof finance. That normalization process doesn’t always happen deliberately. As\nwith hedge funds, some hacks are just ignored and, through inaction, passively\nnormalized.\n\nThis can be a positive—some of these hacks, like NOW accounts and CDs, are\ninnovations in finance—but there is a cost. Many hacks in the preceding chapters\nsubvert the fairness of the market by targeting information, choice, or agency.\nThey’re not so much innovative as subversive. Their normalization testifies to\nthe power of wealthy individuals to have their way at the expense of everyone\nelse.\n\nNormalization isn’t a new phenomenon, and neither is the cat-and-mouse game\nbetween hackers and regulators. In the Middle Ages, both Catholic and secular\nauthorities had very strict restrictions on interest-bearing loans because they\nwere regarded as sinful. As banking developed as a profession, wealthy bankers\navoided those restrictions through a series of increasingly sophisticated\nmethods. This included fudging the record books, misleadingly classifying a\nprohibited usurious loan as a permitted one, and disguising the interest on a\nloan as a gift from the borrower. One hack was a “dry sea loan,” which turned a\nprohibited loan into an allowed “sea loan” by linking it to arbitrary sea\nvoyages.\n\nThe response to those medieval usury hacks echoes everything in this chapter.\nBetween the twelfth and fourteenth centuries, the Catholic Church updated its\nusury regulations to combat new financial innovations such as the dry sea loan,\ncreated more sophisticated enforcement mechanisms, and increased the prescribed\npunishments for convicted usurers. But the rich have a way of protecting their\nprofit sources. Wealthy guilds had the resources and expertise to create\nfinancial products that successfully evaded Church scrutiny. And a form of\nregulatory capture took place, whereby the Church would accept donations and\nfinancial restitution from usury violators, incentivizing a conditional\nacceptance of usury. Modern banking was essentially born in 1517 at the Fifth\nLateran Council, an example of normalizing a beneficial hack. If you’ve ever\nbought a house through a mortgage, financed a college education, or started a\nbusiness with a loan, you have this normalization to thank. (The council also\nlegalized pawn shops, in case you’ve benefited from that system as well.)\n\nNormalization seems to be common today. I’m sure most high-frequency trading\nhacks would have been declared illegal if they had been invented a hundred years\nago. I’m equally certain insider trading would be legal if it had been invented\nin recent decades."},{"title":"Test Section Title","content":"22\n\nHacking the Market\n\nFrom 2010 to 2014, Goldman Sachs owned an aluminum storage company with\ntwenty-seven industrial warehouses in the Detroit area. Several times a day,\ntrucks would shuffle 1,500-pound bars of the metal among the warehouses, loading\nit at one warehouse and unloading it at another. Every day.\n\nIt was a hack, of course. The way the spot price for aluminum is calculated\ndepends in part on the amount of time customers have to wait between purchase\nand delivery. This continual shuffling of aluminum affected that price, and\nsince those twenty-seven warehouses stored over a quarter of the country’s\naluminum supply, Goldman Sachs’s legal dance let it manipulate the price to its\nown advantage.\n\nThis is a hack that is simply not available to people without the wealth of a\nGoldman Sachs. Money is what primes a market economy for hacking, and it’s the\nwealthy that benefit from it.\n\nMarket hacks exploit vulnerabilities in the process by which we make and sell\ngoods and services; that is, the normal logic of supply and demand, consumer\nchoice, how businesses enter and leave the market, and what kinds of products\nget offered in the first place.\n\nMarket capitalism—the free market—is an economic system with unique advantages\nover the mercantile system it replaced. In contrast to central planning systems\nlike communism, market capitalism is not controlled by any one entity.\nIndividuals make individual decisions in their own best interest, capital flows\nwhere it can be used most profitably, and out of that chaos an efficient market\nemerges, at least in a perfect world.\n\nThe fundamental mechanism that makes this all work is self-interested buyers\nmaking intelligent decisions among competing sellers. The rules of the market\nare intended to keep that basic mechanism functioning and to prevent the system\nfrom causing greater damage. These include laws you would expect, like\nprohibitions against deceptive trade practices and unsafe working conditions, as\nwell as laws you might not immediately think of, like contract enforcement,\nnational currencies, civil courts for dispute resolution, and so on.\n\nMarkets need three things to be successful: information, choice, and agency.\nBuyers need information about products and services in order to make intelligent\nbuying decisions: their merits and problems, their prices, their specs, and so\non. Buyers need to have multiple sellers from which to choose, otherwise there\nis no competition to control prices and spur innovation. And buyers need the\nagency to use their knowledge about different buyers and to choose between them.\nAll three of these market elements have been successfully hacked:\n\n•Complex product offerings obscure information. Just try, for example, to\ncompare prices of different cell phone programs, credit cards, or stock\nprospectuses. The obfuscation, and resultant confusion, makes it harder for\nbuyers to intelligently choose between alternatives. To some extent this arises\nfrom the natural complexity of our high-tech world, but to another extent it is\na deliberate hack designed to impede users’ access to accurate information.\n\n•Monopolies eliminate choice. Monopolies aren’t new, and pre-capitalism they\nweren’t a hack. But in a market system composed of sellers competing for buyers,\nthey subvert the market mechanism. Adam Smith wrote about this in 1776,\nexplaining that the economic interests of businessmen are often misaligned with\npublic interests. The goal of businessmen—and, of course, business\nenterprises—is to maximize profits. The goal of the public is to (more or less)\nmaximize product quantity, quality, variety, and innovation, and minimize\nprices. Lack of competition means that sellers no longer fear losing buyers, and\nthus have no incentive to provide any of those things the public wants.\n\n•Lock-in reduces our agency to freely choose among competing products. Someone\nmight drink a Coke today, and if it doesn’t appeal to him, he can drink a Pepsi\ntomorrow. But if that same person has a bad experience today with his cell phone\nplan, or email provider, or credit card, he’s probably still going to have the\nsame cell phone plan, email provider, and credit card tomorrow. The cost to\nswitch, in money, time, convenience, or learning, is just higher. That’s\nlock-in. And the hack part comes from all the different ways of enforcing\nlock-in: proprietary file formats that make it much more expensive to switch\naudio players or book readers, customizations that make it harder for you to\nswitch business applications, social networking sites that won’t let you\ncontinue to access your friends’ accounts if you delete your own, or apps that\ndon’t let you take your data with you when you leave.\n\nThe result of all this is greater profits for the companies, at our expense,\nthrough hacks of the market system.\n\nRegulation can be used to limit these market failures. Deregulation, by its\nnature, removes impediments to action. It allows for more hacks, by basically\npreapproving them before anyone can see them or their effects. This is, of\ncourse, both good and bad. It’s good in that innovations can quickly be\nimplemented. And it’s bad in that subversions can be implemented just as\nquickly.\n\nHistorically, at least in the US, we have prioritized innovation and the\nminimalist regulatory structure that enables that. This has largely worked,\nsimply because the amount of damage a bad hack could cause was contained. Today,\ndue to both the power of technology and the global nature of our economies,\nthat’s no longer true. An economic system based on greed and self-interest only\nworks when those properties can’t destroy the underlying system. And “Move fast\nand break things”—Mark Zuckerberg’s famous motto for Facebook—is only okay when\nit’s your own things you’re putting at risk. When someone else’s things are\ninvolved, then maybe you should think twice—or be forced to fix what you’ve\nbroken."},{"title":"Test Section Title","content":"23\n\n“Too Big to Fail”\n\nThe phrase “too big to fail” captures a critical vulnerability in our market\neconomy. If you are so large that your failure is a systemic risk to the\neconomy, you are free to take bigger risks because you know you won’t be allowed\nto fail. The idea is captured in an old quote widely attributed to J. Paul Getty\n(though probably first said by John Maynard Keynes): “If you owe the bank $100,\nthat’s your problem. If you owe the bank $100 million, that’s the bank’s\nproblem.” That’s “too big to fail” in a nutshell.\n\nIn more detail: some corporations are too critical to the functioning of our\neconomy to be allowed to fail. They have become too large and too essential, and\nif they become too unprofitable, it is cheaper for the government to bail them\nout than to allow them to fail.\n\nRecall that the overarching mechanism of the market is sellers competing for\nbuyers; successful sellers thrive and unsuccessful ones wither. Imagine an\nordinary businessperson or organization considering a risky decision. They must\nweigh the benefits of success with the costs of failure, and their eventual\ndecision will consider both. Directors of an enterprise deemed too crucial to\nfail, on the other hand, know that the inevitable costs of any poor decisions\nthey might make will be paid by taxpayers: that is, by society as a whole. This\ncreates moral hazard and incentivizes risky decision-making. If they’re\nsuccessful, they’ll win. And if they’re unsuccessful, they’re protected from\nloss. “Too big to fail” is an insurance policy against bad bets. It drastically\nperturbs our market system. It’s a distortion fueled by money and power. And\nit’s a hack.\n\nIn the aftermath of the 2008 financial crisis, the US government bailed out\nseveral major Wall Street banks and other financial institutions after their\nmanagers made years of bad business decisions. This was done through the\nTroubled Asset Relief Program, which authorized the government to purchase\nfloundering companies’ assets and stock, including mortgage-backed securities.\nIt was thought that the $700 billion bailout was essential to protect the\noverall US economy. The fear was that absent a bailout, it would all collapse.\nAnd it would have cost the government far more than $700 billion to pay for\ngovernment relief programs in proportion to the recession’s severity. (In\neconomic recessions, government revenues decline because people earn less and\npay less taxes, and government spending increases on programs like unemployment\ninsurance. In short, recessions become more costly as they become more severe.)\n\nThis isn’t the first time the US government bailed out “too big to fail”\ncompanies. The Federal Deposit Insurance Corporation was created in the 1930s,\nfollowing a torrent of bank failures, in order to monitor banks and protect\nconsumer deposits. In 1979, the government bailed out Chrysler Corporation. It\nwas a smaller bailout—only $1.5 billion—but the justifications were similar.\nNational security was invoked; the company was building the M1 Abrams tank\nduring the height of the Cold War. The economy was invoked; it was necessary to\nsave 700,000 jobs in Detroit and beyond. And the US was in the middle of an\nautomotive trade war with Japan. The bailout was successful; Chrysler paid the\nloan back early and with interest.\n\nThe “too big to fail” hack essentially results from a change in the threat\nmodel. When the mechanisms of the market economy were invented, no business\ncould ever be so critical to the entire economy that its failure would\nnecessitate government intervention. This was partly due to size, but also\nbecause critical social functions were not privatized in the same way. Sure,\ncompanies could grow, but none would grow at such a scale. That level of growth\nrequires modern technologies.\n\nAttempts to regulate super-sized enterprises have been lukewarm at best,\nprimarily because of the lobbying power of those enterprises, which generally\nresist oversight. The 2010 Dodd-Frank banking reforms reduced the threat of “too\nbig to fail” institutions, but those were mostly rendered ineffectual as the\nbill made its way through Congress, or were neutered in subsequent tax reform\nlegislation.\n\nOne way to protect against the “too big to fail” hack is to not bail out the\nmega-corporations directly. The US government had at least two other courses of\naction in 2008. It could have conditioned any bailouts on restructuring\nmortgages to eliminate what was a wave of defaults. And it could have bailed out\nthe big banks only if they passed the money on to the borrowers. Both were\nrejected by then National Economic Council director Larry Summers. The 2008 bank\nbailouts provide another example of how wealth protects hacks used by the\nwealthy.\n\nThe most effective way to secure an economic system against companies that are\ntoo big to fail would be to ensure that there aren’t any in the first place. In\n2009, sociologist Duncan Watts wrote an essay: “Too Big to Fail? How About Too\nBig to Exist?” He argued that some companies are so large and powerful that they\ncan effectively use the government as insurance against their risky business\ndecisions, with taxpayers left holding the bag.\n\nHacks like these exemplify three attributes that we’ll revisit later on in the\nbook. First, “too big to fail” is generalizable. As big banks, real estate, and\nother “essential” sectors of the economy recognize that they are able to employ\nthe “too big to fail” hack, the market economy as a whole becomes vulnerable to\nenterprises that expand unsustainably. Second, hacks can be systematized and\nreshape decision-making: the bailouts in 2008 codified “too big to fail” into\nlaw. By demonstrating that the federal government was willing to bail out the\nbanking, real estate, and automotive sectors, Congress normalized the hack as\njust another part of the high-finance game. And third, the very concept of “too\nbig to fail” changes the incentives of those regulating the massive\norganizations, and consequently the organizations themselves.\n\nToday, I’m certain that companies view a “too big to fail” bailout as their\nultimate insurance policy. Certainly, the few organizations that were explicitly\nguaranteed bailouts through Dodd-Frank—Citigroup, JPMorgan Chase, Bank of\nAmerica, and Goldman Sachs—know that the government will bail them out again if\nneeded. It’s a hack that has been normalized, even though it’s incredibly\ndamaging to our market economy."},{"title":"Test Section Title","content":"24\n\nVenture Capital and Private Equity\n\nFood delivery apps rely on an unsustainable business model. In 2020, a pandemic\nyear when most of us stayed home, DoorDash lost $139 million and Grubhub lost\n$156 million. It’s hard to find numbers for Uber Eats, but Uber itself lost $6.8\nbillion—and that’s better than its $8.5 billion loss in 2019. And it’s\nunsustainable for individual investors, too; food delivery doesn’t work for\nanybody. The drivers—gig workers with no benefits or job security—are poorly\npaid. The services hurt restaurants: they’re not profitable for a whole bunch of\nreasons, they don’t bring in incremental sales, and a restaurant’s reputation\nsuffers when the delivery service screws up. Even the customers don’t fare well:\nthey’re hit with service fees and higher prices and suffer all sorts of delivery\nproblems. The only reason that this market even exists is that venture capital\nfirms like SoftBank are willing to pour tens of billions of dollars into it,\nhoping that someday they might capture enough restaurant industry profits to\nturn a profit of their own. This investment strategy is a hack: market\ncapitalism is supposed to use the uncoordinated collective wisdom of buyers to\ninfluence sellers. Venture capital funding prevents that from happening; it\ninhibits buyers’ agency.\n\nVenture capital (VC) as a funding model traces its origins back hundreds of\nyears but didn’t really take off until the 1980s. It was a key player in the\nrise of early tech companies and in the inflation and burst of the dot-com\nbubble in 2001. And it’s grown steadily since then: in 2010, the global venture\ncapital market was $50 billion; in 2019, it was $295 billion. I have personally\nbenefited from venture capital; I sold my first VC-backed company to BT in 2006,\nand my second to IBM in 2016.\n\nVenture capital itself is not a hack. The hack is when unprofitable companies\nuse VC funding to ignore the dynamics of the market economy. We don’t want some\ncentral planner to decide which businesses should remain operational and which\nshould close down. But this is exactly what happens when venture capital firms\nbecome involved. The injection of VC money means that companies don’t need to\ncompete with each other in the traditional manner, or worry about the normal\nlaws of supply and demand. They can do what would normally be crazy things—give\naway their products, pay extravagant salaries, sustain enormous financial\nlosses, provide a service that actually harms people—because of that external\nfunding source. It’s basically central planning by elite investors, something\nthat would be called communism if the government did it.\n\nUber has received $25.5 billion in VC funding since it was founded in 2009. The\ncompany hasn’t had a single profitable year. In 2019, the company lost $8.5\nbillion worldwide, or 58 cents per dollar on each of its 5.2 billion rides. The\nonly reason Uber exists at all is that there are still investors willing to pour\ncapital into this sinkhole, probably waiting for the time when driverless car\ntechnology allows the company to fire all of its drivers and operate a fully\nautonomous fleet.\n\nWeWork has also never turned a profit, losing over $10 billion in the past three\nyears. That particular VC-fueled bubble burst when the company tried and failed\nto go public in 2019. The COVID-19 work-from-home rules further hurt WeWork’s\nchances of success, and the company’s co-founder was ousted as CEO and chairman\nof the board. The only reason that WeWork ever grew so big is because it raised\n$12.8 billion of VC funding between its 2010 founding and the summer of 2019,\nand billions more since as debt relief.\n\nThese examples are not the same as bad investments or even fraudulent bad\ninvestments. Quibi was a venture-backed company that secured over $1.75 billion\nin funding pre-launch, touting the concept of ten-minute-or-less episodes of\ncontent, but shut down just six months after launch after minimal adoption.\nElizabeth Holmes founded and ran Theranos on venture capital without ever\ncreating a successful product, and eventually fleeced investors to the tune of\n$1 billion over several years. Those are both examples of the market working\nnormally, albeit with buyers—in this case, investors—making bad buying decisions\nand in the Theranos case out-and-out fraud.\n\nAs a whole, the VC system subverts market capitalism in many ways. It warps\nmarkets, allowing companies to charge prices that don’t reflect the true cost or\nvalue of what they’re selling. It permits unprofitable enterprises and\nunsustainable business models to thrive and proliferate. It also warps the\nmarket for talent—employees—especially in the tech sector. And finally, it warps\nentire market categories, like transportation, housing, and the media. Uber and\nLyft, for example, have created an unsustainable market for hired-car rides by\ncharging artificially low prices that do not accurately reflect the value of\ndrivers’ labor.\n\nVC funding is also a hack on innovation. By favoring financial returns over\nsubstantive product improvements, it prioritizes certain kinds of innovation and\nignores others. To a VC-funded company, all that matters is return on\ninvestment. So if one of the goals of a market economy is to incentivize\ninnovation, VC funding subverts that goal. VC investors expect to recover their\ninvestment in ten years or less, and that’s how they steer their companies.\n\nSimilarly, VC culture only rewards endeavors that realize a very high rate of\nreturn. Investors bankroll hundreds of companies with different ideas and\nbusiness models, knowing that almost all of them will fail—and that the few wild\nsuccesses will more than pay for the rest. So VC-funded managers are motivated\nto “swing for the fences” rather than grow sustainable, long-term businesses.\nThis is why VC-funded companies can lose so much money, doing all sorts of\nsocietal damage along the way. Those losses are paid for by the successes:\n“unicorns,” in VC-speak.\n\nPrivate equity allows for another hack, and that’s debt financing. When private\nequity firms take on a majority stake to acquire companies, they can use less of\ntheir equity and rely on debt. They can use this to saddle the firms they\nacquire with debt, extract money from them, leave them with more debt, then sell\nthem for even more profit—with all the debtors left holding the (empty) bag.\nConsider the case of Greensill Capital, which collapsed spectacularly in 2021.\nIts unsustainable expansion over the course of ten years—from supply-chain\nfinance startup, to multinational middleman with a $4.6 million debt load, to\ninsolvency—was accelerated by investments and loans from SoftBank, who made\nmillions in funds available in spite of the company’s increasingly fishy\naccounting.\n\nThere’s nothing illegal about any of this. VC funding and private equity are\nsuch a normal part of our economy that it might seem odd to call them hacks. But\nthey are; they’re hacks of pretty much everything the market is supposed to do.\nNo one calls it a hack; everyone just calls it “disruptive” and “innovative.”\nThat it’s both legal and accepted doesn’t change the fact that money and power\ndecide what behavior is accepted and who gets a seat at the gaming table."},{"title":"Test Section Title","content":"25\n\nHacking and Wealth\n\nIn professional sports, salary caps keep leagues competitive by reducing the\nunfair advantage of teams with more capital. Basically, all of the teams agree\nto a maximum total amount they will pay their players. Of course, the agreements\nare hacked. Depending on the sport and the specifics of the rules, teams can\nhide payments in signing bonuses, by spreading payments over multiple years, by\nhaving team sponsors and affiliated companies also hire players, by hiring a\nplayer’s spouse, or by hiding players’ salaries in an associated minor-league\nteam’s budget. There’s a lot of money involved in professional sports. The teams\ndo everything they can to subvert the rules.\n\nThe hacks we’ve seen so far in banking and financial systems are largely\nperpetrated by the wealthy in their attempts to amass even more wealth. This\nflips our traditional notion of computer hacking on its head. We conventionally\nthink of hacking as something countercultural that the disempowered do to\npowerful systems standing in their way. The hacker group Anonymous stands as a\ngood example of this sort of hacking. But it’s more common for the wealthy to\nhack systems to their own advantage, whether for profit or power.\n\nThe wealthy enjoy several advantages that make them better at discovering and\nexploiting hacks. The first is that they don’t actually have to be superior\nhackers themselves. The wealthy have more resources to hire the expertise\nrequired to succeed at hacking: finding vulnerabilities, creating exploits,\nexecuting hacks. Additionally, because money is so important in politics, the\nwealthy are better normalizers of hacks. That is, they can use their power to\nensure that their hacks become legally permissible.\n\nWhen General Motors declared bankruptcy in 2009, it declared its stock\nworthless, then created a completely new stock that it then sold to raise\ncapital. Executives and wealthy investors profited, while common\nshareholders—many of them employees and retirees—were screwed. It was a very\nprofitable hack, but only for those who were already rich.\n\nWhat we see here is—again—that the rich are better at hacking. People and\norganizations with concentrated resources are better at finding and implementing\nhacks. And they’re better at ensuring those hacks are legalized and normalized.\n\nIn 2020, we began to hear about a new hack of the tax system involving stock\ntrading—cum-ex trading, which is Latin for “with-without.” Here’s how the New\nYork Times described it: “Through careful timing, and the coordination of a\ndozen different transactions, cum-ex trades produced two refunds for dividend\ntax paid on one basket of stocks.” That first refund was legitimate, the second\nwas not.\n\nThat it’s a hack is obvious; it was neither anticipated nor intended that one\nindividual or entity receive two tax refunds for one payment. But the system\nallowed it, and from 2006 to 2011, bankers, lawyers, and investors who used this\nhack made off with $60 billion from EU countries.\n\nGermany recently sentenced a banker known as Christian S. to ten years in prison\nover the scandal. This isn’t the final word, though. Christian S.’s case awaits\nappeal. Two London bankers were handed a suspended sentence and £14 million fine\nin 2020 for cum-ex trading. A German private bank was ordered to pay €176.6\nmillion to German tax authorities. A former senior German tax inspector, who\nabsconded to Switzerland in 2012 when news of the cum-ex scandal began to emerge\nbut was eventually extradited, has been charged for providing advice and\ncollecting fees from the bankers involved in the scheme. The Frankfurt offices\nof Morgan Stanley bank were recently raided as part of the cum-ex investigation.\nMore prosecutions are pending. Germany alone is investigating over 1,000 lawyers\nand bankers for their involvement in cum-ex trades.\n\nHere we can clearly see the interplay of hacking, legality, and morality. When\nasked about his own tax avoidance, then candidate Donald Trump famously said,\n“That makes me smart”—but it doesn’t necessarily make him moral. It might, if he\nonly exploited legal loopholes to do so, but it doesn’t mean those tax loopholes\nshouldn’t be closed.\n\nCum-ex trading has cost European nations and their citizens at least $60\nbillion, and most of that won’t ever be recovered. Hacking is parasitical,\nmostly performed by the rich and powerful, and it comes at the expense of\neveryone else."},{"title":"Test Section Title","content":"PART 4\n\n\n\nHACKING LEGAL SYSTEMS"},{"title":"Test Section Title","content":"26\n\nHacking Laws\n\nTax hacks show up in architecture and construction surprisingly often. The\nmansard roof became popular in Napoleonic France. It allowed for an extra story\nof living space without the building being taxed for it, because that story was\ntechnically part of the roof. The gambrel roof also hid a story and evaded the\nUS 1798 Federal Direct Tax law. Buildings in Peru and elsewhere frequently have\nbits of rebar sticking out of their sides and roofs and a pile of rubble nearby,\nbecause unfinished buildings have less property tax.\n\nThis is probably a good place to remind readers what counts as a hack and what\ndoesn’t. A British tax on home windows from 1696 to 1851 led tax-averse\nhomeowners to block up their windows. That’s a hack because the number of\nwindows was being used as a proxy for home size, and blocking up windows\nsubverted that measure. If the tax had measured home size directly, and if\nhomeowners had demolished their buildings as a result, that wouldn’t be a hack.\nOpting out of or destroying part of a system in order to avoid its costs isn’t\nhacking. Hacking means finding and exploiting the rules of the system, turning\nthem to your advantage as you continue to participate in that system.\n\nGovernments take action through words—and those words can change the state of\nthe world. Congress passes laws. Presidents sign executive orders. Agencies make\nrules. These are all just words associated with enforcement power. These words\nare in a sense code. And like computer code, they will have bugs and\nvulnerabilities. The authors of any legal text are imperfect and fallible, and\nalso influenceable. As such, laws can be hacked. Their authors can—accidentally\nor deliberately—leave vulnerabilities in laws that will inevitably be discovered\nby hackers. And there is always the will to hack laws.\n\nSumptuary laws regulated extravagance and luxury. (Think “sumptuous.”)\nHistorically, they’ve mostly been passed to prevent expensive competition among\nnobility to outdo each other in parties, banquets, feasts, and pageantry.\nSometimes, they’ve been passed to prevent people of a lower class from mimicking\nthe aristocrats too closely. In both cases, those annoyed by the laws have tried\nto hack them.\n\nBanquets, for example, have regularly been limited with respect to the number of\ncourses or the varieties of meat that can be served. For example, a 1356\nFlorentine law limited the number of courses at a wedding to three. But the\ndefinition of “course” excluded fruit, vegetables, and cheese, and hosts used\nthat loophole to add additional courses. And a single “roast” could consist of\none meat stuffed with one or more other meats, which means that—yes—the\nturducken was originally a hack of sumptuary laws. This demonstrates yet again\nhow the rich can comply with the letter of the law while completely subverting\nits spirit.\n\nSystems of laws are just another system of rules, and are vulnerable to hacking.\nIn a sense, they’re designed to be hacked. The letter of the law is mostly\nwhat’s enforced, the spirit rarely. If you find a hack—a way of following the\nletter of the law that seems to violate the spirit—it’s not your fault that the\nlaw wasn’t well written. This is the sort of argument that you hear from tax\navoidance proponents everywhere.\n\nAnd laws are hacked everywhere. In 2020, the Federal Reserve implemented an\nemergency loan program for companies affected by the coronavirus pandemic. Even\nthough only US companies were officially allowed to participate, foreign\ncompanies figured out how to turn themselves into US companies and hack the\nregulation. The Pacific Investment Management Company, based in Newport Beach,\nCalifornia, runs a hedge fund registered in the Cayman Islands to avoid paying\nUS taxes. But by investing in a Delaware corporation and tying it to the parent\nCalifornia corporation, the hedge fund was able to borrow money commercially to\nbuy securities, then borrow $13.1 million from the government relief program,\nand finally use that loan to pay back the original and more expensive securities\nloan. Instant profit, perfectly legal, at the expense of everyone in the US.\nSociopathic, perhaps, yet I admire the creativity.\n\nMy notion of hacking laws isn’t just about legislation. Any rule can be hacked.\nHistorically, the Catholic Church’s rules about abstinence varied greatly, and\ngenerally involved not eating meat at certain times. This was called a fast,\nalbeit only a partial one, compared to Yom Kippur or Ramadan. But, people being\nas they are, a great deal of medieval thought went into exactly what counted as\n“meat” and “not-meat,” especially during the month-long fasting seasons of Lent\nand Advent. Fish didn’t count as meat. Barnacle goose was also considered not\nmeat, because it had scaly webbed feet and (supposedly) gave birth in the water.\nA similar argument applied to beavers: also not meat. (This isn’t just a\nhistoric curiosity. Even today, Detroit Catholics are permitted to eat muskrat\nduring fast days on the basis of a missionary’s ruling from the 1700s.) Some\nFrench monasteries served rabbit fetuses, not deemed meat because they were\nswimming in amniotic fluid. (Really: I’m not making any of this up.) St. Thomas\nAquinas declared chicken to be of aquatic origin—whatever that means—and not\nmeat. Some bishops went further, declaring that, because they are not\nquadrupeds, all fowl is fair game (so to speak).\n\nA more modern hack of fasting rules is the practice among some wealthy Saudi\nfamilies of treating Ramadan as a month-long party, staying up most of the night\nand sleeping through most of the day.\n\nAny law is fair game for hacking. And as long as there are people who want to\nsubvert the intent of a law, there will be hacking."},{"title":"Test Section Title","content":"27\n\nLegal Loopholes\n\nThe “Zone of Death” is a weird vulnerability in the US Constitution. It arises\nfrom contradictory jurisdictional rules between state and local law enforcement.\nThe Venue Clause in Article III, Section 2, of the Constitution states that:\n“The trial of all crimes, except in cases of impeachment, shall be by jury; and\nsuch trial shall be held in the state where the said crimes shall have been\ncommitted . . .” The Vicinage Clause in the Sixth Amendment says that: “In all\ncriminal prosecutions, the accused shall enjoy the right to a speedy and public\ntrial, by an impartial jury of the State and district wherein the crime shall\nhave been committed . . .”\n\nThe US District Court for the District of Wyoming has jurisdiction over all of\nYellowstone National Park, which extends slightly into Montana and Idaho. Let’s\nsay you commit murder in the Idaho portion of Yellowstone National Park. You\ncan’t be tried in Wyoming—the jurisdiction in which you were arrested—because\nArticle III requires you to be tried in Idaho. But the Sixth Amendment requires\nthat your jury reside in both the state (that’s Idaho) and the district (that’s\nWyoming) in which the crime was committed. That means your jury must consist of\nresidents of the Idaho portion of Yellowstone National Park . . . which has no\nresidents. Basically, there is no constitutional way to convict you of murder.\n\nNo one has yet used this particular hack to get away with murder, but it has\nbeen used as a poaching defense. In 2007, a man illegally shot an elk in\nYellowstone while standing in the Montana portion. After being indicted, his\nlawyers used this hack as part of their defense. The court dismissed the\nargument, supposedly because it would solidify the “Zone of Death” loophole. By\ndoing so, they disabled the hack by means of adjudication.\n\nA more sinister version of this hack occurs all too often on Native lands.\nTribal courts cannot try non-Native individuals who commit crimes on Native\nlands; only federal authorities can do so, and in disturbing numbers of cases\nthey do not. This means non-Native Americans have free rein to assault Native\nwomen on tribal lands and suffer virtually no repercussions. It has been\nreported that a full 80% of Native American women who are sexually assaulted are\nvictimized by non-Native American men.\n\nOne last hack. Federal enclaves are parcels of land within a state that are\nowned by the federal government, and have long represented a vulnerability of\nthe US legal system. Federal enclaves include military bases, federal\ncourthouses, federal prisons and other federal buildings, and national forests\nand national parks. These have special legal designation because their home\nstates essentially relinquish ownership of them to the federal government,\nmeaning that state and local laws don’t apply to them.\n\nOver time, the legal system has sought to patch this vulnerability. In 1937, a\nUS Supreme Court ruling led to state taxes being applied to federal enclaves. In\n1970, in Evans v. Cornman, the Supreme Court ruled that residents of federal\nenclaves (such as residents of private homes situated within the territory of a\nnational park) could vote in state elections. Other smaller patches have been\nmade through the courts, but federal enclaves remain exempt from numerous state\nlaws, including criminal laws, antidiscrimination laws, and labor protections.\n\nResidents of federal enclaves can also escape foie gras bans. Foie gras is the\nliver of a duck or goose that has been subject to a process called gavage, in\nwhich animals are force-fed twice a day for a couple of weeks until their livers\nare engorged to ten times their usual volume and are ready to cook. Animal\nrights activists regularly agitate against the process, and in 2004 California\nbanned the sale and production of foie gras. In the following years, the ban was\nrepeatedly challenged in court. In 2014, the owners of a San Francisco\nrestaurant called the Presidio Social Club pointed out that since the club was\nlocated on a federal enclave, California’s state ban didn’t apply to them.\nBefore a court could rule, however, the club’s owners succumbed to the hecklers’\nveto and pulled foie gras from the menu after animal rights protesters picketed\nthe restaurant. So we don’t have a final ruling on this particular hack.\n\nIn all of these anecdotes, the real patch is for the legislature to return to\nthe law and fix the loopholes. Congress needs to designate the Zone of Death\nwithin the US District Court for the District of Idaho. Congress needs to give\nIndian nations the jurisdiction and infrastructure to provide safety and\nrecourse to Native women and girls within their territories. Although the 2013\nViolence Against Women Act partially closed this vulnerability, a 2019\nreauthorization was derailed by the gun lobby for reasons having nothing to do\nwith this particular provision."},{"title":"Test Section Title","content":"28\n\nHacking Bureaucracy\n\nWhen you design a set of rules, it’s common for those who must comply with them\nto optimize their actions to fit within the rules—even if what they end up doing\ngoes against the expressly stated goal of those rules. Examples include an\nexterminator who releases an insect swarm to drum up business or a teacher who\nteaches strictly to the test to increase student test scores. Economists refer\nto this as Goodhart’s law: when a measure becomes a target, it stops being a\ngood measure. In this manner, bureaucratic rules are hacked all the time by\npeople who don’t want to abide by them.\n\nBureaucracies are hacked from below, by those who are constrained by them, in\norder to get things done in spite of them. In the 1980s, Administrator Daniel\nGoldin hacked the normally moribund NASA bureaucracy and found loopholes in the\nregulations that applied to NASA in order to launch more, and cheaper, space\nprobes like the Mars Pathfinder mission. Newly formed public innovation agencies\nlike 18F and the US Digital Service hacked a variety of slow and complicated\ngovernment hiring, contracting, and procurement processes in order to implement\ntechnological upgrades at Internet speeds. Government technologists in the UK\nand Canada have done the same thing in their countries.\n\nBureaucracies are also hacked by those who oppose them. Work-to-rule is a labor\ntactic that is short of going on strike. It’s malicious compliance, and\nbasically means following the rules exactly, which—of course—quickly brings\nthings to a standstill. Some of it is obvious: taking all allowed breaks,\nstopping work exactly at quitting time. A nurse might refuse to answer the\ntelephone, because that’s not part of a nurse’s job description. The tactic has\nbeen tried-and-true for decades, and inspired the plot of Jaroslav Hašek’s\nunfinished satirical novel, The Fate of the Good Soldier Švejk during the World\nWar, in the 1920s.\n\nSome are definitely hacks: insist on doing everything through formal channels,\nmultiply paperwork in plausible ways, apply all regulations to the letter. The\nidea, of course, is to turn the system of rules against itself.\n\nIn the 1980s, Malaysia had a system of sharecropping rents, called sewa padi.\nBasically, rents were collected after the harvest and depended on the quality of\nthe harvest. So, of course, farmers would secretly harvest at night before the\nofficial harvest began, remove some of the grain at the actual harvest if\nsupervision was lax, or do a shoddy job at threshing so that rice on the stalks\ncould be later gleaned and retained, and then spread spurious claims of crop\ndamage to cover up their behavior. Much of this was just cheating, but some\ntactics could be considered hacking. The government closed this vulnerability by\ninstituting a new system, called sewa tunai, with fixed rents paid before\nplanting.\n\nThis particular style of hack is common. In 1902, the Hanoi government tried to\neradicate the rat population by paying for rat tails. People quickly realized\nthat the smart thing to do was to trap a rat, cut off its tail, and then release\nit back into the wild so it could breed more rats to catch. In 1989, Mexico City\nintroduced a pollution-control scheme whereby cars with even and odd license\nplates could drive on alternate days. People responded by buying a second car,\noften an old and highly polluting one.\n\nMore recently, Uber drivers in Nairobi created a hack to cut the company out of\nits share of the ride fee. Passengers hail drivers through the Uber app, which\nalso sets the ride charge. At pickup, the driver and passenger agree to “go\nkarura,” which means that the passenger cancels the ride and pays the driver the\nentire amount in cash.\n\nThe Boeing 737 MAX debacle provides a particularly high-profile example of the\nregulatory negligence that results from overly close relationships between\nregulators and regulated industries. In this case, FAA regulators applied\ninsufficient scrutiny to the 737 MAX’s Maneuvering Characteristics Augmentation\nSystem (MCAS), which the company had modified. As a result of this failure of\noversight, two 737 MAX airplanes crashed in Indonesia (2018) and Ethiopia\n(2019), killing 346 people.\n\nLet’s be explicit about the hack here. Regulatory agencies are supposed to be\nthe expert proxy for the average person’s interest. I am not an expert in\nairplane safety (or automobile safety, food safety, drug efficacy, or how banks\nshould organize their balance sheets to keep the economy stable). Government\nprovides that expertise in the form of regulatory agencies, which make rules on\nmy behalf to protect me. This oversight mechanism is what’s being subverted.\n\nAnalysis of the failure pointed to regulatory failures. The FAA never\nindependently scrutinized the MCAS; it relied on Boeing’s own assessments of the\nsystem. The FAA didn’t have the expertise, and its Aviation Safety Oversight\nOffice delegated much of the work to Boeing. The engineers who worked on the\nplanes were allowed to certify their own work. And there were instances where\nFAA managers took Boeing’s side when its engineers wanted safety changes. The\nFAA even waived several regulations to permit Boeing an abbreviated\ncertification process that allowed it to sell the planes more quickly. Taken\ntogether, the incident paints a picture of an FAA regulatory process hacked by\nthe airline industry, which created an environment rife with regulatory capture,\nperverse incentives, ethical dilemmas, and dangerous safety lapses.\n\nIn 2021, the Justice Department reached a settlement with Boeing over criminal\ncharges related to those crashes: $2.5 billion. That might seem like a lot of\nmoney, but the company got off easy. Only $243.3 million went to FAA fines—a low\nnumber, according to market analysts—with no binding criminal charges or\nadmissions of guilt required from Boeing, despite credible reports of systemic\nnegligence on safety issues.\n\nThe cozy relationship between Boeing and regulators shows the need to reconsider\nthe proper compartmentalization of duties between regulators and regulated\nindustries. Ultimately, the onus for ensuring responsible conduct and products\nin regulated industries lies with regulatory agencies, and relying too heavily\non industry self-certification creates long-term conflicts of interest and\natrophies government’s capacity for oversight. More importantly, there is a need\nto further compartmentalize the individuals who serve as regulators by requiring\nlengthy “cooling off” periods before they take industry employment. Once\nregulators see themselves not as public servants, but as future employees in the\ncompanies they regulate, there is a perverse incentive for self-serving\nregulation that is not necessarily in the public interest."},{"title":"Test Section Title","content":"29\n\nHacking and Power\n\nHacking is a way of exerting power. A hack affords more power to the hacker at\nthe expense of someone else—and often everyone else—in a system. It’s driven by\na desire to forward the hacker’s own agenda, rules be damned. (This is true even\nfor the quintessential teenage computer hacker, trying to satisfy her own\ncuriosity. Yes, curiosity is largely benign, but privacy has a purpose.)\n\nThe disempowered hack to subvert existing power structures. They do it to bypass\nbureaucracy or for personal gain. Much of the world has no say in the global\nsystems that affect their lives; they often have no choice but to hack them—as\npeople everywhere hack systems that are causing them problems. Such hacking can\nbe a reasonable response to elite or state hacks like administrative burdens.\n\nBut while we might think of hacking as something an underdog does to gain an\nadvantage over some traditional power, it is more often used by the powerful to\nfurther increase their own advantage.\n\nAs I discussed previously, the largest US banks deployed specialized legal teams\nto identify and exploit loopholes in the Dodd-Frank Act, and executed a\nthree-year, multimillion-dollar lobbying campaign to get them normalized. Thanks\nto the size and wealth of the banks, they were able to find and exploit those\nvulnerabilities; thanks to the power that wealth purchased, those loopholes\nremain legal.\n\nThere are differences in how the disempowered and the powerful hack, though.\nCriminals, dissidents, unorganized citizens—all outliers—are more agile. They\ncan hack new systems faster, and can magnify their collective power because of\nit. But when the established institutions finally figure out how to hack the\nsystems that constrain them, they can do it more effectively. And because they\nhave more raw power to magnify, they benefit more from those hacks. This is true\nfor both governments and large corporations.\n\nJust as there’s a power dynamic to hacking, there’s a power dynamic to getting\nhacks normalized. The powerful (by which I generally mean the wealthy) are\nbetter equipped to ensure that their hacks are long lasting, and that you no\nlonger think of them as sneaky, but as part of the normal way of doing things.\nThat’s the way you probably think about hedge funds, venture capital funding,\nand all sorts of tax avoidance strategies.\n\nThe reasons are structural. One, tax loopholes often require the assistance of\nwell-paid lawyers and accountants to exploit effectively. Two, wealthy people\nand organizations have more money to hide and are therefore more motivated to\nfind and exploit loopholes. Three, tax loopholes often operate in a legal grey\narea; those who are less well-off don’t have the financial resources to fight\nthe tax authorities. And four, lax enforcement means that wealthy tax cheats are\nless likely to be held accountable.\n\nThis generalizes. Successful hacks often require specialized expertise, or the\nresources to hire people with that expertise, or the resources to shape a system\nto make it hackable by people with that expertise. On all three counts, wealthy\nand powerful people and organizations have the upper hand and are far better\nequipped to perform and entrench hacks at a large scale.\n\nThere’s also a social power dynamic at play here. The less mainstream and more\nmarginalized, as well as people of classes and races and genders and ethnicities\nwith less power, are both less likely to hack and less likely to get away with\nit when they try. They might commit crimes, but that’s not the same. Women are\ntaught to follow the rules, while white men are taught to break them if they\ncan. This is an important consideration to keep in mind when thinking about\nhacking and power.\n\nThe powerful are also better at stopping hacks by the less powerful. Union\ntactics like work-to-rule are much less prevalent today, primarily because the\npowerful have steadily eroded the power of unions. Management in general is\nincreasingly hostile towards union organizing and has pushed for anti-union laws\nand court decisions. As a result, many employees can be fired without cause.\nBecause work-to-rule methods require union membership or just-cause termination\nprotections, these tactics have become less prevalent over time.\n\nGeorgetown law professor Julie Cohen wrote that “power interprets regulation as\ndamage and routes around it.” By this she meant that the powerful have the\nwherewithal to circumvent rules. Once the powerful understood that they had to\nhack systems—primarily the regulatory processes that prevented them from doing\nas they pleased—they developed competence to do just that. We have seen that\nwith the banking industry, with financial markets, and with luxury real estate.\n\nThink about the 2016 US Senate refusal to even consider Merrick Garland as a US\nSupreme Court nominee. This is a hack, a subversion of the Senate confirmation\nprocess. What’s interesting to me is that we don’t know if this hack has been\nnormalized. We know that the Republicans weren’t punished for their hypocrisy\nwhen Amy Coney Barrett was nominated four years later. We’ll learn the new\nnormal the next time a Supreme Court seat opens up when one party controls the\npresidency and the other party controls the Senate. Will a Republican-dominated\nSenate do the same thing again? Will Democrats take the opportunity when it\narises? If the answer to either one of those questions is yes, then it’s likely\nthat Supreme Court justices will forevermore be appointed only when the same\nparty controls both the presidency and the Senate—because the Senate has the\npower to hack the Supreme Court confirmation system in this particular way.\n\nThis is why stories of hacking by the less powerful—by the poor, by the\ndisadvantaged, by political dissidents in authoritarian countries—are harder to\ncome by. They’re declared illegal, so the hacks become cheats. Tax loopholes\nused by the poor are closed by the IRS. Sit-in and slow-down strikes, once\ncommon in the 1930s, are no longer protected by US federal law. We don’t even\nthink of these as hacks. This doesn’t mean that the less powerful aren’t as good\nat hacking, only that they’re less effective at normalizing their hacks.\n\nWhen examining a system, pay attention to who it serves and who it doesn’t.\nThose who are ill served in some way are those who will hack it. That’s both the\npowerful and the disempowered. And while both will hack away at their\nconstraints, the powerful are more likely to excel at it—and avoid any\nconsequences."},{"title":"Test Section Title","content":"30\n\nUndermining Regulations\n\nAs far as users are concerned, Uber is a taxi service. It looks like a taxi\nservice. It acts like a taxi service. But if you ask Uber—and any of its\ncompetitors—it is not a taxi or a livery company. It is an Internet services\ncompany that connects people who are driving cars with people who want to be\ndriven somewhere. Those drivers are supposedly independent contractors, not\nemployees; Uber claims to have no control over them. Uber schedules the drivers\nand handles their billing, but that’s nothing more than a courtesy. To hear Uber\ntell it, the company really doesn’t have anything to do with cars at all, at\nleast as far as any government regulations are concerned.\n\nRide-sharing apps are a hack of the taxi industry, or—more generally—society’s\nattempt to manage its short-term transport needs. Their business model allows\nthem to ignore dozens of laws regulating licensed taxis and limos, including\nworker protection laws, safety laws, consumer protection laws, permit and fee\nrequirements, and public-good laws. Taxi drivers are required to have background\nchecks. Uber and Lyft drivers are not (although they now grudgingly do so). Taxi\ncompanies must pay minimum wage and are subject to citywide caps on the number\nof vehicles they operate at any given time. Not Uber and Lyft. The list goes on\nand on.\n\nThis all started around 2012, and Uber has since leveraged its competitive\nadvantage over traditional taxis and limos to dominate the market. As of 2021,\nit operates in over 10,000 cities in 72 countries, completing 19 million trips\neach day. It has 3.5 million drivers and services 93 million monthly active\ncustomers. And it still can’t turn a profit.\n\nMunicipalities around the world have tried to close the vulnerabilities Uber has\nused to hack the taxi market with mixed success. In 2017, the European Union’s\ntop court ruled that Uber is a transportation service, not the technology\ncompany it claimed to be in the hope of evading transportation regulations. In\n2018, the UK Court of Appeal ruled that Uber drivers are employees, contrary to\nUber’s contention that they are independent contractors; the French Cour de\nCassation made a similar decision in 2020. In the US, California passed\nlegislation in 2019 requiring companies like Uber to treat their workers as\nemployees; litigation ensued, and continues. Other cities and states are trying\nto do the same, although most states have preempted local rulings on this issue.\n\nAirbnb is a similar hack of the hotel industry. Airbnb lodgings are not the same\nas hotels, although they serve the same purpose of short-term lodging. But\nAirbnb maintains that because it is not actually a hotel company, Airbnb\naccommodations should not be subject to any of the laws and regulations—or\noccupancy taxes—imposed on conventional hotels. Because Airbnb doesn’t own any\nproperties, it maintains that it is just a technology company. The people who\nown the accommodations are independent contractors, and are responsible for\npaying taxes and complying with local regulations. Of course, most fail to do\nso.\n\nMunicipalities either let Airbnb slide without paying its share of occupancy\nfees or try to fight back. Some sought to limit its expansion through\nregulation, and Airbnb sued them (while still operating), resulting in lengthy\ncourt battles. In addition, Airbnb often deployed property owners as grassroots\nlobbyists. Airbnb would send a message out to owners saying the city was\nthreatening their ability to make money, even sending information about specific\nmeetings the hosts should attend.\n\nThese companies are just two examples of the “gig economy,” which is\ncharacterized by attempts to hack labor law, consumer protection law, and other\nlaws and regulations. TaskRabbit, Handy, and DoorDash all employ the same hacks.\nAmazon does it too, running what’s basically a private Uber-like system for its\ndelivery vehicles. Because those drivers are independent contractors, the\ncompany can ignore all sorts of laws that conventional delivery drivers must\nfollow.\n\nThat companies hack regulations is a surprise to no one. What’s important here,\nespecially when talking about ride sharing, short-term rental, and short-term\nloan companies, is that regulatory evasion is central to their business model.\nMany “disruptive” gig economy services would be completely unviable if forced to\ncomply with the same regulations as the “normal” businesses they compete with.\nAs a result, they—and their venture capital backers—are willing to spend\nunbelievable sums of money to combat these regulations. This has two\nimplications. The first is obvious: their regulation-compliant competitors are\nput at a disadvantage. And two, the long-term profitability of these companies\nassumes either the continued avoidance of regulation (and, by extension, the\nexploitation of the poorly paid gig workers they employ) or the wholesale\nreplacement of their gig workers by machines.\n\nThe response by these companies to state and local governments’ attempts to\npatch the vulnerabilities upon which they rely demonstrates how far they will\ngo. Following a 2018 California State Supreme Court ruling and the 2019 state\nlaw mentioned above, several gig economy companies banded together to push a\nreferendum (Proposition 22) that would remove many employee protections from\ntheir gig workers: employee classification, wage floors, unemployment insurance,\nhealthcare insurance, and so on. Led by Uber, Lyft, and DoorDash, gig economy\ncompanies spent $200 million to support this referendum and convince workers\nthat it was in their interests to endorse it. The measure passed in 2020,\nrolling back California’s efforts to protect workers. The battle is not over,\nand undoubtedly there will be developments after this book goes to press.\n\nI could probably write an entire book about how companies and industries hack\nregulations that limit their profits, but I’ll just offer a couple more\nexamples. Payday loans are short-term loans targeted at poor people, generally\nmade in small amounts at astronomically high interest rates. Four-fifths of\nborrowers renew or roll over the loans, trapping themselves in a vicious cycle\nof debt, interest, and fees, and resulting in an average interest rate of 400%\nper year, plus fees. States have worked to regulate the payday loan industry and\nreduce the interest rates it can charge, but the payday loan companies have\nconsistently found ways around the rules. They branched out into issuing\ninstallment loans instead of loans where the full repayment is due the next\npayday—thus technically skirting the definition of payday loans. They also\noperate as loan brokers: middlemen that can charge unregulated fees. In Montana,\npayday loan providers moved to Indian reservations to avoid state and federal\nregulation. In 2020, the Trump administration’s Consumer Financial Protection\nBureau (CFPB) rolled back a whole list of new regulations that would have\nrestricted the most predatory practices of this industry.\n\nOne final story: During the COVID-19 pandemic, the US and Canada closed their\nland border to nonessential travel. You could fly between the countries, but\nthere were all sorts of restrictions on driving. This was a problem for the\nCanadian “snowbirds” who winter in the US, but there was a loophole: cargo was\nstill permitted. Availing itself of the cargo loophole, a shipping company in\nHamilton, Ontario, offered a service that would truck a customer’s car into the\nUS and to the Buffalo Airport, and a helicopter company would fly the customers\nthere to meet it. Those who could afford the service were able to completely\nevade the land border closure.\n\nWherever there is a regulation, there are people who are constrained by it.\nRegulations generally serve a useful purpose, but they can also benefit\nincumbents, stifle innovation, and reflect an outdated mode of thought. New\ncompanies have an incentive to look for vulnerabilities in those regulations and\nconstruct hacks that meet the letter of a regulation while completely violating\nits spirit. And since all regulations will either be incomplete or inconsistent,\nthey’re all vulnerable to these hacks.\n\nThis all leads to an important question: How do we prevent hacks from\ndeep-pocketed, technically sophisticated, politically savvy corporations whose\nvery existence depends on hacking regulations? What does a clever, resilient\nsolution look like in this instance?\n\nOne security measure is red-teaming new regulations before they’re enacted.\nAccording to Jeremy Rosenblum, a Philadelphia attorney who advises payday\nlenders, the industry needs to constantly work to develop new financial products\nin advance of regulatory interference: “If you’re serving this market, you have\nto be considering alternative strategies if the CFPB does come up with\nregulations.” This is the same philosophy that every company discussed in this\npart follows. To counter that, regulators need to be proactive in their\nregulatory efforts and consider possible vulnerabilities and industry responses\nin advance. By doing so, regulators can better anticipate and prevent socially\ndeleterious industry action and financial innovation.\n\nAnother is iteration and agility. While it’s nice to hope—or even believe—that\neffective regulations are put in place in advance to prevent these kinds of\nhacks, regulators need to be prepared for unexpected and socially deleterious\ninnovation. To combat this, they need to monitor regulated parties and be ready\nto act quickly to police new products that emerge post-regulation, knowing that\nthey won’t necessarily get it right the first time around—and patch all\nvulnerabilities as soon as they emerge."},{"title":"Test Section Title","content":"31\n\nJurisdictional Interactions\n\nThe Double Irish with a Dutch Sandwich tax loophole that companies like Cisco,\nPfizer, Merck, Coca-Cola, and Facebook used to avoid paying US taxes stemmed\nfrom the limitation of laws by national borders. By making clever use of foreign\nsubsidiary companies and transferring both rights and incomes between them,\nlarge US corporations are able to avoid paying taxes on much of their global\nincome. (Note that individual US citizens are taxed on their entire income,\nregardless of the country in which it was earned, so this trick only works for\ncorporations.)\n\nThis is just one of many hacks involving tax havens around the world. Global tax\navoidance costs the US just under $200 billion a year, 1.1% of GDP. Total cost\nto global tax revenue is between $500 and $600 billion, depending on the\nestimate. What’s interesting about these hacks is that they leverage the\ninteractions amongst a series of vulnerabilities in the laws of multiple\ncountries.\n\nThe solution is both simplicity and transparency. In the US, twenty-eight states\nand the District of Columbia have adopted Combined Reporting Systems for State\nCorporate Income Tax, which helps to prevent domestic multi-jurisdictional\nprofit shifting. Under combined reporting systems, companies and their\nsubsidiaries must report their total profits (in this case, their total\n“domestic” profits) and the percentage of their overall business that takes\nplace within a given jurisdiction (that is, a state). The jurisdiction is then\nentitled to tax a share of that profit proportionate to the percentage of a\ncompany’s business that takes place in it, thus preventing companies from\ndodging their tax obligations through jurisdictional interactions and profit\nshifting. This approach has already helped states recover billions of dollars in\ntax revenue that had previously been hidden through domestic tax havens.\n\nHowever, this innovation hasn’t resolved the broader issue of multinational\nprofit shifting and tax avoidance. First, almost all US states that use a\ncombined reporting system for taxation (Montana being a notable exception) do\nnot require companies to disclose their offshore profits, allowing companies to\navoid paying taxes on domestically earned profits that they have shifted abroad.\nSecond, as I noted previously, US corporate income taxes are not assessed on\nprofits earned abroad, which facilitates tax avoidance and overseas profit\nshifting at the federal level.\n\nThe Tax Cuts and Jobs Act of 2017 made a half-hearted attempt to address this\nissue through the Global Intangible Low Tax Income provision, which required\ncompanies to pay a nominal tax (10.5%) on untaxed profits in an overseas tax\nhaven, but it has largely failed to stem international profit shifting.\n\nThe best idea I’ve seen for solving this problem again combines simplicity and\ntransparency. It’s called Mandatory Worldwide Combined Reporting (MWCR), a\nremarkably simple method for resolving notoriously complex jurisdictional\ntaxation issues. Similar to a combined reporting system, this would require that\na company and its subsidiaries report their total worldwide profits, as well as\nthe percentage of their overall business (typically expressed through revenue)\nthat comes from a given jurisdiction. The jurisdiction would then be entitled to\ntax a share of that profit proportionate to the percentage of a company’s\nbusiness that takes place in it.\n\nAt this book’s time of writing, the Biden administration and the Organization\nfor Economic Co-operation and Development (OECD; a club of rich and developed\nnations) were both working to make something like MWCR a reality. In 2021, the\nOECD announced that 130 countries and jurisdictions had agreed to each tax the\nlargest multinational corporations at a minimum rate of 15% of profits earned\nfrom their respective territories, as opposed to today’s system, where companies\nare only taxed by their “home country.” Biden’s proposal is similar, but with\nkey differences, such as requiring compliance by a wider range of for-profit\nentities. Time will tell how these proposals evolve and how corporations will\ntry to hack them, just as they have for previous fixes.\n\nCountries sometimes invite this kind of jurisdictional arbitrage by deliberately\nsubverting their own laws to attract a global clientele. For example, a system\nof ship registration called “flags of convenience” has made it easy for\nshipowners to avoid rules about ship maintenance, ignore labor laws, and evade\nprosecution for environmental damage like oil spills. Historically, ships would\nfly the flag of their own country, giving them government protection but also\nsubjecting them to its laws. In the early twentieth century, Panama allowed\nanyone to fly its flag for a fee. This was quickly popularized by other\ncountries like Liberia and Singapore, and became an opportunity for smaller\ncountries with few natural resources, like the Republic of Vanuatu. Shipowners\nloved this hack, because those countries had few and lax laws. Between the 1950s\nand 2010s, these “open registries” ballooned from 4% to 60% of ships. The 1994\nUnited Nations Convention on the Law of the Sea specifies that there should be a\n“genuine link” between the ship and its flag; however, twenty-five years later\nthe interpretation of that phrase is still a subject of debate.\n\nThe same sort of reasoning is why corporations like to incorporate in Delaware.\nThe state first began to adapt its tax laws in the late nineteenth century,\nmaking changes to attract businesses from larger, more prosperous states like\nNew York. Delaware became an “onshore” tax haven for US companies, not only\nbecause of the ease of doing business, but also because of the “Delaware\nLoophole”: the state collects zero tax on income relating to intangible assets\nheld by a Delaware holding company. This allows companies to shift royalties and\nsimilar revenues from where they actually do business to holding companies in\nDelaware, where they are not taxed. But this means a loss of millions of dollars\nfor states in which corporations are actually operating. This loophole costs the\nother forty-nine states approximately $1 billion a year.\n\nThe hack here isn’t that companies register their ships in Panama or incorporate\nin Delaware. The hack lies in those jurisdictions’ deliberate exploitation of\nthe rules governing jurisdiction in order to make their own more attractive. By\npitting itself against other states, Delaware subverts the intent of federal\ninterstate commerce rules and state tax authorities. Similarly, flags of\nconvenience subvert the intent of the UN Convention on the Law of the Sea.\n\nThese are all examples of the hacks made possible by an organization that is\nlarger than the body that is regulating it. Corporations generally do business\nboth in and out of Delaware. Maritime shipping companies are global—much larger\nthan Panama. We’re seeing this now with the big tech companies. No public\ninstitutions possess a regulatory footprint that can match them. Companies like\nFacebook are global, yet regulations affecting them are national. Regulatory\nstructures suitable for the information age just don’t exist yet, and that\nenables companies to profit from jurisdictional arbitrage."},{"title":"Test Section Title","content":"32\n\nAdministrative Burdens\n\nSometimes a hack is the product of necessity, born of adversity and the need to\nadapt. If one tactic doesn’t work, try another. That’s the story of\nadministrative burdens. They’re a way of hacking policy. In particular, of\nhacking social benefits systems like unemployment insurance or Medicaid,\nwhich—in America—are often politically divisive. Opponents of these policies\nwill first try to simply ban them outright. But sometimes that’s not possible:\nthe votes simply aren’t there, or there’s a pesky constitutional provision in\nyour way.\n\nThat’s when people get creative. If you’re in charge of implementation, you can\nmake the law very, very difficult to follow. In other words, you can drown the\npolicy, and those trying to access it, in bureaucratic hurdles. The tactics\nvary—from long waiting times and excessive paperwork, to cumbersome filing\nsystems and repeated in-person interviews, to lousy websites—but the goal\nremains the same: to impose a burden so onerous that people otherwise eligible\nfor the benefit, many of whom are already weighed down by poverty, poor health,\nlimited education, and unstable housing, simply cannot overcome. Public-policy\nscholars Pamela Herd and Donald Moynihan have named this phenomenon\n“administrative burdens,” and it’s a policy hack.\n\nFlorida’s unemployment insurance scheme provides a good example. According to\none advisor to Governor DeSantis, its system was purposefully designed “to make\nit harder to get and keep benefits.” The entire application process was moved\nonline to a system that barely functions. A 2019 audit noted that the system\n“frequently gave incorrect error messages” and would often entirely prevent the\nsubmission of applications. The form itself is spread across multiple pages, so\nthat after entering some details, such as name and date of birth, you need to\nproceed to the next page. But often this causes the website to crash, sending\nthe applicant back to square one. On top of this, the website is only accessible\nat specific hours of the day, and requires applicants to revisit the site every\ntwo weeks to “verify their claims.”\n\nThis system caused particular pain for 4.5 million COVID-19–unemployed\nFloridians. In 2020, many people spent hours or even days trying to submit their\nclaims. According to the website, 2.4 million people were ultimately deemed\nineligible by the opaque state system, which had the follow-on effect of\nrestricting their eligibility for the CARES Act Federal Pandemic Unemployment\nCompensation.\n\nSome administrative burden stems from legitimate differences in how to implement\na policy. When you design any system that awards a benefit, you have to worry\nabout two types of error. The first is that someone deserving will not receive\nthe benefit. The second is that someone undeserving will receive it. Minimizing\none necessarily results in increasing the other. If you make it easy for people\nto apply for and obtain benefits, you’ll also inevitably make it easier for a\nshare of those who do not deserve them to slip through. And if you increase the\nvetting process to prevent the undeserving from applying for and receiving the\nbenefit, you’ll also inevitably deny some of the deserving. Depending on your\npolitics, you’ll prefer one outcome over the other.\n\nDeliberate creation of administrative burden takes this to an extreme. Instead\nof weeding out the unqualified, the burden associated with receiving the benefit\nis increased to the point where many people who should qualify simply give up.\nIt’s passive-aggressive benefit denial.\n\nWe could see this tactic used in the US around abortion, during the fifty years\nit was constitutionally legal. When states were unable to pass laws banning\nabortion outright, advocates shifted to using administrative burden to make\nabortion significantly more difficult to access, even as abortion remained\ntechnically legal. Tactics included requiring waiting periods, mandatory\ncounseling, multiple clinic visits, parental consent, and ultrasounds. The\nbiggest offender was Louisiana, which enacted eighty-nine abortion regulations\nsince 1973, including onerous licensing requirements for clinics, and rules that\ncan force their immediate closure for even the most minor paperwork violations.\nWhen the US Supreme Court ruled in 1992 that states may not “place a substantial\nobstacle in the path of a woman seeking an abortion,” the battles over the\nsubsequent thirty years shifted to defining what is or is not regarded as\nsubstantial.\n\nThere are many other examples. The Women, Infants, and Children (WIC) program is\na government nutrition program that places lengthy, detailed, and almost\ncomically complicated restrictions on exactly what foods can be purchased. For\nexample, you’re not allowed to mix brands of baby food. The administrative\nburdens are effective; less than half of families who are eligible for WIC\nbenefits receive them. The processes for applying for and receiving food stamps\nand Medicaid can be similarly hacked. Arkansas, for example, succeeded in\nkicking many people off its Medicaid rolls when it enacted a work\nrequirement—not because those people didn’t meet the work requirement, but\nbecause they couldn’t deal with the associated paperwork.\n\nAll of these are examples of the rich and powerful hacking systems to the\ndetriment of the average citizen. And the effects disproportionately hurt those\nwho lack the skills, resources, and time to overcome them.\n\nOutside of judicial intervention, it’s difficult to find a satisfactory solution\nbecause political authorities are the ones creating these administrative\nburdens. Nonetheless, one partial solution could be the use of independent\nbenchmarks or system audits by outside organizations to determine the scale and\nimpact of administrative burden. While this would not directly address the\nproblems created by administrative burden, by quantifying its impact on affected\ngroups (particularly legally protected classes) with high-quality data\ncollection, analysis, and visualization, independent audits may be able to\nconvince legislators to act or create grassroots pressure for action. Other than\nthat: I don’t know what to do."},{"title":"Test Section Title","content":"33\n\nHacking Common Law\n\nThe complex systems we’re discussing here tend to be overspecified or\nunderspecified—they’re what are known as “wicked problems.” What this means is\nthey are too complex for traditional analysis techniques. The only solutions\ntend to be iterative. But an iterative solution can be hacked, and can use hacks\nto improve itself.\n\nHacks involve contradicting a system’s rules. But those rules are often subject\nto interpretation, and those interpretations can change. To explore this, let’s\nlook at a legal system that’s designed to evolve in just this way: common law.\nCommon law is the best example—and model for the future—we have of a large\nsystem that is able to adapt through iterative hacking. It’s built into the\nsystem by design. And it’s effective.\n\nIn 1762, author and schoolmaster John Entick was suspected of writing libelous\npamphlets against the English government. Under the direction of the secretary\nof state, the king’s chief messenger and others broke into Entick’s home,\nconfiscating hundreds of charts and pamphlets as evidence. In an unprecedented\nmove, Entick sued the messengers for trespassing on his land, despite their law\nenforcement status.\n\nThis doesn’t seem like a hack now, but in 1765 it was an unintended and\nunanticipated use of trespass law. Before this case, trespass law was only used\nto prevent citizens from invading each other’s property—it did not constrain the\ngovernment. The police had a presumptive right to search an individual’s\nproperty within their law enforcement purview. Entick maintained that his\nindividual right to be secure on his property superseded that. He subverted the\nexisting norms of how the law applied. It was a progressive—even\nradical—interpretation of that law.\n\nThe English courts decided that Entick’s interpretation of the law was valid and\nsuperior. “By the laws of England, every invasion of private property, be it\never so minute, is a trespass.” The ruling in Entick’s case extended the concept\nof liability for trespass to the secretary of state and his deputies. It would\nbecome part of English common law from that date forward. Entick hacked trespass\nlaw. He advanced an interpretation that logically followed from the words of the\nlaw but was unintended and unanticipated. The court allowed the hack and\nenshrined it in law. Entick became a landmark case in establishing the civil\nliberties of individuals and limiting the scope of state power. In the United\nStates, the ideals of the Entick ruling are enshrined in the Fourth Amendment.\n\nSometimes a hack is beneficial. It might violate the intent of an existing rule\nor norm. But it doesn’t necessarily violate the greater social contract. In the\nabove example, the court decided that the social contract was enhanced by\nenabling citizens to be secure on their own property, and by not enabling the\nprivacy of their homes to be violated by anyone for any reason. While a hack\nbenefits the hacker at the expense of another part of the system, sometimes that\nexpense is minimal. If a hack falls within the spirit of the social contract,\nthen it becomes an innovation that the system would benefit from absorbing.\n\nIn these cases, no singular governing body makes that decision—just many courts\ntrying to reconcile many interpretations of many precedents to apply to new\nhacks as they emerge. The rules are a complicated, incomplete, and sometimes\ncontradictory mess. They’re not designed for a purpose in the same way that\nordinary legislation is. They’re iterative, and they evolve. They’re added to by\nmany different people, each with their own goals for the overall system. In\nsystems governed by multitudes, we need a different sort of mechanism for\nadjudicating challenges and subversions of the status quo. This is basically how\ncommon law works.\n\nA quick definition: common law is law derived from judicial decisions in the\nform of legal precedents. It’s different from statutory law, which is passed by\nlegislatures, and regulatory law, which is established by government agencies.\nCommon law is more flexible than statutory law. It allows for consistency across\ntime, but can also evolve as judges reapply, analogize, and transform past\nprecedents to fit new circumstances. That evolution is basically a series of\nadjudicated hacks that are either declared illegal or that become future\nprecedent.\n\nTake patent law. It’s based on statutory law, but the details are largely\nprovided by judge-made rules. And it’s complicated. Patents can be worth\nbillions, and lawsuits are common. Because there’s so much money at stake, hacks\nof the system abound. I’ll just give one example: patent injunctions. The idea\nwith patent injunctions is that someone whose patent is being infringed on can\nobtain a quick injunction preventing that infringement until the court issues a\nfinal ruling. Until 2006, they were easy to get. As a result, they became a\ngo-to anticompetition hack for large companies, particularly tech companies.\nPatent injunctions were used to compel smaller competitors to either stop\nselling their products or to pay exorbitant fees to the patent holder (a\npractice that many likened to extortion).\n\nThe patent injunction hack was adjudicated when MercExchange, a technology and\nonline auction company, sued eBay, claiming that eBay was violating MercExchange\npatents in its online auction system. The US Supreme Court took up the case in\n2006, rewriting the rules on patent injunction, patching the vulnerability by\nordering courts to apply a more rigorous, four-factor check when deciding when\nan injunction is merited.\n\nLaws are never complete. Grey areas, blind spots, or null spaces become evident\nwith time and social change. Just as with legislation, loopholes, omissions, or\nmistakes can occur in either statutory law or common law. Someone twists the\nexisting set of laws to fit into those spaces, in ways that were unintended and\nunanticipated by the law’s creators, in order to gain some advantage. Then,\nsomeone else—generally someone who is put at a corresponding disadvantage\nbecause of the hack—challenges the hack in court. A judge is called upon to act\nas a neutral arbiter and to decide whether the hack is legitimate or\nillegitimate. If it is illegitimate, it’s declared illegal—and that effectively\npatches the system. If it’s legitimate, it becomes part of common law and is\nhenceforth legal. Common law is inherently a hack of the adjudication system.\nAnd its decisions, relying on creative applications and reinterpretations of\nbroad precedents and principles, are themselves a kind of social hack to resolve\nthe otherwise unresolvable.\n\nHacking is how law adapts to new circumstances, new developments, and new\ntechnologies. No one in the legal profession calls it hacking, but that’s\nbasically what it is. Common law is nothing but a series of hacks and\nadjudications. It’s the best system we have of harnessing the power of hacking\nto continually improve the law. Hacking is how the law adapts over time.\n\nHere’s another example. During the Middle Ages, when landowners in England left\nto fight in the Crusades, often a landowner would transfer the title of his real\nproperty to someone he trusted. The idea was that while he was away, his deputy\ncould care for his property and ensure that any continuing obligations, like\nfeudal payments, were met. It didn’t always end well. Sometimes when the\ncrusader returned, his former friend would refuse to transfer the title back to\nhim. This was a hack of the law: selling the property was not the crusader’s\nintent.\n\nTo resolve the matter, aggrieved crusaders petitioned the lord chancellor and\nhis Court of Chancery. His solution—which patched the vulnerability—was to\ncreate a new right. In his conception, there could be two owners of a given\nproperty: the legal owner—the person on the title—and the equitable owner—the\nperson who, in all fairness (that is, equity), owned the land. The equitable\nowner enjoyed the benefits of the property, like using the land. In this case,\nthe legal owner was the crusader and the equitable owner was the caretaker. It\nwas an easy patch: the incentives of the key stakeholders were aligned. Nobility\nwanted to preserve their property rights, and returning crusaders were a\npowerful and sympathetic petitioning group.\n\nToday, this same division of rights persists in many common law countries. In\nthe US, a division still exists between matters of law and matters of equity.\nThis division allows for trusts as a financial structure. Basically, someone\nelse owns the trust (and the assets it holds), while you, the “real” owner and\nbeneficiary, are entitled to the fruits of those assets (for example, monetary\ndistributions)."},{"title":"Test Section Title","content":"34\n\nHacking as Evolution\n\nOrthodox Jews are masters at hacking their religious rules. Work is prohibited\non Shabbat, the Jewish Sabbath that runs from Friday evening to Saturday\nevening. Work includes lighting a fire, which has been extended to include\ncreating a light of any kind, or doing anything that requires electricity.\nGrowing up, my cousins had a timer attached to the television’s power cord. The\ntimer would turn the television on and off automatically—no human action\nrequired—so the only debate was what single channel to set the TV to before\nsundown on Friday. Carrying things in public is prohibited, which means you\ncan’t carry a house key with you when you go out. But if that key is integrated\ninto a wearable piece of jewelry, then you can take it with you.\n\nSince carrying things in your own home is permitted, some communities will run\nan unbroken piece of wire called an eruv around an entire neighborhood, which\nhacks ancient definitions of semiprivate common areas and redefines “home” to\ninclude everything inside that wire boundary line.\n\nNon-Jews are not subject to the same rules. In my synagogue growing up, a\nGentile custodian was deliberately hired so he could do things on Shabbat that\nthe Jews could not. It’s forbidden to ask for help directly, though. While you\ncan’t ask “Can you turn up the thermostat?” you can say “It’s a little cold in\nhere.” Similarly, an observant Jew can’t walk into an elevator and ask “Can you\npush five for me?” but he can wonder aloud, “Is five pushed?” Many elevators in\nthe religious parts of Israel just automatically stop on every floor on Shabbat.\n\nWhen I was a kid, these sorts of ways of precisely following the letter of the\nrules to avoid their spirit felt contrived. But they’re really the method by\nwhich the 2,000-year-old Jewish law has adapted over the centuries to modern\ntimes. It’s hacking and—more importantly—the integration of those hacks into our\never-evolving society.\n\nHacking is about finding novel failure modes that have not yet been exploited.\nWhen they actually work, they have unexpected outcomes.\n\nThis is important. Hacking isn’t just malicious manipulation inflicted upon a\nsystem. A successful hack changes the hacked system, even more so as it is\nrepeatedly used and becomes popular. It changes how the system works, either\nbecause the system gets patched to prevent it or expands to encompass it.\nHacking is a process by which those who use a system change it for the better,\nin response to new technology, new ideas, and new ways of looking at the world.\nThis is hacking as evolution. We saw that with modern banking, high-frequency\ntrading, luxury real estate, and—probably—much of what the gig economy companies\nare doing. And it continues. Today, there’s a Bluetooth device that makes a\nsmartphone usable on Shabbat. The hack is that the buttons constantly have a\nsmall current running through them, so pressing them does not close a\ncircuit—which makes it permissible under Jewish law.\n\nHarnessed well, hacking is a way of accelerating system evolution by\nincorporating an adversary in the process. Harnessed for ill, hacking can be a\nway of accelerating system destruction by exposing and exploiting its flaws for\nselfish gain in a way that tears it apart.\n\nInnovation is essential if systems are to survive. An ossified system can’t\nrespond to hacks, and therefore has trouble evolving. Political scientist\nFrancis Fukuyama makes this argument when he theorizes that both states and\ninstitutions are developed to respond to particular environmental conditions,\nand fail or are conquered by others because they can’t evolve when the\nenvironment changes. (He used the Ottoman Empire as an example.) Contemporary\npolitical science research suggests that when conservative groups representing\nthe rich and powerful refuse to allow their societies to evolve, they can break\ntheir political systems as a whole.\n\nThis disruptive power can also be harnessed by those at the bottom of our power\nstructure and serve as an engine for social change. It’s how revolutions happen.\nHacking is one of the weapons of the weak, and an important one at that.\n\nHere’s one example: people are hacking the notion of corporate personhood in\nattempts to win rights for nature, or great apes, or rivers. The very concept of\ncorporate personhood is a hack of the Fourteenth Amendment, which lays out the\nrules of citizenship and the rights of citizens.\n\nIn Darwinian evolution, Mother Nature decides which hacks stay and which hacks\ngo. She can be cold and brutal, but she doesn’t play favorites. In social system\nevolution, the powerful are the favorites, and often get to decide which hacks\nstay and go. If this isn’t fixed, then allowing hacks to drive evolution of\nsystems will perpetuate status quo injustices. The future of social hacking has\nto combine the push to evolve with a focus on the greater good—or we’ll see our\nsocial systems begin to break down. And then it’s hacking as revolution.\n\nMaybe a better metaphor for hacking is that of an invasive species. Different\nspecies evolve in specific environments, balanced with respect to predators,\nprey, environment, and other factors. When a species is transported from one\nenvironment to another, it can often take advantage of differences in novel and\nsurprising ways. Maybe the predator that used to keep it in check is not in the\nnew environment, and nothing else takes its place (such as the Burmese python in\nFlorida). Or maybe an environmental factor that limited its growth is not there\n(such as cold weather for kudzu, the Scourge of the South). Or maybe a new food\nsource is unnaturally—for that species—abundant (as is the case for the ravenous\nAsian carp). The result is that the invasive species is able to multiply at a\nheretofore unseen rate. Hacks are like that. They’re discontinuous jumps in\ncapability, introduced into an ecosystem that isn’t prepared for it. The\ninvasive species could die out, if the ecosystem happens to deploy the right\ndefenses. But it could also overwhelm the system. The catastrophic end-state is\ncalled “ecosystem collapse,” when a hack is so devastating that it destroys the\nentire ecosystem."},{"title":"Test Section Title","content":"PART 5\n\n\n\nHACKING POLITICAL SYSTEMS"},{"title":"Test Section Title","content":"35\n\nHidden Provisions in Legislation\n\nWhen the Russian SVR hacked into the SolarWinds company and slipped a backdoor\ninto an Orion software update, 17,000 or so Orion users installed that corrupted\nupdate and inadvertently gave the SVR access to their networks. That’s a lot of\nvulnerable networks, and it’s inconceivable that the SVR would try to penetrate\nthem all. Instead, it chose carefully from its cornucopia of vulnerable victims\nto find the most valuable prospects.\n\nThis is known as a “supply chain attack,” because the SVR didn’t attack any of\nthose networks directly. Instead, it attacked a software system that all of\nthose networks used. Supply chain attacks are a clever way to attack systems,\nbecause they can affect thousands at once. Other examples of this kind of attack\ninclude hacking the Google Play store to include a fake app, or intercepting\nnetwork equipment in the mail to install eavesdropping capabilities (the NSA has\ndone that one).\n\nWe can think of hacking the legislative process in the same way. In the previous\nchapters, we’ve considered how hackers find and exploit vulnerabilities in laws\nafter they’re passed. Hackers can also target the legislative process itself.\nAnd like the hacked update to the Orion network management software, hackers can\ndeliberately insert vulnerabilities into pending legislation and take advantage\nof them if the legislation is passed into law.\n\nIn a way, we’re taking the hacks we’ve been discussing and moving them up a\nlevel. Instead of finding vulnerabilities in laws and regulations, these hacks\nare against the very process of creating those laws and regulations. Powerful\nhackers can do this.\n\nThis isn’t just hacking a system, it’s hacking the means to patch the system.\n\nLoopholes are common in law, but most of them don’t qualify as hacks. They’re\ndeliberate exceptions to a more general rule, created to support a particular\npolicy goal, to appease particular constituents, or as a compromise to appease\nother legislators. Examples include a 2004 law, lobbied for by Starbucks, that\ncounts roasting coffee beans as domestic manufacturing or, on a more general\nlevel, antitrust exemptions for “natural monopolies” for industries that require\ncoordination between different companies, like sports leagues. These are not\nunintended and unanticipated. They’re not based on ways to outsmart the system\nof creating, debating, and passing legislation. As such, they are not hacks.\n\nThis doesn’t mean that the legislative process that creates these loopholes\nisn’t hacked all the time. All it takes is for someone to add a strategically\nworded sentence to a bill. That sentence might refer to several other laws, and\nthe interplay of those laws might result in a specific outcome, unknown to and\nunanticipated by everyone else.\n\nAn entire industry of lobbyists is dedicated to engineering such unanticipated\noutcomes on behalf of their moneyed sponsors. In 2017, during the drafting\nprocess for the Tax Cuts and Jobs Act, over half of the lobbyists in Washington,\nDC, disclosed that they worked solely on tax issues. That was over 6,000\nlobbyists, more than 11 for every member of Congress.\n\nFor example, a 2013 debt deal passed by Congress included the following\nsentence: “SEC. 145. Subsection (b) of section 163 of Public 5 Law 111-242, as\namended, is further amended by striking “2013–2014” and inserting “2015–2016.”\nThat seemingly innocuous provision, inserted by Senator Tom Harkin, functioned\nas a hidden gift for Teach For America. Basically, that sentence extended by two\nyears another piece of legislation that benefited students still in teacher\ntraining programs, including Teach For America recruits.\n\nIn 2020, Congress passed the $2 trillion CARES Act, a COVID-19 stimulus bill. On\npage 203 of the 880-page bill, there was a change in how real estate investors\ncould offset their losses. This tax break profited real estate moguls, such as\nthen president Donald Trump, $17 billion annually—$17 billion in potential tax\nrevenue. It didn’t matter that the provision had nothing to do with COVID-19, or\nthat the retroactive tax break covered a period long before COVID-19 arrived.\nSpeed and stealth aided in sneaking this passage through. The text of that bill\nwas finalized less than an hour before the vote, and Republican staffers added\nthe provision at the last second to the final text of the bill.\n\nThe vulnerability lies in the fact that bills are so long and so complicated,\nand contain so many provisions without clear and obvious effects. The exploit\nlies in the act of slipping a provision into the bill in such a way that\nlegislators don’t notice. We like to think that this sort of chicanery requires\nthe complicity of a member of Congress who might or might not anticipate the\neffects of his or her contribution to the bill, but it’s also possible for a\nstaffer to do it without anyone else realizing it—or even for a lobbyist to\ncraft wording that ends up being used.\n\nThis kind of thing is so common it hardly qualifies as a hack anymore. Over the\npast several decades, power has been increasingly centralized in the hands of\npolitical party leaders in each chamber and away from legislative committees,\nwhich has facilitated this cloistered and opaque legislative process. This state\nof affairs, combined with Congress passing a smaller number of larger bills when\ncompared with past congressional sessions, provides ample opportunity for the\nenactment of hidden provisions that benefit favored individuals and industries.\nIt was even the plot of a Simpsons episode, where Krusty the Clown gets elected\nto Congress and sneaks a change to the air traffic control law into a bill\ngiving flags to orphans.\n\nFixing all of this isn’t easy. Even though legal language is analogous to\ncomputer code, the processes by which the two are created and used are very\ndifferent. Computer code is written by a group of people following an overall\nplan, generally under the direction of a single company or individual. These\nprogrammers know what their code is supposed to do, when it doesn’t do that, and\nwhen it can’t do that. And they alone have the authority to fix bugs in their\ncode.\n\nLaw isn’t like that. It’s decentralized at every level. In a democracy, law is\nwritten by many different competitors. They have different goals and different\nopinions about what the law is supposed to do. A bug to one is a feature to\nanother, even if everyone knew exactly what they were voting for throughout the\nentire process.\n\nHidden provisions, and the vulnerabilities that they represent, would be less of\nan issue if House and Senate rules mandated a certain amount of review time for\nbills once the text was finalized and published, perhaps proportionate to the\nlength of the bill. Hidden provisions are no longer “hidden” if they’re\ndiscovered and scrutinized by a robust media, and then publicized in enough time\nto spur change or extract a political cost. By providing representatives with\nsome reasonable minimum amount of time to review and demand amendments to\nhigh-profile bills, there’s at least some chance to uncover hidden provisions\nthat wouldn’t pass muster otherwise.\n\nAs part of its ninety-seven recommendations for streamlining the US House, the\n2019 Select Committee on the Modernization of Congress proposed that it\n“finalize a new system that allows the American people to easily track how\namendments change legislation and the impact of proposed legislation to current\nlaw.” Basically, it’s proposing a Track Changes system for legislation, one that\nexpands upon an earlier “Comparative Print Project.”\n\nThe goal would be to make it easier to see and understand legislative changes,\nwhich could make it easier to detect hidden provisions. This certainly won’t fix\nthe problem, especially because the committee is only proposing expansion of\naccess to “all House offices,” but it would be a step in the right direction. If\nmade available to the public and combined with measures that ensured adequate\nlegislative review time, this could be even more potent.\n\nSufficient time isn’t enough; we need to also offer incentives for people to\ndiscover hidden provisions. Taking a page from software vulnerabilities, we\ncould all benefit from the legislative equivalent of a bug bounty system,\nwhereby citizens could be rewarded for discovering vulnerabilities in pending\nlegislation. The most obvious place for this kind of thing would be laws with\ntax implications; the bounty could be a very small percentage of the expected\ntax revenue.\n\nAlternatively, bills could benefit from red-teaming exercises, in which\nspecialized teams (playing the role of private companies or wealthy elites)\nattempt to “hack” the pending legislation and discover previously unknown\nvulnerabilities.\n\nWhile both of these exercises could be valuable, they run into a core issue with\nmodern legislation: namely, that bills are often put together in secret by a\nrelatively small number of legislators and lobbyists, and many of the loopholes\nare intentionally crafted. Imagine that a red team finds a vulnerability in a\ntax bill. Is that a bug or is it a feature? Who gets to decide? And on what\nbasis? Further, many bills are quickly passed by Congress once unveiled, making\nit impossible for anyone to read and understand every line; red-teaming would\nonly be feasible if sufficient time were afforded to engage in it and act upon\nthe findings.\n\nFor example, the 2017 Tax Cuts and Jobs Act was voted on only hours after the\nfinal language was made available to legislators. This was deliberate; the\nauthors didn’t want professional staff to have adequate time to review the bill\nwith any thoroughness. Similarly, the CARES Act was released at 2:00 pm on\nDecember 21, 2020. Even though the bill ran 5,593 pages, it was passed in the\nHouse around 9:00 pm and in the Senate by midnight. The measure contained $110\nbillion in lightly scrutinized “tax extenders,” and a permanent cut in excise\ntaxes for “producers of beer, wine, and distilled spirits.” Many lawmakers were\nunaware of the many tax loopholes it contained.\n\nWe may have to wait for AIs, which operate at computer speed, to read,\nunderstand, and identify hacks before the laws are enacted. That would certainly\nhelp solve the problem—although it would equally certainly create new ones."},{"title":"Test Section Title","content":"36\n\nMust-Pass Legislation\n\nSome bills are simply more important than others. Appropriation bills or bills\nthat respond to external forces, like natural disasters, pandemics, or security\nthreats, are often considered must-pass legislation. These bills provide an\nopportunity for legislators to attach policy changes, known as riders, that\nwould never float on their own. Maybe they are unpopular, against the public\ninterest, skewed to benefit special interests, or are the result of political\nwheeling and dealing.\n\nPlacing non-germane riders on these must-pass pieces of legislation enables\nlawmakers to avoid the scrutiny or backlash that would accompany a vote for a\npolitically difficult provision, credibly claiming that they were merely voting\nfor the measure as a whole. This now-common hack subverts the way legislation is\nsupposed to work: a discrete proposal is made for a new law, and then that\nproposal is voted on.\n\nThree examples:\n\n•Between 1982 and 1984, a series of riders—called the Boland amendment—were\nadded to several must-pass appropriations bills; the amendment limited US\nassistance to the Contras in Nicaragua.\n\n•In 2016, an agriculture and food spending bill included a rider that prohibited\nthe FDA from regulating “large and premium cigars.”\n\n•In 2021, lawmakers attached three intellectual property copyright bills to the\ncompletely unrelated Consolidated Appropriations Act. These measures had\nlanguished on their own in the face of widespread protests from tech enthusiasts\nand technology companies but were enacted when attached to a far larger, more\ncomplex, must-pass bill.\n\nThis sort of hack exploits the fact that the president can’t veto individual\nline items in a bill. He eithers vetoes the entire bill or accepts it in full,\nwith any and all riders included. It also exploits the congressional committee\nprocess. The full legislature cannot vote on a bill unless it’s been approved by\nthe relevant committees. This means committee members can simply tack riders\nonto legislation, either openly or in secret.\n\nAttempts to curtail the practice have largely been ineffective. Congress\nattempted to give President Clinton a line-item veto power in 1996, but it was\ndeclared unconstitutional in 1998. It was utilized eighty-two times in its\none-year run, and the suit against it was brought, in part, by a group of potato\ngrowers who objected to Clinton vetoing a rider that benefited them.\n\nIn the case of modular computer code, each independent segment performs a single\nfunction, a structure that can make programs more resilient, maintainable, and\ndiagnosable. Legislation that similarly deals with fewer discrete issues would\nbe less susceptible to the sort of hacking I’ve just described. This is the\nlogic behind single-subject laws and constitutional provisions, which mandate\nthat laws must deal with only one primary issue. Such a bill, called the One\nSubject at a Time Act in 2021, has been regularly proposed in Congress but never\npassed into law.\n\nAt the state level, efforts to limit non-germane riders have been somewhat more\neffective. Forty-three state constitutions require each individual piece of\nlegislation to be limited to a single subject. Minnesota’s constitution states:\n“Laws to embrace only one subject. No law shall embrace more than one subject,\nwhich shall be expressed in its title.” However, even these restrictions can\nprove remarkably hackable. As Columbia University law professor Richard\nBriffault wrote, “Whether a measure consists of one subject or many will\nfrequently be ‘in the eye of the beholder.’ ” On the one hand, as the Michigan\nSupreme Court explained, “There is virtually no statute that could not be\nsubdivided and enacted as several bills.” On the other hand, as an older\nPennsylvania Supreme Court case put it, “No two subjects are so wide apart that\nthey may not be brought into a common focus, if the point of view be carried\nback far enough.”\n\nAnother defense is system resilience. Must-pass legislation is particularly\nvulnerable to riders because of the extreme negative consequences associated\nwith non-passage of the parent legislation. However, some of these consequences,\nsuch as a government shutdown from non-passage of appropriations bills, are\ntotally artificial and could be ameliorated with good policy. For instance,\nseveral organizations have proposed that Congress increase the resilience of\ngovernment operations by creating a process for automatic continuing\nresolutions. Under an automatic continuing resolution, government funding would\ncontinue at comparable levels if Congress failed to pass a regular\nappropriations bill. By reducing the consequences of delayed action on must-pass\nlegislation, this reform would make it easier for rider opponents to vote down\nthe budget bill until the rider is removed."},{"title":"Test Section Title","content":"37\n\nDelegating and Delaying Legislation\n\nIn the years after the Cold War ended, Congress was faced with the unwelcome\nprospect of closing military bases around the country—not an easy task. Those\nbases represented hundreds, even thousands of jobs, and no legislator would ever\nagree to closing a base in their home district. Instead of making the hard\ndecisions, Congress came up with a hack to depoliticize the process. It\ndelegated its lawmaking power to a separate, external body by establishing a\nBase Realignment and Closure Commission. That commission was empowered to decide\nwhich bases to close or scale back, and its recommendations would automatically\ntake effect unless Congress did something to overrule it. It worked; there have\nbeen five such commissions since 1988, resulting in the closure of more than 350\nmilitary installations.\n\nThis hack enables Congress to resolve difficult or politically controversial\nissues without actually having to decide anything itself. It reduces the extent\nto which partisanship skews decisions regarding base closures. It also allows\nCongress to circumvent burdensome rules and processes that might otherwise slow\nthe decision down.\n\nIt’s not used often. In 2010, Congress formed the Independent Payment Advisory\nBoard (IPAB), which was supposed to cut Medicare spending. Normally, changes in\nMedicare require an act of Congress to take effect. Congress authorized this\nboard to make changes that could only be overruled by a congressional\nsupermajority. Again, avoiding the responsibility to craft and pass an actual\nMedicare cost-cutting vote was the intent. Unlike the base-closing commission,\nthis one never completed its work. Thanks to medical service providers’\nopposition to the law, and the smearing of IPAB by politicians such as former\nvice presidential candidate Sarah Palin, Congress never appointed any members,\ninstead repealing IPAB in 2018 after five unstaffed years.\n\nA similar hack is a “title-only bill,” which is basically an empty shell. It has\nno substantive content, but lawmakers in the state of Washington introduce a\nbunch of them each session. They’re placeholders, just in case lawmakers want to\ncircumvent legislative rules and deadlines later in the year. In the final days\nof the 2019 legislative session, Democrats used a title-only bill to pass a bank\ntax with minimal public oversight and debate.\n\nMore generally, this hack is part of a larger class of legislative delegations\nto the executive branch. For many, the “administrative state” and the extensive\nrule-making authority granted to the executive branch by the legislative branch\nrepresent an unbalanced hack of the legislative system. And this is a hack\nthat’s used regularly. In the US, between 3,000 and 4,000 new administrative\nrules are finalized each year, dwarfing congressional output. And while much of\nthis is simply the effect of an increasingly dysfunctional Congress ceding power\nto relatively efficient federal agencies, some of it is a result of members of\nCongress not wanting to be on the record as supporting or opposing various laws.\n\nFixes aren’t apparent or easy. If the legislative branch feels, at any time,\nthat the executive branch has overstepped its regulatory authority or pursued\nimprudent goals, it could pass a law adjusting the scope of its delegated\nauthorities or countermanding the action. Some legal scholars think Congress\nshould do just that. Others think the US Supreme Court should put a stop to the\npractice.\n\nAside from abrogating their legislative responsibility, legislators can also\nrefuse to hold votes. The filibuster is an obstructionist tactic in which a\nlegislator delivers a lengthy speech in order to prevent a timely vote on a\nproposal or bill and thereby block its passage. It is perhaps most famously\npracticed in the US Senate, but has also been used as a tactic in legislatures\naround the world, from the UK and Canada, to Austria and the Philippines.\n\nTo be fair, filibustering isn’t a new hack. It dates back to 60 BCE, when Roman\nsenator Cato the Younger deliberately gave interminable speeches in order to\ndelay voting. Since the Roman Senate had to conclude all business by dusk, the\nbody couldn’t vote if he refused to be silent. Cato managed to do this for six\nmonths, which is a lot of talking.\n\nThe filibuster is only possible in the US because of a vulnerability in the\nrules that was an accidental side effect of another legislative rule change.\nBack in 1805, Vice President Aaron Burr declared that the US Senate should not\nhave too many procedural rules. One of the rules dropped on his\nrecommendation—in 1806, after he left office—was the “motion to previous\nquestion,” which ended debate on legislation. It took until 1837 for someone to\nnotice and exploit the vulnerability. This was patched in 1917 with the cloture\nrule ending debate, which meant that a filibuster required nonstop talking to\nsustain. The current three-fifths majority—or sixty senators—requirement was\nonly added in 1975, and the talking requirement was eliminated. It’s a hack on\ntop of a patch on top of a hack, and it can only be changed by another hack.\n\nThe filibuster subverts the legislative system. A legislative body is supposed\nto preserve the minority’s right to be heard, while still respecting majority\nrule. However, the modern filibuster flips that on its head, because now the\nminority party can use the filibuster to halt the legislative process for any\nbill without a sixty-vote majority, which actually prevents meaningful\nconsideration or debate of an issue. It’s also bad for the rights of minorities\nin society, not just the minority party in the Senate. Historically, the\nfilibuster was most often used to block legislation advancing racial equality.\n\nIn the US, this is now normal. The Senate has such relaxed rules that a senator\ndoesn’t have to actually speak for days or months to filibuster; he or she can\nsimply state a theoretical intention to do so in order to delay a vote. But back\nin 60 BCE, it was certainly unanticipated and unintended by whoever created the\nrules of the Roman Senate. Obstructive speechifying was a subversion of those\nrules, designed to prevent the very thing that the Senate was there to do: vote\non legislation.\n\nThe filibuster isn’t the only legislative delaying tactic. In the UK, House of\nCommons members can move that the House of Commons meet in secret. It’s intended\nfor matters of national security, but has been misused as a delaying tactic—most\nrecently in 2001. In the Japanese Diet, the tactic of “ox walking” means walking\nthrough the voting lobbies extremely slowly—enough to delay the entire voting\nprocess. Deployed strategically, it can result in a bill being shelved until the\nnext legislative session. In Italy, a 2016 constitutional reform bill in\nparliament had 84 million—not a typo—amendments inserted in an attempt to delay\nvoting on it.\n\nWhether these sorts of hacks are good or bad depends on whether you think the\nmain purpose of the governance system is providing political accountability or\ndelivering impartial, efficient policy decisions. If you think government should\nonly act when it has clear supermajority support or extensive deliberation, then\nthese delaying tactics might be good if minority parties can use them to get a\nseat at the negotiating table. If you think government should be more active and\nrespond to pressing policy challenges quickly while facing the voters’ judgment\nlater, then adding ways for minority parties to effectively veto legislation is\nvery bad indeed.\n\nSolutions range from patching the underlying system so that the hack is no\nlonger possible—eliminating the filibuster in the US case—to making it a more\ncostly hack to implement, and therefore less frequently used. Right now,\nsustaining a filibuster is easy: no one needs to talk on the Senate floor for\nhours or days on end, they just need to declare their intent to filibuster a\nmotion. Because it’s incumbent on the majority to find sixty votes to break the\nfilibuster, it’s far harder to break a filibuster than it is to keep one going.\nI’ve heard suggestions for several possible reforms, but the most exciting\noption comes from Norm Ornstein at the American Enterprise Institute, who argues\nfor flipping the equation. Instead of requiring sixty votes to end a filibuster,\nthe rules would require forty votes to sustain it. The idea here is that the\nmajority could keep the Senate in session around the clock for days or weeks.\nAnd the minority needs be present and alert, sleeping near the Senate floor,\nready to vote on a moment’s notice."},{"title":"Test Section Title","content":"38\n\nThe Context of a Hack\n\nWhat I am developing is a sophisticated notion of hacking. It’s not that hacks\nare necessarily evil. It’s not even that they’re undesirable and need to be\ndefended against. It’s that we need to recognize that hacks subvert underlying\nsystems, and decide whether that subversion is harmful or beneficial.\n\nFor example, I’ve talked a lot about hacking the tax code. Most of the examples\ninvolve hackers (accountants and tax attorneys) finding inadvertent\nvulnerabilities (loopholes) in the tax code.\n\nLoose language in the American Jobs Creation Act of 2004 created several\nvulnerabilities in the tax code, which well-heeled firms were able to exploit to\ngreat effect. Most notable among these was the domestic production activities\ndeduction, which was supposed to help domestic manufacturers compete\ninternationally; it defined manufacturing so broadly—“combining or assembling\ntwo or more articles”—that all sorts of companies took the credit. World\nWrestling Entertainment claimed it for producing wrestling videos. Grocery\nstores claimed it because they spray ripening chemicals on their fruit.\nPharmacies claimed it because they had photo printing booths. A maker of gift\nbaskets claimed it because it combined wine and chocolate into a single box. The\ngovernment took that company to court over the deduction, and lost.\n\nIt’s impossible to know for sure, but this problematic wording seems to have\nbeen deliberately inserted into the law by legislators responding to lobbyist\npressures and the need to get enough congressional votes to pass it. It was just\none of the many tax breaks in that law, albeit the one that seems to have had\nthe most inadvertent effects. It was such a popular tax break that it stayed\naround until 2017, when it was replaced with the qualified business income\ndeduction.\n\nAs we’ve moved from simpler to more complex examples, it’s become harder to\ndetermine if any particular hack is good. What, exactly, is the “intent” of the\nrules of hockey, and are they furthered or impaired by curved sticks? Curved\nsticks make for a faster puck and a more exciting game. But a faster puck is\nmore dangerous, and results in more injuries. When the National Hockey League\nestablished rules specifying just how curved a stick could be, it tried to\nbalance both safety and sportsmanship considerations. And those rules have\nchanged since 1967, as the league tweaked that balance: first a\none-and-a-half-inch maximum curvature was allowed, then one inch, then half an\ninch, and currently three-quarters of an inch.\n\nIt’s even harder to determine the intent of the legislative staff who crafted\nthat overly broad tax deduction for manufacturing. Did some lobbyist hack the\nlegislative process, giving some member of Congress or that member’s underlings\ndeliberately vague language that the lobbyist knew would be abused? Did the\nmember of Congress believe corporate taxes were inherently bad and slip in\nlanguage that the member knew would be overlooked as the bill moved through\ncommittee and into debate? Was the law just poorly written?\n\nWhether or not a hack is an improvement also depends on who sits where. A clever\nentrepreneur might use a regulatory loophole for their own gain. Their customers\nmay also be happy, but the government may suffer.\n\nWe’ve defined a hack as a technique that adheres to the rules of the system but\nsubverts its intent. This isn’t always a bad thing. As we’ve seen, some hacks\nare also beneficial innovations. They end up being normalized and improving the\noverall system. In China, for example, the reformist governments of the 1980s\nand 1990s maneuvered around opposition to private ownership through hacks such\nas offering occupants seventy-year renewable leases on their land. They followed\nthe Communist Party’s rules, but completely subverted their intent.\n\nPutting any particular hack into one bucket or the other isn’t something that\nthe system can do. It has to be done by a more general, overarching governing\nsystem, because the definition of hacking depends on context.\n\nAn ATM exists within the broader context of a banking system. The rules of\nhockey exist within the broader context of the players, league, fans, and\nsociety. The examples in this book—of banking, the economy, law and legislation,\nand human psychology itself—exist within the broader context of society: our\nidentities, relationships, desires, values, and goals.\n\nThis leads to the obvious question: Who gets to define intent? Who decides\nwhether a hack is beneficial or not, or whether the subverted system is better\nor not? This can be a very complicated matter, especially in systems with\nmultiple designers, or that have evolved over time. Hacks are often beneficial\nto some and detrimental to others.\n\nAnd here are some truths about a system that cannot be understood within it, and\nthat only become clear at a higher level. All computer programs are ultimately a\ncomplex code of circuits opening and closing, representing zeroes and ones, but\nno human cares about that, and no one writes in machine code. What we care about\nare the tasks and jobs that code represents: the movie you want to watch, the\nmessage you want to send, the news and financial statements you want to read. To\nillustrate this point in the language of biology: the molecular structures and\nchemical reactions that characterize life look like incredibly complex noise\nunless you step up to the level of the organism and realize that they all serve\nthe function of keeping the organism alive.\n\nOver the past chapters, we’ve encountered many different governing bodies whose\njob it is to accomplish that adjudication. Simpler systems can have a single,\nand single-purposed, governing body. The Nevada Gaming Commission updates casino\nrules on the basis of hacks. The Fédération Internationale de l’Automobile does\nthe same for Formula One racing and the Fédération Internationale de Football\nAssociation for soccer.\n\nDo hacks subvert the intent of the systems? Or do they actually further it? What\nis the intent of these systems, anyway? The answer (and there is no one answer)\nisn’t simply a matter of analyzing the hack and the system; your answer will\ndepend on your morals, ethics, and political beliefs. There will be reasonable\ndifferences of opinion about whether any of these hacks should be normalized or\nnot. In the end, what matters is who benefits and who loses. That, too, is\npolitically contested. So there’s a debate, and maybe a vote. And money and\npower influence both.\n\nHere’s an example. In 2020, President Trump wanted to appoint retired Army Brig.\nGen. Anthony Tata to the position of under secretary of defense for policy,\nwhich requires US Senate confirmation. When it became clear that the Senate\nwould never confirm him, Trump withdrew his nomination and instead designated\nhim as the official “performing the duties of” the deputy under secretary of\ndefense for policy. He also repeatedly used the term “acting” to circumvent\nSenate confirmation. These are hacks of the 1998 Vacancies Reform Act. But are\nthey a flagrant disregard of reasonable Senate oversight duties or a reasonable\nresponse to the overly broad requirement that the Senate confirm 1,200 different\nexecutive positions? It depends on your opinion on how government should work."},{"title":"Test Section Title","content":"39\n\nHacking Voting Eligibility\n\nThere are many ways to cheat in an election. Stuffing ballot boxes, fiddling\nwith the vote tallies: history, both old and recent, has many examples. But\noften the best way to manipulate election results isn’t to cheat directly, it’s\nto hack the process. Like markets and legislative processes, democracy is based\non information, choice, and agency. All three can be, and are, hacked. That is,\nhackers can subvert the intent of democratic elections by tweaking the rules.\n\nIf you don’t vote, you don’t matter. This is why many hacks interfere with voter\nagency.\n\nRatified in 1870 after the end of the Civil War, the Fifteenth Amendment made it\nillegal to deny the vote to men based on race, color, or previous status as a\nslave. (Women still couldn’t vote or hold office.) Soon after, Black men brought\ntheir increasing influence to bear in elections, and started being elected to\npublic office. This outraged Southern whites and the formerly slaveholding\npolitical elite, who promptly began hacking the election process to limit the\nvoting rights and political power of newly enfranchised African American men.\n(They also used a lot of tactics that weren’t hacks, such as violence and\nmurder, to accomplish this goal.)\n\nIn Alabama, for example, a coalition of conservative Democrats calling\nthemselves “Redeemers” seized power in an 1874 election marked by fraud and\nparamilitary violence. (Not a hack.) Over the next thirty years, they gradually\nchipped away at African Americans’ political influence through carefully\ntargeted voting restrictions. These efforts culminated in the ratification of a\nnew state constitution in 1901, in which the stated goal of its drafters was “to\nestablish white supremacy in this state.” The constitution introduced or\nentrenched poll taxes, property ownership requirements, literacy tests, and\nvarious disqualifications that limited the number of African Americans entitled\nto vote. (That’s the hack.) It worked; in the early 1870s, over 140,000 African\nAmericans were eligible to vote. In 1903, fewer than 3,000 were able to\nregister.\n\n“Literacy test” is a misnomer. Literacy tests in this context were not tests of\nreading ability, they were complex tests designed so that people would\ninevitably fail them. We can argue about their constitutionality, but the hack\npart was giving local election officials substantial leeway to determine which\nprospective voters were required to pass this impossible test. This allowed\nvoting officials to selectively deny the franchise at will. The 1964 Louisiana\nliteracy test is an example that can be easily found online. One question—yes,\nthis is real—“Write every other word in this first line and print every third\nword in same line, [original type smaller, and the first line ended at comma]\nbut capitalize the fifth word that you write.”\n\nFast-forward to today. Alabama still employs a variety of voter-suppression\ntactics to limit the participation of felons, minorities, immigrants, and rural\nvoters in the election system. Alabama’s barriers to voting rights begin with\nregistration. The state doesn’t offer electronic voter registration,\nregistration in DMV offices, automatic voter registration, election day\nregistration, or any sort of preregistration for coming-of-age voters. State law\nrequires people to show proof of citizenship in order to register. This law has\nnot been implemented because of an ongoing federal investigation, but if allowed\nto stand, it will have the effect of denying the vote disproportionately to\nminority citizens, who often don’t have passports or other documentation. Kansas\nhas turned away thousands of new voters from the polls using a similar rule.\n\nHistorically, most felons were disqualified from voting in Alabama. This policy,\ntoo, served disproportionately to disenfranchise minorities. The hack consisted\nof the “Black Codes” implemented by many Southern states that categorized\nrelatively trivial offenses (think cattle theft) as felonies. African Americans\nconvicted of these crimes would be forever disenfranchised. In 2017, Alabama’s\nlegislature repealed that law, providing almost 60,000 citizens with a pathway\nto restoring their right to vote. But the secretary of state hasn’t gone to the\ntrouble of publicizing the policy, so many felons remain unaware of their\nrights. And even those felons who are aware of their rights face substantial\ndifficulties actualizing them, because of administrative difficulties and a poor\nunderstanding of the law by state and local officials.\n\nPeople can also be denied the right to vote by removing their names from the\nvoting rolls without their knowledge. The common manner in which this is applied\nis to remove those who haven’t voted in recent elections. This works because\ninactive voters are unlikely to return to the polls before the voter rolls are\npurged. Alabama has removed 658,000 infrequent voters from its voter rolls since\n2015.\n\nThese are all the sorts of administrative burdens first touched on in Chapter\n32. They don’t generally have much impact on people with money and status. But\nfor citizens with fewer resources or time to spare, who are disabled, or who are\nnew to the political process, rules like these make it much more difficult to\nexercise the franchise. All too often, people make a sincere attempt to navigate\nthese rules, fail to do so, and are then unable to vote. More often than not,\nthese rules limit election participation by poorer people and minorities, who\noften lean towards the Democratic Party. As a result of these hacks, only 69% of\nvoting-age Alabamians are registered to vote."},{"title":"Test Section Title","content":"40\n\nOther Election Hacks\n\nAnother hack of agency centers on the voting process itself. Basically, the idea\nis to make voting so difficult for eligible, registered voters who aren’t\nsupporting your candidate that they won’t bother to come to the polls. Many of\nthese examples can also be classified as administrative burdens.\n\nImmediately after the Fifteenth Amendment was ratified, Southern states enacted\nvoting restrictions that didn’t specifically mention race, but that nonetheless\npredominantly affected Black Americans. These included poll taxes that the\npoorest couldn’t afford to pay; rules that only enfranchised people whose\ngrandfathers were qualified to vote before the Civil War; and—as previously\nmentioned—devilishly designed, selectively administered, capriciously judged\nliteracy tests. Several of these hacks were only banned after passage of the\nTwenty-Fourth Amendment (which was ratified in 1964), the 1965 Voting Rights\nAct, and the 1966 US Supreme Court ruling in South Carolina v. Katzenbach. After\nkey parts of the Voting Rights Act were struck down by the Supreme Court in\n2015, these tactics returned, most commonly in the form of voter ID laws.\n\nIn Alabama, for example, potential voters must present a state-issued photo ID\nor be turned away from the polls. Seemingly a simple requirement, it doesn’t\nplay out so simply in Alabama. Close to 25% of eligible voters live over ten\nmiles from a Department of Motor Vehicles (DMV) office, and many don’t own a\ncar. These are poorer citizens in the state, and they disproportionately reside\nin minority communities. State authorities then tried to close thirty-one DMV\noffices (which issue both driver’s licenses and non-driver identification\ncards); the offices on the chopping block were all located in the six counties\nwhere African Americans composed over 70% of the population. After the US\nDepartment of Transportation objected, this plan was eventually rejected. Still,\nover 100,000 Alabama residents of voting age don’t have acceptable IDs for\nvoting—tellingly, while the figure represents a little less than 3% of Alabama’s\ntotal voting-age population, it represents more than 10% of the African American\nvoting-age population.\n\nThere can be a legitimate difference of opinion about the necessity of\nimplementing an administrative hurdle, and the relative balance between allowing\neveryone authorized to receive a benefit and preventing anyone unauthorized from\nreceiving it. Yes, there is value to ensure that only eligible voters vote. But\nwith the actual incidence of election fraud so low (a matter that has been\nabundantly established in courts across the country), it’s pretty clear that the\nmeasures described above are primarily aimed at preventing eligible voters from\nbeing able to vote.\n\nFinally, people can be denied the right to vote by the lack of polling places\nnear their homes. Alabama has been closing polling places since 2013, often in\nAfrican American neighborhoods. For example, the city of Daphne (population\n28,000) downsized from five to two polling places in 2016, and the three\nstations removed were all located in predominantly African American areas of\ntown.\n\nI don’t have to pick on Alabama in these chapters. Other states are just as\naggressive in voter suppression, and are becoming increasingly so. Georgia, for\nexample, also enforces voter ID and proof of citizenship requirements, voter\nroll purges, reductions in early voting, and polling place closures concentrated\nin African American communities. (Don’t even ask me about Florida.) And today,\nnew measures are being enacted all over the country to try to suppress young\nvoters, especially idealistic college students who are often assumed to veer\ntowards the Democratic Party.\n\nGerrymandering isn’t a new hack. The word comes from Massachusetts governor—and\nDeclaration of Independence signer—Elbridge Gerry, who enacted a bill in 1812\nthat created a state senate district in Boston that was shaped like a salamander\nand was engineered to consolidate and strengthen the Federalist vote and\nfracture the Democratic-Republican vote. The basic idea is that if you can\ncontrol the proportions of different voters in voting districts, you can\ninfluence who wins and thereby dominate the overall representation in a\nmultidistrict legislative body. You engineer the demographics so that your party\nwins many districts by a small percentage—let’s say 10%—and the other party wins\nas few districts as possible by a high percentage: say 90%.\n\nThere are two ways to gerrymander. The first is to “pack” a district to include\nas many of the opposing party’s voters as possible. That helps the governing\nparty win neighboring districts where the opposition’s strength has been\ndiluted. The second is to “crack” a district by splitting up clusters of\nopposition voters among several districts, so that they will be outnumbered in\neach district.\n\nThe basic problem is conflict of interest: the legislators who are in charge of\ndrawing the districts are the ones who benefit from their demographics. The\nsolution, obvious to anyone who studies the issue, is compartmentalization.\nDistricts should be drawn by independent commissions whose members have no stake\nin their outcome. Michigan, for example, approved a ballot initiative mandating\nexactly this in 2018. That the state’s Republicans were still fighting this\ncommission in 2020 illustrates the power of the gerrymandering hack.\n\nBeyond questions of how and in what district citizens vote, there are countless\nlevers policymakers can use to hack and skew the electoral process. Public\nofficials often have discretion on scheduling elections, recording and\nrecounting of votes, and which candidates and propositions are allowed on the\nballot. In territories where they exist, election commissions can even\ndisqualify candidates for failing to file on time, having insufficient support,\nor other technical issues. Using these powers selectively is the hack.\n\nOne final tactic: In 2018, Wisconsin governor Scott Walker simply refused to\ncall a special election for state legislative seats, fearing that they would be\nwon by Democrats. He was eventually ordered to conduct the election by a federal\nappellate court judge. Governors in Florida and Michigan have also tried this\nhack. In 2018, Stacey Abrams narrowly lost a Georgia gubernatorial election to\nBrian Kemp, who oversaw the election at the time as secretary of state, and\npurged the rolls of half a million registered voters just before the election."},{"title":"Test Section Title","content":"41\n\nMoney in Politics\n\nMoney can control information and choice. Money can buy agency: the power to\nmake change. These are all political hacks because they subvert the intent of\nthe democratic voting process. This is especially true in the US, where\nelections are unnaturally expensive.\n\nThe reasons are complicated, but I’ll list four basic ones. One, US election\ncycles are long; candidates begin to campaign over a year before the election\nitself. (Comparatively, Japanese campaigns last twelve days from start to\nfinish, and French campaigns two weeks. UK elections come after an average of\ntwo to four weeks of campaigning. No Australian or Canadian campaign season has\never exceeded eleven weeks—and that extreme occurred only in 1910 and 1926.)\nTwo, US party discipline is weaker than in other countries. Where party\ndiscipline is strong, it makes less sense to bankroll specific candidates and\npit them against each other in primaries. Three, the US is a large country with\na large population, expensive television advertising markets, and—as opposed to\nother countries—no limits on campaign spending. And four, the US has enough\nloopholes in its contribution disclosure laws to reduce the political\naccountability of those who accept inappropriate campaign contributions (such as\nby non-US citizens).\n\nThere is enormous incentive to hack the systems that regulate campaign\nfinancing, and for candidates to use their campaign coffers to hack the\npolitical process itself.\n\nMany wealthy people like these hacks and have worked to make them legal, since\nthey proportionally increase their political influence. After passage of the\nFederal Election Campaign Act of 1972 and its 1974 amendments that limited\ncontributions and expenditures, a 1976 ruling excluded money spent to support a\nparty or candidate but not in coordination with the party or candidate. This led\nto the rise of “soft money” spent on “party building” activities, which often\nended up being political attack ads against the other party’s candidates. Over\nthe years, various wealthy individuals and groups slowly challenged the limits\nof campaign financing rules. This was curtailed in 2002 by the Bipartisan\nCampaign Reform Act. But more rules brought more hacks. Then the 2010 Citizens\nUnited decision, affirmed by a 2014 US Supreme Court ruling, reopened the door\nto allow all sorts of formerly forbidden money in politics, including\ncontributions from corporations.\n\nTo be sure, money doesn’t guarantee political success, but the lack of it nearly\nalways guarantees political failure. As Harvard law professor Lawrence Lessig\nargues, “To be able to run in the voting election, one must do extremely well in\nthe money election.” Money can keep candidates alive in a lengthy political\nprocess like the US presidential primary system. We saw this in the 2012\nRepublican primary, where billionaires Sheldon Adelson, Foster Friess, and Jon\nHuntsman Sr. had an enormous influence on the process by singlehandedly funding\ncandidates when few others would. It’s kind of like a venture capital system for\npolitics. You don’t need to be among the best and brightest, you just need to\nconvince some wealthy investors that your candidacy is a good bet.\n\nMoney can also help sow chaos. The US has a de facto two-party system, so one\nhack is to fund an independent or third-party candidate that will siphon votes\nfrom your opponent. If you’re a Republican, you might fund some unaffiliated\nliberal upstart to compete against and thereby undermine the front-running\nDemocrat in that race. If you’re a Democrat, you might fund some independent\nconservative candidate to split the Republican vote.\n\nIn the US, the “independent spoiler” hack is a hard one to pull off, because\nboth parties have an interest in patching this particular vulnerability. Some\nstates enforce very early filing deadlines that penalize candidates who enter\nthe race late, or rules that make it harder to get on the ballot if you’re not a\nDemocrat or Republican. Forty-four states have “sore loser” laws that prevent\nthe loser of a primary election from running in the general election as an\nindependent candidate.\n\nThis isn’t to say it never happens. After seeing how Ralph Nader affected the\n2000 election, Republican operatives around the country tried to take advantage\nof Green Party candidates to siphon Democratic votes. In Seattle, an\neighteen-year-old former Nader volunteer named Young Han contemplated running in\nthe 2002 state legislature race. A “Mr. Shore” helped Han organize a campaign\nannouncement and also donated to the campaign. Mr. Shore was actually a\nRepublican strategist based out of Washington, DC. His wife, similarly, was\npropping up a Green Party candidate in a Seattle county-wide race. Something\nsimilar happened in Arizona in 2010, New York in 2014, and Montana in 2018 and\n2020. Republicans helped Kanye West’s attempt to get on the 2020 presidential\nballot, hoping he would pull Democratic votes away from Joe Biden. In the end,\nall the hacks failed; this is all a lot easier in theory than it is in practice.\n\nIt’s easier if you also can add confusion. In a 2020 congressional race in\nFlorida, a “former” Republican named Alex Rodriguez ran against Florida\nDemocratic state senator Jose Rodríguez and appropriated the senator’s signature\nissue: climate change. Alex had no political background—and didn’t actually run\na campaign—but the resulting confusion gave him 3% of the vote, and Republican\nIleana Garcia won by thirty-two votes after a manual recount. Alex Rodriguez’s\ncampaign was supported by $550,000 from a recently formed company named\nProclivity, Inc., and PACs linked to Republican staffers.\n\nThe vote-splitting strategy can be taken to extremes. In India, a person with\nthe same name as a political opponent is sometimes asked to run for the same\noffice as their namesake. In a 2014 parliamentary election, for example, five of\nthe thirty-five candidates running for a particular seat were named Lakhan\nSahu—and only one of those was an actual politician with a legislative record.\nThe candidate from the major opposing party called it a “mere coincidence” that\nso many Lakhan Sahus were motivated to jump into the fray at exactly the same\ntime.\n\nIn the US, the general vulnerability is the two-party system, but vulnerability\nalso lies in the first-past-the-post winner-take-all system of elections.\nBecause we don’t require that candidates get a majority of the vote, but merely\na plurality, political candidates are less likely to win if another candidate\nhas a similar policy profile (or even a similar name) and splits the votes of\nwould-be supporters.\n\nOne fix is ranked-choice voting, in which voters rank their choices for an\noffice, the lowest-scoring candidate is eliminated, and votes for those bested\ncandidates are redistributed in sequential “runoffs” until one achieves a\nmajority. A ranked-choice system prevents third-party spoilers (a would-be\nspoiler’s votes are just reallocated to a different candidate, most likely one\nfrom whom they were intended to siphon support), and helps to ensure that the\ncandidate most acceptable to a true majority of the electorate wins the\nelection. Australia’s 2022 parliamentary elections served as a demonstration:\nmany third-party candidates received first votes that weren’t subsequently\n“wasted.”"},{"title":"Test Section Title","content":"42\n\nHacking to Destruction\n\nIn 1729, Paris had defaulted on its municipal bonds, so the government set up a\nlottery where each bond owner could buy tickets on the basis of the value of his\nbonds. Each ticket cost one-thousandth of a bond’s value, and every month the\ngovernment would select a single winner and award that person the bond’s face\nvalue plus a 500,000-livre bonus.\n\nVoltaire noticed that the payout was greater than the number of tickets in\ncirculation, so—and here’s the hack—he formed a syndicate with some wealthy\npatrons to buy up all the necessary bonds and tickets. They collected their\nwinnings month after month, and in less than two years made about 7.5 million\nfrancs: $100 million in today’s dollars.\n\nThe organizers of the Paris lottery eventually realized that many prizes were\nbeing claimed by the same few people. Voltaire, being Voltaire (and knowing that\nno good thing lasts forever, so why not have some fun), left riddles on the back\nof each ticket that made it easier for the government to track the hacker. The\nFrench finance minister took the syndicate to court, but since they had done\nnothing illegal, they were allowed to keep their winnings. The Parisian\ngovernment then canceled the lottery—an effective defense, albeit an extreme\none.\n\nMore recently, Ohio built a website through which employers could report\nemployees who refused to work during the COVID-19 pandemic, so that they\nwouldn’t receive unemployment benefits. A hacker realized that there was no\nauthentication in the reporting process; anyone could submit a report. So he\nwrote a program that automatically submitted fake reports—even defeating the\nCAPTCHA—and posted it online. We don’t know how many of these were filed by the\nonline system, and Ohio government officials claimed that they had been able to\nweed them out, but the state ended up abandoning the plan to use the reports to\nkick people off the unemployment rolls.\n\nBack in Chapter 10, I said that hacks are parasitical. Like any parasite, a hack\nmust balance the subversion of a system with its destruction. Too much hacking,\nand the system collapses. Sometimes, as with the Paris lottery, the system is\nabolished as the result of the hack being just too successful. Other times, as\nwith the Ohio unemployment reporting website, the goal of the hacker is to shut\ndown the system.\n\nFinancially motivated hackers tend not to want to destroy the systems they’re\nhacking. If there are too many ATM hacks, the machines will disappear. If a\nsport is hacked to the point where it’s no fun to play or watch, it will wither\nand die. Those hackers fundamentally want to maintain the system they’re\nhacking, but create better outcomes for themselves. If they destroy the system,\nit’s generally incidental and accidental.\n\nThis isn’t necessarily true when the hackers are following some moral or ethical\nprecept. They’re hacking the system because they don’t like the system, not\nbecause they want to profit from it. Like the Ohio unemployment website hacker,\ntheir goal is to reduce its functionality, undermine its efficacy, or destroy\nit. We saw another example of this in 2020, when TikTok users coordinated to\nsubmit fake ticket requests to a Trump campaign rally in Tulsa, in order to\nengineer an arena full of no-shows. It was a basic hack, exploiting the fact\nthat all it took to reserve a ticket was an easily obtained dummy email address\nand a dummy phone number care of Google Voice. The ticketing system wasn’t\nultimately destroyed, but the low audience turnout embarrassed Trump, and the\ncampaign switched to other, less vulnerable, ticketing systems.\n\nWhatever the motivation, hacking can destroy social systems on a much larger\nscale than that of Voltaire’s lottery, Trump’s ticketing system, or Ohio’s\nunemployment benefits. We saw hints of that in the 2008 banking crisis, where\nrepeated hacks of the system almost brought down the entire US financial\nnetwork. We’re seeing hints of it with money in US politics and with political\nmisinformation and social networks. And it happens in political revolutions,\nwhen all the mechanisms of society are hacked for a wildly different intent. So\nwhile hacking can be a good thing, and necessary for system evolution, there can\nbe too much of it too quickly.\n\nTake another economic example: printing paper money. Paper money is at least as\nold as the eleventh century Sung Dynasty in China, and it’s a hack. Currency is\nsupposed to represent some real amount of economic value, but today, most\ngovernments have the power to print as much currency as they want, regardless of\nhow much the economy is actually producing. This means governments can hack\npublic financing systems by creating enough new money to pay off their bills,\nrather than funding programs through taxes or debt to private investors. In\nEurope, this hack was first devised by economist John Law to help Louis XV of\nFrance pay for his wars.\n\nThis is an example of a beneficial, and now normal, hack. The ability to print\nmoney can be essential during economic crises. It’s how the US government funded\nthe interventions that calmed markets in 2008–2009, and limited the economic\nfallout from the pandemic and lockdowns in 2020. And it’s part of how the US\ngovernment funded massive military mobilizations that helped to win World Wars I\nand II.\n\nBut when governments become reliant on printing money to service foreign debt,\nthings can go really bad. While hyperinflation is rare, it can cause incredible\ndamage incredibly quickly. When Zimbabwe experienced hyperinflation in 2007, the\nZimbabwean dollar lost more than 99.9% of its value over a single year, locals’\naverage wealth fell below 1954 levels, and the amount of money that could once\nbuy twelve cars wasn’t enough to pay for a single loaf of bread. In Venezuela,\nhyperinflation began in 2017 and eventually pushed prices so high that the\naverage family would need more than 100 times the minimum wage to pay for bare\nessentials, leading more than 10% of the country’s population to emigrate.\n\nOther examples of hacking to destruction come from the recent rise of\nauthoritarian governments around the world, in countries like Russia, Syria,\nTurkey, the Philippines, Hungary, Poland, Brazil, and Egypt. Elections are still\nheld and votes are still counted. Legislatures still pass laws, and courts\nenforce them. Rights to free speech and association often remain on the books,\nat least formally. But all of those mechanisms and institutions have been\nhacked—subverted to serve the needs of the dictatorship.\n\nConversely, some systems need to be hacked in order to be destroyed. Boycotts,\nand civil disobedience in general, are hacks: they subvert the rules of markets\nand politics as usual in order to protest unjust practices. The backlash they\nprovoke makes the implicit violence and cruelty of systems explicit, shifting\nthe political agenda to destroy systems such as overtly discriminatory laws that\nwere long accepted as “normal” and ignored. The challenge we face is making sure\nour hacks destroy the bad while leaving the good . . . and knowing which is\nwhich."},{"title":"Test Section Title","content":"PART 6\n\n\n\nHACKING COGNITIVE SYSTEMS"},{"title":"Test Section Title","content":"43\n\nCognitive Hacks\n\nHere’s a hack I used regularly to save money on flights back in the 1990s when\nwe were all still using paper tickets. Obtaining a paper boarding pass was a\nseparate action from buying the ticket, you could get it weeks in advance, and\nyou had to talk with an actual human to do that.\n\nI was living in Washington, DC, and flying a lot for work. I had reason to spend\nweekends in Chicago, but work wouldn’t pay for the expensive stopover. But I had\na hack. Say I had a ticket from Seattle to DC for Sunday, with a change in\nChicago. First I would to go the airline’s ticket office and get printed\nboarding passes, which the agent stapled to my tickets. I would remove and hide\nthose, and on another day return to the ticket office and change both flights to\nFriday—itinerary changes were inexpensive back then. The agent would make the\nchange in the computer and issue me a new pair of boarding passes, again stapled\nto that same ticket. I would then fly Seattle-to-Chicago on Friday, as I was\nsupposed to, then spend the weekend in Chicago. Back at the airport on Sunday, I\nwould go to my Chicago-to-DC gate with the original ticket and boarding pass\n(which I’d saved). Even though I wasn’t in the computer with a reservation, I\nhad a properly dated ticket and a proper boarding pass—and the ticket and\nboarding pass from Sunday’s Seattle-to-Chicago flight to show if anyone asked.\nConfused, the gate agent would override whatever the computer was telling him,\nissue a new boarding pass, and let me on the plane.\n\nIt was a great hack, and it worked until the airlines moved to e-tickets and\nditched the separate boarding passes. But what exactly was I hacking? It wasn’t\nthe airline reservation system. The computer clearly said that I didn’t have a\nreservation for the flight. What I was really hacking was the gate agent\nhimself. I was a confident white male business traveler with a proper-looking\nticket and boarding pass in hand. The problem could be attributed to a computer\nscrewup, or so the gate agent conveniently assumed. It might sound weird to say\nthis, but I hacked the gate agent’s mind.\n\nOur brain is a system, evolved over millions of years to keep us alive and—more\nimportantly, from our genes’ point of view—to keep us reproducing. It’s been\noptimized through continual interaction with the environment. But it’s been\noptimized for humans who lived in small family groups in the East African\nhighlands 100,000 years ago. It’s not as well suited for twenty-first-century\nNew York or Tokyo or Delhi. And the human brain can be manipulated because it\nengages in many cognitive shortcuts to accommodate our modern social\nenvironment.\n\nIt’s fairly simplistic to talk about how human biological, psychological, and\nsocial systems “naturally” work, then claim that a hack subverts their intent.\nThey occur naturally and unplanned. Even so, doing that can provide a useful\nframework for discussion. We can refer to the “purpose” or “intent” of\nbiological and psychological systems—the purpose of the pancreas, the purpose of\nour sense of trust—without having to invoke anything other than evolutionary\nprocesses. (Kind of like our economic or political systems, which also lack a\nsingular designer.) Hacks creatively undermine those systems. Like all of the\nhacks of human-created systems, cognitive hacks exploit a vulnerability in order\nto subvert the intent of cognitive systems.\n\nCognitive hacking is powerful. Many of the societal systems our society relies\non—democracy, market economics, and so on—depend on humans making rational\ndecisions. In the previous chapters, we’ve seen hack after hack that\nsuccessfully limited one of the three aspects of that: information, choice, and\nagency. In these upcoming chapters, we’ll see them hacked directly—in our own\nminds.\n\nFor example, disinformation is a hack that subverts our system of freedom of\nspeech and freedom of the press. This isn’t a new notion. Goebbels, Hitler’s\npropaganda minister, once said: “This will always remain one of the best jokes\nof democracy, that it gave its deadly enemies the means by which it was\ndestroyed.” Disinformation is also a hack that subverts many of the cognitive\nsystems we will talk about: attention, persuasion, trust, authority, tribalism,\nand sometimes fear.\n\nUnlike other hacks, cognitive hacks lie at a higher level of generality. In\nfact, they are the most general hacks of all. While laws govern basically all\neconomic transactions and many other areas of society, legislatures and courts\ngovern the creation and revision of laws, and a nation’s constitution (or\nsimilar document) establishes the legislative process and the court system. But\nour social systems—and all technological systems, insofar as they interact with\nhuman users—rely on people thinking or, more often, using cognitive shortcuts to\nmuddle through. If you can hack a mind, you can hack any system that is governed\nby human action.\n\nCognitive hacks are as old as our species, and many were normalized so long ago\nthat we don’t even think twice about them—let alone think of them as hacks.\nBecause humans are intelligent and conscious, because we have a theory of mind\nand an ability to plan far into the future, we have taken hacking to a level of\nsophistication beyond any other creature in the natural world. And, like many of\nthe hacks in the previous chapters, cognitive hacks tend to target the\ninformation, choice, or agency humans need so they can make deliberative and\neffective decisions.\n\nWhat has changed over the past half-century is the extent to which computers and\ncomputer interfaces provide greater opportunities to manipulate the perceptions\nof others. Combined with computer algorithms and behavioral science, they change\nthe speed and sophistication of mind-meddling, and those differences in degree\nlead to differences in kind.\n\nNot always, though. Writer and activist Cory Doctorow cautions us from blindly\nbelieving “the thesis that Big Tech used Big Data to create a mind-control ray\nto sell us fidget spinners.” At best, what I’ll be talking about in the next few\nchapters are cognitive nudges that push us one way or the other to varying\ndegrees. But I think we need to be equally reluctant to ignore these techniques.\nPaired with AI, they’re going to get more effective.\n\nPatching generally doesn’t work with cognitive systems, although conscious\nawareness of a hack is itself a patch. Security against cognitive hacks requires\nprevention and damage mitigation. Many con games work by hacking our emotions of\ngreed, trust, fear, and so on. There’s no way to patch our brains, but we can\nuse a different system to declare specific hacks illegal—that is, outside the\nbounds of acceptable social behavior—and educate potential victims on how to\navoid them.\n\nOne more caveat: hacks of cognitive systems aren’t as cleanly delineated as the\nhacks described in previous chapters. For example, consider the various webpage\ninterface design tricks that the Trump campaign used to trick people into\ndonating far more money than they had intended, and for purposes other than\npolitical campaigning: pre-checked boxes authorizing recurring weekly\nwithdrawals from a donor’s checking or credit card account, donation amounts\nhidden in small print, more small print stating that the donation could be used\nfor the candidate’s personal expenses, and the like. These are clearly hacks:\nthey’re examples of a “dark pattern” that we’ll talk about later. But are they\nhacks of our perceptual, emotional, or executive decision-making systems? The\nanswer is, kind of all three. I’m okay with this ambiguity. Humans are\ncomplicated. Cognitive systems are messy. Any discussion of them will be messy\nas well."},{"title":"Test Section Title","content":"44\n\nAttention and Addiction\n\nEveryone hates pop-up ads. Even their inventor, Ethan Zuckerman, has publicly\napologized for creating them. But they have proliferated because they are\nprofitable, and they are profitable because they successfully hack the attention\nof enough people to increase advertisers’ sales.\n\nUnlike banner ads, which we are generally able to tune out, pop-up ads force you\nto devote at least grudging attention to them, even if only to swat them away.\nThey usually appear right in front of you, blocking whatever you were actually\nwatching. Many include images, sounds, and video. You have to take action to\nclose them—and sometimes that action is hard to figure out, or takes several\ntries to accomplish. And they work. Holding our attention, even for a relatively\nshort period of time, can have a long-term effect.\n\nAs a cognitive system, attention enables us to focus on important things. At any\ngiven time, countless events are occurring around and within us. Although our\nbrains are powerful, their processing capacity is limited. We can’t pay\nattention to everything.\n\nGiven this limitation, we deploy attention selectively. We prioritize things and\nevents that promote our survival, and pay less attention to things we already\ntrust. Our attention is most readily captured by phenomena that could indicate\nthe presence of a predator or other threat: sudden movements, loud noises,\nbright lights. We also prioritize phenomena that affect our social survival,\nlike our security and position within a group, or phenomena that involve\nattracting and maintaining sexual partners. Similarly, we generally focus our\nattention on phenomena that promote our well-being and our level of comfort.\nThat’s why anything that gives us a reward—whether that be food, money, drugs, a\nKinder Egg prize, or even a “like” on our digital profile—will capture our\nattention. We can’t always consciously choose how or where we focus our\nattention, because so much of the attentional system is hardwired into our\nbrains.\n\nAdvertising doesn’t naturally capture our attention, so advertisers have to hack\nour cognitive systems. In the 1860s, French lithographer Jules Chéret invented a\nnew form of advertising poster: bright, contrasting colors, beautiful\nhalf-dressed women, scenes in motion—all impossible to ignore. Later, Leonetto\nCappiello helped to promote all manner of consumer products with stunning,\nlarger-than-life images specifically designed to be recognized at high speed by\npassengers on the newly built Paris Metro.\n\nAdvertisers are always looking to hack our attention more effectively. It’s why\nsupermarkets, and even stores like Staples and Bed Bath & Beyond, stock candy in\nthe checkout aisles, a hack known as “point-of-purchase placement.” It’s also\nwhy television commercials used to be slightly louder than the shows they\npunctuated, until the FCC banned the practice in 2012. And it’s why we have\npop-up ads.\n\nWhile data-driven endeavors took off with the market research and\npsychology-driven campaigns of the 1950s (and onward), contemporary ad campaigns\ncan use microtargeting to hack each of us personally. In doing so, advertisers\nand data brokers amass and monetize vast hoards of personal information,\nthreatening our personal privacy in an attempt to better capture our attention.\n\nOne more hack of our attention circuits that occurs on modern social networks:\nmanufacturing outrage. Facebook uses algorithms to optimize your feed. Its goal\nis to keep you on the platform—the more you’re on Facebook, the more ads you\nsee, and the more money the company makes—so it tries to show you content that\nengages you on which to display ads. (Don’t forget this: the whole point of\nthese systems is to sell advertising, whose whole point is to manipulate you\ninto making purchases.)\n\nSimilarly, Google wants to keep you watching YouTube videos. (YouTube is a\nGoogle subsidiary.) The YouTube algorithm figured out that increasingly\npolarizing and fringe content engages users. This is an unanticipated hack and\nvery profitable for Google. Facebook and YouTube are polarizing not because they\nwere originally intended to be, but because (1) the algorithm optimized itself\nto serve up ever more specialized content on the basis of a user’s interests,\nand (2) management chose to disregard the potential problems that this created.\nApplied to politics, such schemes tend to polarize users by making it easier for\nthem to occupy an ideological bubble with others who share their worldview, and\nby prioritizing material that provokes the most excitement. By accelerating and\nfine-tuning the task of finding and displaying specialized, polarizing content,\nautomated content recommendation systems reduce the less filtered interactions\nthat force us to consider and reconsider our beliefs and opinions.\n\nOne solution to the advertising part of this problem is to regulate the\ninformation utilized by advertisers for microtargeting. After the 2020 election,\nGoogle implemented a policy in which it decided to limit the targeting of\nelection ads to general categories: age, gender, and location at the postal code\nlevel. These sorts of simple defenses are likely to be effective—assuming, of\ncourse, that Google sticks with them. Members of both parties will do their best\nto subvert them, though, as microtargeting has become essential to modern\npolitics.\n\nA better solution is to enforce antitrust laws. With so much content in one\nplace, this sort of hyper-specialization becomes both easy and problematic. In\ncontrast, a proliferation of smaller social media sites—each with less\ncontent—would limit the amount of specialization that’s possible. Note that the\nhyperconservative social media sites that sprang up when Donald Trump was banned\nfrom Twitter have nowhere near the power that the large multinational social\nmedia companies do.\n\nThe logical extreme of attention hacking is addiction, the most effective form\nof lock-in there is. The hack isn’t the physiological process of addiction, but\nthe process of getting someone addicted. By designing their products to be\naddictive, manufacturers and developers ensure that their customers and users\ncontinue to use them. Sometimes the addition is physiological, but most of the\ntime it starts as a behavioral fixation, then becomes entrenched with the help\nof endorphins, adrenaline, and other neurochemicals that the behavior elicits.\n\nThe basic methodology of behavioral addiction is nicely illustrated with a slot\nmachine. We know that variable rewards are more addictive than fixed rewards,\nand by its nature gambling provides them. It’s worth going through the system in\ndetail. Step one consists of a trigger that sparks our attention. Slot machines\nare deliberately bright and noisy. They make noise when no one is using them,\nand they make a racket when someone wins. Step two consists of an action that\nbrings with it an anticipation of a reward. That’s the bet—once a coin in a\nslot, now a push of a button. Step three consists of the variable reward; you\nwin some, you lose some. Step four consists of the emotional investment, which\nincreases the player’s propensity to re-enter the loop; everyone loves a winner.\nAll it takes is another push of the button and—who knows?—there might be a\njackpot, and you might be a winner again.\n\nOnline games are getting in on the variable-reward addictive action,\nparticularly with digital goods known as “loot boxes.” Players pay—sometimes\nusing in-game currency but mostly real money—for a random assortment of in-game\nitems. Valuable items are rare, sometimes extremely rare, mimicking the\naddictive characteristics of a slot machine. Video games in general are usually\nengineered with dozens of behaviorist tweaks intended to keep players online as\nlong as possible, to the point that their addictive nature is an open secret in\nthe industry.\n\nInformation products, like smartphone apps and social networking sites, are\ndeliberately designed to work in a similar manner and become addictive. The\ntriggers are the alerts that grab our attention: beeps, dings, vibrations, push\nnotifications. (Very Pavlovian, I know.) The action is the click that brings\nwith it an anticipation of a reward. The variable rewards are the wins, posts,\ncomments, images, and whatever else appears in our feed.\n\nNone of this is accidental. Digital platforms can update and refresh their pages\nautomatically, with no user intervention, if their designers choose to do so.\nBut forcing users to click or swipe to see more posts mimics the behavior of the\nslot machine and provides an addicting smidgen of control that will habituate\nyou to do it repeatedly. Similarly, offering any sort of batch notification—show\nme all of my new notifications once per day—reduces the variable reward feature\nand its addictiveness. And that’s why this otherwise convenient, simple feature\nhas never been offered by any advertising-based social media platform.\n\nFor all of the tendency of people to regard addiction as a moral failing, it’s\nmuch better thought of as a hack—a reliable and highly effective one. We know\nthe properties that make behaviors and experiences addictive. Companies can and\ndo deploy them everywhere, often so subtly that consumers never notice. And as\nwe’ll see, algorithms and rapid testing are making digital platforms more\naddictive with less and less human intervention."},{"title":"Test Section Title","content":"45\n\nPersuasion\n\nIn 2014, bots posing as females on the Tinder dating app would text male users,\nmake trivial small talk, mention a phone game they were playing—Castle\nClash—then supply a link. As cognitive hacks go, it was kind of lame. It played\non a variety of male emotions, including trust and sexual desire, but the new\n“friend” was pretty obviously a bot if you were the least bit suspicious. We\ndon’t know how successful those accounts were at persuading people to download\nand play the game before Tinder removed them.\n\nThis sort of scam isn’t unique. Chatbots have regularly been used to manipulate\nhuman emotions and persuade people to do things for commercial and governmental\nbenefit. In 2006, the US Army deployed SGT STAR, a chatbot designed to persuade\npeople to enlist. AI and robotics technologies make efforts like these all much\nmore effective.\n\nIn the 1970s, the Federal Trade Commission asked advertising executives to\nexplain marketing to them. Before then, they had a pretty basic view of the\nindustry, that advertisements were vehicles for companies to explain the\nbenefits of their products to prospective consumers. Of course, advertising is\nmuch more than that, and today’s techniques are more about hacking cognitive\nsystems.\n\nPersuasion isn’t easy. Out of fear of manipulation or just fear of change,\npeople often resist attempts to change their minds or behavior. But despite our\nconscious and unconscious resistance, countless tricks subtly but reliably\nchange our minds. Many are deviously simple, like the “illusory truth” effect:\npeople are more likely to believe what they’ve heard repeatedly. (Yes, the Big\nLie technique works: if you repeat a lie often enough, your listeners will begin\nto believe it.) Smarter and more analytical people aren’t any better at\nresisting the illusory truth effect, either. In fact, repetitions of lies and\nhalf-truths by elites and media might actually explain the persistence of false\nbeliefs. Either way, it’s clear that simple tricks like repetition can slip\nbelow our radar and persuade us more powerfully than we might expect.\n\nDrip pricing is another example. It’s common in the airline and hotel\nindustries, since price is regularly the first attribute people look at when\nchoosing a travel service. The trick is to display a low price initially, then\npile on fees and hope that the buyer isn’t paying close attention. One study\nwith StubHub, an online ticket marketplace, showed that drip pricing resulted in\npeople spending about 21% more than they otherwise might.\n\nSome sellers use decoy prices to influence buyers. If you are choosing between\ntwo products, a cheaper one and more expensive one, you’ll try to evaluate them\non their merits—and you might select the cheaper one because the more expensive\none isn’t worth it. But if the seller adds a third decoy item, one even more\nluxurious and expensive, you’re more likely to choose the middle option.\n\nOnline, persuasion is often accomplished by means of “dark patterns.” Much user\ninterface design consists of norms and metaphors that we humans use to make\nsense of what computers do under the hood. The metaphors are just that: files,\nfolders, and directories are all to some extent abstractions and\nrepresentations. And they’re not always accurate. When we move a file into a\nfolder, we’re not actually moving anything, just changing a pointer designating\nwhere the file is stored. Deleting a file isn’t the same thing as destroying the\nphysical object, something that criminal defendants learn over and over again as\nfiles they thought they’d deleted are recovered and used against them by\nprosecutors. But they’re close enough for most purposes. And the norms are taken\nfrom the real world as much as possible.\n\n“Dark patterns” is a term given to subversive user-design tricks that co-opt\ncommon designs to nudge users towards certain ends. Normally, standardized\ndesign guides us through our interactions online; it’s a visual language that we\ntrust. In habitual behaviors like driving, for example, green means go, and red\nmeans stop. Those same colors are similarly used as guides in user experience\ndesign all the time. They become a dark pattern when a series of green\n“continue” buttons is suddenly subverted to sell an in-app purchase, as in the\nmobile game “Two Dots.” Or when ads for other software place a green “click here\nto download” button as they interrupt a series of “continue” buttons in a\nsequence of webpages. Way too often those buttons get you something other than\nwhat you’re expecting—you have to be constantly vigilant.\n\nIntuit has a free tax-filing program called Free File, but it’s intentionally\nhard to find, and tries to trick users into paying for the tax-filing features\nin its TurboTax product. (A 2022 multistate plea agreement forced Intuit to pay\n$141 million in restitution over this; we’ll see if it changes Intuit’s future\nbehavior in any meaningful way.) A banner ad from a company called Chatmost has\nwhat looks like a speck of dust on a touchscreen, tricking users into clicking\non the ad as they try to swipe away the dirty spot.\n\nIn 2019, US senators Mark Warner and Deb Fischer introduced legislation banning\ndark patterns. It didn’t pass. But if a future version does, the sponsors had\nbetter get their definition right, because that definition itself will be\nsubject to all sorts of hacks, as programmers and apps that use dark patterns to\nhack us try to get around the rules."},{"title":"Test Section Title","content":"46\n\nTrust and Authority\n\nOn March 19, 2016, John Podesta, then chair of Senator Hillary Clinton’s\npresidential campaign, received an email purporting to come from Google. It was\na security alert, and included a link to what looked like a Google log-in page.\nPodesta entered his credentials on the page, which wasn’t Google at all. It was\nactually run by the GRU, the Russian military intelligence agency. Once\noperatives on the other side of the screen had Podesta’s Gmail password, they\ngrabbed at least 20,000 of his old emails—then sent them to WikiLeaks to\npublish. This was a social engineering hack.\n\nSocial engineering is a common way to hack computer systems. Basically, it\ninvolves convincing someone with some specialized access to a system to use it\nin a way that they shouldn’t. Over twenty years ago, I wrote “Only amateurs\nattack machines; professionals target people.” It’s still true today, and much\nof it relies on hacking trust.\n\nOne social engineering attack involves calling a cell phone tech-support line,\npretending to be someone else, and convincing the operator to transfer that\nperson’s cell phone number to a phone that you control. This is known as SIM\nswapping, and is a particularly nasty attack because controlling your phone\nnumber is a gateway to a variety of other frauds—and often results in losses in\nthe thousands of dollars. One victim lost $24 million; aggregate losses are\nhuge.\n\nThere are a gazillion variations on social engineering. They can involve\ntelephoning an employee—that’s how the 2020 Twitter hackers were able to access\nthe company’s network and take over 130 accounts—and they can also involve\nemail. “Phishing” is the term for sending fake emails trying to entice the\nrecipient to click on a link, open an attachment, or otherwise do something that\nmight compromise the recipient’s computer or bank account. They’re not that\neffective; mostly their perpetrators cast a wide net and necessarily keep their\nappeals fairly generic. “Spear phishing” is the term used when these emails are\npersonalized. It takes a lot of research to craft a persuasive message, but it\ncan be a very effective hacking technique. Podesta fell for it. So did former\nsecretary of state Colin Powell.\n\nIn Chapter 12, I discussed business email compromise. A hacker gains access to\nthe email account of a company executive, then writes to a subordinate something\nlike: “Hi. I’m Mr. CEO. Yes, this is unusual, but I’m traveling and don’t have\nmy normal network access. I need you to transfer $20 million to this foreign\naccount right now. It’s important. A big deal depends on this. I’ll send you the\nvarious forms when I’m back in my hotel.” Depending on how good the hacker is at\nmaking the details plausible, how distracted and trusting the employee is, and\nhow this all fits into whatever situation is actually going on, it can be a very\nsuccessful fraud. Toyota lost $37 million to this scam in 2019, one of many\nvictims, big and small.\n\nIn 2015, Syrian agents posing as beautiful women on Skype were used to steal\nbattle plans from gullible rebels, as well as the identities and personal\ndetails of senior leaders. Russian agents have used this same tactic to try to\nglean classified information from US service members.\n\nTechnology is making this kind of chicanery easier. Criminals are now using\ndeep-fake technology to commit social engineering attacks. In 2019, the CEO of a\nUK energy company was tricked into wiring €220,000 to an account because he\nthought the chief executive of his parent company was telling him to do so in a\nphone call and then in an email. That hack only used fake audio, but video is\nnext. Already one scam artist has used a silicone mask to record videos and\ntrick people into wiring him millions of dollars.\n\nThis kind of fraud can have geopolitical effects, too. Researchers have produced\ndeep-fake videos of politicians saying things they didn’t say and doing things\nthey didn’t do. In 2022, a video of Ukrainian president Volodymyr Zelenskyy\ntelling Ukrainian troops to surrender to their Russian invaders was debunked by\nZelenskyy himself. Although the video was of poor quality, and easily identified\nas a fraud, it is inevitable that these will get better with time and\ntechnological advancement.\n\nThe very existence of such technology is enough to degrade our trust in audio\nand video in general. In 2019, a video of Gabon’s long-missing president Ali\nBongo, who was believed to be in poor health or already dead, was labeled as a\ndeep fake by his opponents and served as the trigger for an unsuccessful coup by\nthe Gabonese military. It was a real video, but how could a non-expert be sure\nwhat was true?\n\nCombine these techniques with existing and near-future AI technologies that\nenable bots to produce realistic text—essays, messages, and conversations—and we\nwill soon have some very persuasive technologies that hack our perception of\nwhat is and isn’t human.\n\nWe saw this sort of fakery in action in the 2016 US presidential election.\nBuzzFeed found 140 fake news websites with American-sounding domain names and\nsensationalistic headlines that got high traction on Facebook. That marked the\nbeginning of a plethora of newly hatched websites disguised as authoritative\nsources of information. Domain names like BostonTribune.com, KMT11.com, and\nABCNews.com.co looked official and tricked many readers into believing their\ncontent. Sites like The Tennessee Star, the Arizona Monitor, and the Maine\nExaminer were designed to look like traditional newspapers, but instead\ndelivered partisan propaganda.\n\nMany historical indicators of trust no longer work. Print books and television\nnews were both seen as authoritative, because the publishing and broadcast\nindustries acted as gatekeepers. That sort of naive trust doesn’t translate well\nto the Internet. Now anyone can publish anything as a book. It’s still hard to\nfake a paper newspaper, but it’s easy for a website to mimic a trusted\nnewspaper. An impressive bank building used to send a message of solvency and\ntrustworthiness; now it’s easy to have that iconography on a website.\n\nI can offer more examples of trust hacking. “Sponsored content” matches the form\nand function of the platform that features it but is in fact paid advertising.\n(Most platforms do, however, identify sponsored content as such at the beginning\nof an article.) Customer reviews, now ubiquitous on Internet commerce sites, may\nappear authentic but are easily faked. People routinely claimed false or dubious\nprofessional credentials: goons pretending to be immigration authorities in\norder to extort money from recent newcomers, mail-order PhDs pretending to be\nmedical doctors in order to hawk quack remedies, fraudsters pretending to be tax\nauthorities in order to gain access to honest taxpayers’ computers and\npasswords.\n\nOne final thing: our cognitive systems of trust are based on trusting\nindividuals. We’re not hardwired to evaluate the trustworthiness of\norganizations, brands, corporations, and the like. Hence the lovable mascot and\ncelebrity endorsement; advertisers have been giving brands a human face and\ntriggering all of our cognitive trust systems for decades.\n\nBrands have even acquired distinct social media personalities, from the\nfast-food chain Wendy’s Twitter persona as a sarcastic troll to Amazon’s furious\npushback on critics in government, all to mimic intimacy and gain trust in the\nsame manner that influencers and politicians do. As businesses and political\nmovements increasingly employ AI to optimize their social media presence—and\ngrow tempted to make and run fake accounts to create perceptions of grassroots\nsupport—even cynics and skeptics may soon have their trust hacked as they never\nhave before."},{"title":"Test Section Title","content":"47\n\nFear and Risk\n\nOur human sense of fear is innate; it evolved over millennia as our ancestors\nlearned how to evade predators who wanted to turn us into food and—more\nrecently—members of our own species who wanted to harm us for their own\nadvantage. Like the systems of attention we just reviewed, our fear system\nconsists of cognitive shortcuts. It too is optimized for the circumstances of\nour evolutionary past.\n\nThese are very basic brain functions, largely controlled by the amygdala in the\nbrain stem. Our brains aren’t very good at probability and risk analysis. We\ntend to exaggerate spectacular, strange, and rare events, and downplay ordinary,\nfamiliar, and common ones. We think rare risks are more common than they are. We\nfear them more than probability indicates we should.\n\nMany psychological researchers have sought to explain this, and one of their key\nfindings is that people react to risk more on the basis of stories than data.\nStories engage us at a visceral level, especially if they’re vivid, exciting, or\npersonally involving. A friend’s story about getting mugged in a foreign country\nis more likely to affect how safe you feel traveling to that country than will a\npage of abstract crime statistics. Novelty plus dread plus a good story equals\noverreaction.\n\nThe effects of this are everywhere. We fear being murdered, kidnapped, raped, or\nassaulted by strangers, when it’s far more likely that any perpetrator of such\noffenses will be a relative or a friend. We worry about airplane crashes and\nrampaging shooters instead of automobile crashes and domestic violence—both of\nwhich are far more common and deadly. We initially had, and some of us still\nhave, no idea how to react to the risks of COVID-19, which are individually\nsmall, collectively huge, extremely sensitive to small changes in social\nconditions, and continually mutating.\n\nTerrorism directly hacks these cognitive shortcuts. As an actual risk, it’s\nminor. The 9/11 attacks killed about 3,000 people, and about 300 more have died\nfrom terrorist attacks in the US in the two decades since then. On the other\nhand, 38,000 people die every year in car accidents; that’s about 750,000 deaths\nin the same span of time. Over a million people died in the US from COVID-19.\nBut terrorism is designed to override any logic. It’s horrifying, vivid,\nspectacular, random, and malicious: the very things that cause us to exaggerate\nrisk and overreact. Fear takes hold, and we make security trade-offs we might\nhave never considered before. These are society’s anxieties and instincts\ncollectively being hacked.\n\nPoliticians hack fear as well. If you can argue that your political program can\nprovide security and resolve whatever threat may be most in the news, you’ll\nattract support. People can acquire fears from party leadership or their peers,\neven in the absence of relevant personal experience. A voter living in northern\nNew Hampshire may be extremely fearful of immigrants at the southern border of\nthe US, even though that person has no experiences with people from Central\nAmerica. As Bill Clinton said, “When people are insecure, they’d rather have\nsomebody who is strong and wrong than someone who’s weak and right.”\n\nTribalism is a system of collective group identity. We are wired to form groups\nand to exclude nonmembers. The vulnerability lies in the fact that we will form\ngroups at the slightest provocation, even if it makes no real sense to do so.\nWhen I was a kid at summer camp, the counselors organized something called\n“color war.” Basically, the whole camp was randomly divided into two groups for\na week: reds and golds. We no longer ate together. We no longer played together.\nThe effects were immediate. We were the good guys, and they were the enemy. Of\ncourse, I can no longer remember what color I was, but I remember well the\nfeeling of being polarized against other campers who used to be my friends.\n\nThere are three basic ways to exploit our tribalism vulnerability. The first is\nto reinforce existing group identity and group divisions. This is what the\nRussian Internet Research Agency did in the US in the months leading up to the\n2016 election, with tactics like donating money to partisan organizations and\nprovoking conflict on online forums. “Find the cracks,” I’ve heard it called.\nThat is, find existing societal fissures that can be magnified into tribal\ndivisions.\n\nThe second is to deliberately create tribal groups for some ulterior purpose.\nColonial governments in the nineteenth and twentieth centuries were infamous for\nthis. In Rwanda, the Germans and Belgians who ruled the region turned an\neconomic distinction between Hutus (farmers) and Tutsis (herders) into a major\nethnic and class distinction, ultimately leading to genocide decades later.\nToday, brands use similar strategies—albeit at a much lower intensity—to sell us\neverything from sneakers to soda to cars.\n\nThe third is to create conditions for tribalism to naturally arise. That is,\ntake existing affinity groups and make that affinity tribal in nature. Sports\nteams do this. Increasingly, political parties and partisan actors also do this.\n\nFox News must certainly understand the research demonstrating that an amplified\nsense of threat is associated with increased support for in-groups and fear of\nout-groups. When Fox runs stories with themes like “immigrants are going to take\nyour jobs,” “[this or that city] is crime-ridden and dangerous,” “ISIS is a\nthreat to Americans,” and “Democrats are going to take your guns,” they aren’t\nonly building support for those issues. They’re also creating the conditions\nunder which groups become more polarized.\n\nData analytics and automation are only getting smarter at hacking people’s sense\nof group identity to achieve some goal. And tribalism is so powerful and\ndivisive that hacking it—especially with digital speed and precision—can have\ndisastrous social effects, whether that’s the goal of a computer-assisted social\nhacker (like the Russians) or a side effect of an AI that neither knows nor\ncares about the costs of its actions (like social media recommendation engines)."},{"title":"Test Section Title","content":"48\n\nDefending against Cognitive Hacks\n\nThe “pick-up artist” community is a movement of men who develop and share\nmanipulative techniques to seduce women. It predates the popular Internet but\nthrives there today. A lot of their techniques resemble cognitive hacks.\n“Negging” is one of their techniques. Basically, it’s a backhanded compliment\ndeliberately designed to undermine the recipient’s confidence and increase their\nneed to seek emotional approval by the manipulator. Yeah, I know. Gross.\n\nI have no idea if negging, or any of their other hacks, reliably work. The men\nwho discuss this online offer plenty of self-aggrandizing anecdotal evidence,\nbut it’s hard to separate the lies from the bad scientific methodology. Reading\nstories by women who are on the receiving end of these attempted hacks, one\nthing is clear: foreknowledge is the best defense. If you know that negging is a\ntactic, you can see it coming.\n\nForeknowledge accelerates regression to the mean. That is, many cognitive hacks\nwork well in the beginning but less so as people adapt to them. Banner ads had a\n49% click-through rate when they first appeared in 1994; now their success rate\nis less than 1%. Pop-up ads exhibited a similar decline as they became\nannoyingly ubiquitous. We’re likely to see the same effect with microtargeting,\ndrip pricing, fake Facebook accounts, and everything else I talked about in the\npast several chapters. As we become inured to these tactics, they become less\neffective.\n\nForeknowledge only goes so far, though. Many cognitive hacks work even when we\nknow we’re being manipulated. If you can manipulate a person into believing\nsomething, they often maintain or strengthen their beliefs when confronted with\nclear evidence that they are wrong. More concretely, companies often use free\nintroductory trials followed by recurring monthly subscriptions to hack\nconsumers’ willingness to pay, counting on humans’ systematic overconfidence in\ntheir memory and time management skills to charge them monthly for services they\nkeep meaning to cancel—and knowing that even if they are aware of their tendency\nto lose track of time, they won’t stop doing it.\n\nAnother defense is to declare particular manipulative practices illegal. For\ninstance, Australia has mandated that the full price of goods be disclosed up\nfront to prevent drip pricing, and the FTC requires that advertised claims be\n“reasonably substantiated.” We can render some of these hacks less effective,\nand therefore less dangerous, by reducing the ability to microtarget these hacks\nat particular individuals. If paid messaging, particularly political\nadvertising, must be broadly targeted, it would be more difficult to exploit\nmany classes of cognitive hacks for nefarious means.\n\nHowever, any new rules will be hacked. So, while we need robust, flexible\noversight and transparency to ensure that cognitive hacks can’t be used to\nmislead, these alone are unlikely to be sufficient to stop people from deploying\nthem. It’s even harder because it’s difficult to explain what’s “wrong” with\nmany of these hacks, whose harms can be abstract or long-term and challenging to\nprove.\n\nCognitive hacks play on the most basic and pervasive aspects of the human mind,\nfrom our survival instincts to our craving for social status. They can be used\nagainst anyone. Protecting ourselves from cognitive hacks requires society-wide\ndefense-in-depth: spanning education, regulation and—especially online—technical\nsolutions. As digital technology occupies ever more of our attention, cognitive\nhacking is increasingly taking place by means of machines. And as computer\nprograms evolve from tools of human hackers into ever faster, more powerful, and\nmore autonomous hackers, understanding how our digital products can hack us will\nbecome increasingly critical to protecting ourselves from manipulation."},{"title":"Test Section Title","content":"49\n\nA Hierarchy of Hacking\n\nNo system exists in isolation. It’s always part of a hierarchy.\n\nImagine someone who wants to steal money via an online banking transaction. They\ncan hack the bank’s website. They can hack a bank customer’s Internet browser.\nThey can hack the customer’s computer operating system or its hardware. All of\nthose hacks could potentially achieve their goal of free money and their\nobjective of thievery.\n\nNow imagine someone who wants to pay less tax. Most obviously, they can hack the\ntax code and find new loopholes. But if they have the power and influence, they\ncan also go up a level and hack the legislative process used to create the tax\ncode. Or they can go up another level and hack the rule-making process used to\nimplement the legislation, or the appropriations process, so the taxation\nauthorities don’t have enough staff to conduct tax audits. (Hacking the\nenforcement process is another way to subvert the intent of a system.) They can\ngo up three levels and hack the political process used to elect the legislators.\nThey can go up four levels and hack the media ecosystem used to discuss the\npolitical processes. Or they can go up five levels and hack the cognitive\nprocesses provoked by the media ecosystem used to discuss the political\nprocesses that elect the legislators that create the tax code that opens or\ncloses loopholes. They can even go down one level and find vulnerabilities and\nexploits in a tax preparation program.\n\nMy point here is that systems occupy a hierarchy of increasing generality\nwhereby the system above governs the system beneath it—and hacks can target any\nlevel. Hacking works by exploiting a hierarchy of mutually entangled systems.\nOne system may be hard to breach or manipulate on its own, but the higher-level\nsystems that govern it or the lower-level systems that implement system commands\ncan be a powerful source of exploits for targets that would be secure in\nthemselves.\n\nIn the technological context, moving up levels is difficult. The fact that\nMicrosoft Windows has vulnerabilities doesn’t guarantee that someone can hack\nthe Microsoft Corporation’s hiring process to put himself in a position to\ninsert more vulnerabilities into the operating system. In social systems, it’s\neasier, especially for those with money and influence. Jeff Bezos had no problem\nbuying the largest home in DC to entertain and influence lawmakers. Or buying\nthe Washington Post, one of the most respected news sources in the US. He can\nalso easily hire programmers to write any sort of software he wants.\n\nSome hacks work at multiple levels simultaneously. In 2020, we learned about\nGhostwriter, a collective—probably Russian in origin—that breached the content\nmanagement systems of several Eastern European news sites and posted fake\nstories. This is a conventional hack of computer systems connected to the\nInternet, combined with a trust hack: the reputation for legitimacy of those\nnews sites.\n\nPatching is also easier lower down than higher up. A vulnerability in TurboTax\ncan be fixed in days. A vulnerability in the tax code might take years to fix.\nCognitive vulnerabilities can easily last generations (although the particular\nexploitation tactics may have to change regularly).\n\nThis makes cognitive hacks the most dangerous exploits of all. They govern all\nof our actions, both individual and collective, and thus all of our social\nsystems. If you can hack the human mind, you can use those techniques on voters,\nemployees, businessmen, regulators, politicians, and other hackers alike, and\nnudge them to reshape the systems they inhabit as you see fit.\n\nThe danger of cognitive hacking is spreading. Human minds are not the only\ncognitive systems we need to worry about anymore. Public services, business\ntransactions, and even basic social interactions are now mediated by digital\nsystems that make predictions and decisions just like humans do, but they do it\nfaster, more consistently, and less accountably than humans. Our machines\nincreasingly make decisions for us, but they don’t think like we do, and the\ninteraction of our minds with these artificial intelligences points the way to\nan exciting and dangerous future for hacking: in the economy, the law, and\nbeyond."},{"title":"Test Section Title","content":"PART 7\n\n\n\nHACKING AI SYSTEMS"},{"title":"Test Section Title","content":"50\n\nArtificial Intelligence and Robotics\n\nArtificial intelligence—AI—is an information technology. It consists of\nsoftware, it runs on computers, and it is already deeply embedded into our\nsocial fabric, both in ways we understand and in ways we don’t. It will hack our\nsociety in a way that nothing heretofore has done.\n\nI mean this in two very different ways. One, AI systems will be used to hack us.\nAnd two, AI systems will themselves become hackers: finding vulnerabilities in\nall sorts of social, economic, and political systems, and then exploiting them\nat an unprecedented speed, scale, scope, and sophistication. It’s not just a\ndifference in degree; it’s a difference in kind. We risk a future of AI systems\nhacking other AI systems, with the effects on humans being little more than\ncollateral damage.\n\nThis may seem somewhat hyperbolic, but none of what I describe requires\nfar-future science-fiction technology. I’m not postulating any “singularity,”\nwhere the AI-learning feedback loop becomes so fast that it outstrips human\nunderstanding. My scenarios don’t require evil geniuses. I’m not assuming\nintelligent androids like Data from Star Trek, R2-D2 from Star Wars, or Marvin\nfrom The Hitchhiker’s Guide to the Galaxy series. We don’t need malicious AI\nsystems like Skynet from Terminator, Ultron from the Avengers works, or the\nagents from the Matrix movies. Some of the hacks I will discuss don’t even\nrequire major research breakthroughs. They’ll improve as AI techniques grow in\nsophistication, but we can see hints of them in operation today. This hacking\nwill arise naturally, as AIs become more advanced at learning, understanding,\nand problem-solving.\n\nDef: AI / ā-ī/ (noun) -\n\n1. (abbrev.) Artificial intelligence.\n\n2. A computer that can (generally) sense, think, and act.\n\n3. An umbrella term encompassing a broad array of decision-making technologies\nthat simulate human thinking.\n\nThis definition isn’t canonical, but defining AI is hard. In 1968, the\npioneering computer scientist Marvin Minsky described AI as “the science of\nmaking machines do things that would require intelligence if done by men.”\nPatrick Winston, another AI pioneer, defined it as “computations that make it\npossible to perceive, reason, and act.” The 1950 version of the Turing\ntest—called the “imitation game” in the original discussion—focused on a\nhypothetical computer program that humans couldn’t distinguish from an actual\nhuman.\n\nI need to differentiate between specialized—sometimes called “narrow”—AI and\ngeneral AI. General AI is what you see in the movies, the AI that can sense,\nthink, and act in a very general and human way. If it’s smarter than humans,\nit’s called “artificial superintelligence.” Combine it with robotics and you\nhave an android, one that may look more or less like a human. The movie robots\nthat try to destroy humanity are all general AI.\n\nA lot of practical research has been conducted into how to create general AI, as\nwell as theoretical research about how to design these systems so they don’t do\nthings we don’t want them to, like destroy humanity. While this is fascinating\nwork, encompassing fields from computer science to sociology to philosophy, its\npractical applications are probably decades away. I want to focus instead on\nspecialized AI, because that’s what’s under development now.\n\nSpecialized AI is designed for a specific task, such as the system that controls\na self-driving car. It knows how to steer the vehicle, how to follow traffic\nlaws, how to avoid getting into accidents, and what to do when something\nunexpected happens—like a child’s ball suddenly bouncing into the road.\nSpecialized AI knows a lot and can make decisions based on that knowledge, but\nonly in the limited domain of driving.\n\nOne common joke among AI researchers is that as soon as something works, it’s no\nlonger AI. It’s just software. That might make AI research depressing, since by\ndefinition the only advances that count are failures, but the joke hides a grain\nof truth. AI is inherently a mystifying science-fictional term, but once it\nbecomes reality, it’s no longer all mystifying. We used to assume that reading\nchest X-rays required a radiologist: that is, an intelligent human with\nappropriate training and professional credentials. We’ve learned that it’s a\nrote task that can also be performed by a computer.\n\nHere’s how to think about it: there is a continuum of decision-making\ntechnologies and systems, ranging from a simple electromechanical thermostat\nthat operates a furnace in response to changing temperatures to a\nscience-fictional android. What makes something AI often depends on the\ncomplexity of both the tasks performed and the environment in which this occurs.\nThe thermostat performs a very simple task that only has to take into account\nthat one aspect of the environment. It doesn’t even require a computer. A modern\ndigital thermostat might be able to sense who is in the room and make\npredictions about future heat needs on the basis of both usage and weather\nforecast, as well as citywide power consumption and second-by-second energy\ncosts. A futuristic AI thermostat might act like a thoughtful and caring butler,\nwhatever that might mean in the context of adjusting the ambient temperature.\n\nI would rather avoid preoccupation with definitions, because they largely don’t\nmatter for the purpose of this discussion. In addition to decision-making, the\nrelevant qualities of the AI systems I’ll be discussing are autonomy (the\nability to act independently), automation (the ability to act on preset\nresponses to specific triggers), and physical agency (the ability to alter the\nphysical environment). A thermostat has limited automation and physical agency,\nand no autonomy. A system that predicts criminal recidivism has no physical\nagency; it just makes recommendations to a judge. A driverless car has some of\nall three. R2-D2 has a lot of all three, although for some reason its designers\nleft out English speech synthesis.\n\nDef: Robot /bät/ (noun) -\n\n1. Physically embodied objects that can sense, think, and act on their\nenvironments through physical motion.\n\nRobotics also has developed a popular mythology and a less-flashy reality. Like\nAI, there are many different definitions of the term. In film and television,\nrobots are often represented as artificial people: androids. But like AI,\nrobotics encompasses a spectrum of reasoning and physical abilities. Again, I\nprefer to focus on technologies that are more prosaic and near term. For our\npurposes, robotics is autonomy, automation, and physical agency dialed way up.\nIt’s “cyber-physical autonomy”: AI technology inside objects that can interact\nwith the world in a direct, physical manner."},{"title":"Test Section Title","content":"51\n\nHacking AI\n\nAI systems are computer programs, running on computers, almost certainly on\nlarge-scale computer networks. As such, they are vulnerable to all the same\ntypes of hacking to which other computer systems are vulnerable. But there are\nalso hacks to which AI systems are uniquely vulnerable—machine learning (ML)\nsystems in particular. ML is a subfield of AI, but has come to dominate\npractical AI systems. In ML systems, blank “models” are fed an enormous amount\nof data and given instructions to figure solutions out for themselves. Some ML\nattacks involve stealing the “training data” used to teach the ML system, or\nstealing the ML model upon which the system is based. Others involve configuring\nthe ML system to make bad—or wrong—decisions.\n\nThis last category, known as “adversarial machine-learning,” is essentially a\ncollection of hacks. Sometimes, they involve studying the ML system in detail in\norder to develop enough understanding about its functioning and its blind spots\nto craft inputs that target those blind spots. For example, an ML system can be\nfooled with carefully constructed inputs. In 2017, MIT researchers designed a\ntoy turtle such that an AI image classifier would decide it was a rifle. Other\nexamples include carefully placed, seemingly innocuous stickers affixed to a\nstop sign that fool an AI classifier into thinking it’s a speed-limit sign, or\nplacement of stickers on a road that fool a self-driving car into swerving into\noncoming traffic. These are all theoretical examples, and while researchers have\nsucceeded in causing cars to fail in this manner in tests, as far as we know no\none has actually crashed a self-driving car through adversarial ML.\n\nAdversarial ML doesn’t have to be malevolent, and it isn’t restricted to\nlaboratory settings. Right now, there are adversarial ML projects trying to hack\nfacial recognition systems so that protesters and others can congregate publicly\nwithout fear of being identified by police. Similarly, you can imagine a future\nwhere insurance companies use AI systems to make claims-authorization decisions.\nA doctor might resort to a known hack to guarantee insurance approval for a\npatient who needs a particular drug or procedure.\n\nOther successful hacks involve feeding an ML system specific inputs designed to\nelicit changes in the system. In 2016, Microsoft introduced a chatbot, Tay, on\nTwitter. Its conversational style was modeled on the speech patterns of a\nteenage girl, and was supposed to grow more sophisticated as it interacted with\npeople and learned their conversational style. Within twenty-four hours, a group\non the 4Chan discussion forum coordinated their responses to Tay. They flooded\nthe system with racist, misogynistic, and anti-Semitic tweets, thereby\ntransforming Tay into a racist, misogynistic anti-Semite. Tay learned from them,\nand—with no actual understanding—parroted their ugliness back to the world.\n\nAI systems are computer programs, so there’s no reason to believe that they\nwon’t be vulnerable to the same hacks to which other computer programs are\nvulnerable. Research into adversarial ML is still in its early stages of\ndevelopment, so we can’t say definitively whether any of the adversarial attacks\nI have described will be easy or difficult, or how effective security\ncountermeasures will be. If the history of computer hacking is any guide, there\nwill be exploitable vulnerabilities in AI systems for the foreseeable future. AI\nsystems are embedded in the same sorts of sociotechnical systems that I’ve\ndiscussed throughout the book, so there will always be people who want to hack\nthem for their personal gain.\n\nThe thing about the hacks I just described is that the results are obvious. Cars\ncrash. A turtle is misclassified as a rifle. Tay acts like a racist misogynistic\nNazi. We’ll see it happening, and—hopefully—patch the ML systems and restore\ntheir functioning to a more reasonable state.\n\nThere is a continuum of imaginable hacks, from the obvious to the invisible. I\nam more worried about attacks the results of which are subtler and less obvious.\nCars may not crash, but they may drive slightly erratically. Chatbots may not\nturn into full-fledged Nazis, but they may become slightly more inclined to\nvalidate the positions of one particular political party. Hackers may figure out\na phrase to add to college applications that will bump them up into a better\ncategory. As long as the results are subtle and the algorithms are unknown to\nus, how would anyone know that they’re happening?"},{"title":"Test Section Title","content":"52\n\nThe Explainability Problem\n\nIn The Hitchhiker’s Guide to the Galaxy, a race of hyper-intelligent,\npan-dimensional beings build the universe’s most powerful computer, Deep\nThought, to answer the ultimate question to life, the universe, and everything.\nAfter 7.5 million years of computation, Deep Thought informs them that the\nanswer is 42. But it’s unable to explain its answer, or even what the question\nwas.\n\nThat, in a nutshell, is the explainability problem. Modern AI systems are\nessentially black boxes. Data goes in at one end, and an answer comes out the\nother. It can be impossible to understand how the system reached its conclusion,\neven if you are the system’s designer and can examine the code. Researchers\ndon’t know precisely how an AI image-classification system differentiates\nturtles from rifles, let alone why one of them mistook one for the other.\n\nIn 2016, the AI program AlphaGo won a five-game match against one of the world’s\nbest Go players, Lee Sedol—something that shocked both the AI and the Go-playing\nworlds. AlphaGo’s most famous move was in game two: move thirty-seven. It’s hard\nto explain without diving deep into Go strategy, but it was a move that no human\nwould ever have chosen to make. It was an instance of an AI thinking\ndifferently.\n\nAIs don’t solve problems like humans do. Their limitations are different from\nours. They’ll consider more possible solutions than we might. More importantly,\nthey’ll look at more types of solutions. They’ll explore paths that we simply\nhave not considered, paths more complex than the sorts of things we generally\nkeep in mind. (Our cognitive limits on the amount of simultaneous data we can\nmentally juggle has long been described as “the magical number seven plus or\nminus two.” An AI system has nothing even remotely like that limitation.)\n\nIn 2015, a research group fed an AI system called Deep Patient health and\nmedical data from approximately 700,000 individuals, and tested whether or not\nthe system could predict diseases. The result was an across-the-board success.\nUnexpectedly, Deep Patient performed well at anticipating the onset of\npsychiatric disorders like schizophrenia, even though a first psychotic episode\nis nearly impossible for physicians to predict. It sounds great, but Deep\nPatient provides no explanation for the basis of its diagnoses and predictions,\nand the researchers have no idea how it comes to its conclusions. A doctor\neither can trust or ignore the computer, but can’t query it for more info.\n\nThat’s not ideal. The AI system should not only spit out an answer but also\nprovide some explanation of its reasoning in a format that humans can\nunderstand. We need this both to be comfortable trusting the AI system’s\ndecisions and to ensure that our AI systems haven’t been hacked to make biased\ndecisions. Providing a reasoned explanation has intrinsic value apart from\nwhether it improves the likelihood of accuracy; it is regarded as a basic\ncomponent of the idea of due process under the law.\n\nResearchers are working on explainable AI; in 2017, the Defense Advanced\nResearch Projects Agency (DARPA) launched a $75 million research fund for a\ndozen programs in the area. While there will be advances in this field, there\nseems to be a trade-off between efficacy and explainability—and other trade-offs\nbetween efficacy and security, and explainability and privacy. Explanations are\na form of cognitive shorthand used by humans, suited for the way humans make\ndecisions. AI decisions simply might not be conducive to humanly understandable\nexplanations, and forcing AI systems to make those explanations might pose an\nadditional constraint that could affect the quality of their decisions. It’s\nunclear where all this research will lead to. In the near term, AI is becoming\nmore and more opaque, as systems become more complex, less human-like, and less\nexplainable.\n\nIn some contexts, we might not care about explainability. I might feel confident\nbeing diagnosed by Deep Patient—even though it couldn’t explain its actions—if\nthe data demonstrated that it was more accurate than a human doctor. I might\nalso feel the same way about an AI system that decided where to drill for oil or\npredicted which airplane parts were more likely to fail. I might not be as\ncomfortable with an AI system that made college admission decisions by\npredicting the likelihood that an applicant would succeed academically, a system\nthat made loan decisions by factoring racial stereotypes into its predictions of\nthe possibility of default, or a system that made parole decisions by predicting\nrecidivism. Some people may eventually be comfortable with AI systems making\neven high-stakes decisions without an explanation. This is all highly subjective\nand will likely change over time as we become more inculcated in AI\ndecision-making.\n\nOthers disagree, and strongly oppose unexplainable AI. The Future of Life\nInstitute and other AI researchers note that explainability is especially\nimportant for systems that might “cause harm,” have “a significant effect on\nindividuals,” or affect “a person’s life, quality of life or reputation.” The\nreport “AI in the UK” suggests that if an AI system has a “substantial impact on\nan individual’s life” and cannot provide “full and satisfactory explanation” for\nits decisions, then the system should not be deployed.\n\nTo me, the difference between an AI that needs to offer an explanation and an AI\nthat doesn’t is one of fairness. We need to ensure that AI systems aren’t\nracist, sexist, ableist, or discriminatory in some way that we haven’t even\ndreamed up yet. Without explainability, we could easily obtain the results\nsimilar to those generated by Amazon’s internal AI system to screen job\napplications. That system was trained on ten years of the company’s hiring data,\nand because the tech industry is male dominated, the AI system taught itself to\nbe sexist, ranking resumes lower if they included the word “women’s” or if the\napplicant graduated from an all-women’s college. (There are times when we don’t\nwant the future to look like the past.)\n\nThat was obviously biased and unfair, and Amazon executives lost enthusiasm for\nthe project and scrapped the system once they realized what was going on. They\nfaced a difficult, maybe even insurmountable problem, because there are multiple\ncontradictory definitions of fairness; “fair” in one context isn’t necessarily\nfair in another. Is a fair system for determining admission one that is gender\nblind, one that deliberately corrects for previous gender biases, one that\nawards admission to genders in the proportion they apply, or one that provides\nfor equal opportunity between the genders as well as for transgender or\nnon-binary people?\n\nIf an AI system can explain its reasoning for making a particular hiring\nrecommendation or a particular parole decision, we will be better able to\nscrutinize its decision-making process. This means we are more likely to trust\nthat system in situations that are more socially nuanced than “Does this X-ray\nindicate a tumor?”\n\nOn the other hand, human decisions aren’t necessarily very explainable. Sure, we\ncan give them, but the research indicates that they are more after-the-fact\njustifications than actual explanations. So maybe the answer is to simply look\nat the results. When courts decide if a particular police department’s behavior\nis racist, they don’t open up the skulls of the police officers or ask them for\nexplanations of their behavior. They look at the results and make a\ndetermination from that."},{"title":"Test Section Title","content":"53\n\nHumanizing AI\n\nArtificial intelligence systems will affect us at the personal level as well as\nthe social level. Previously, I mentioned social engineering. The most effective\nphishing attempts—the ones that result in people and companies losing lots of\nmoney—are personalized. An email impersonating the CEO to someone in the finance\ndepartment, asking for a particular wire transfer, can be especially effective,\nvoice or video even more so. The laborious task of customizing phishing attacks\ncould be automated by AI techniques, enabling scammers to fine-tune their\nindividually targeted emails or voice messages from authority figures to make\nthem more believable.\n\nBeing deceived by an AI isn’t necessarily more problematic than being deceived\nby another human; the greater danger lies in the fact that AIs will be capable\nof persuasion at computer speed and scale. Today’s cognitive hacks are crude: a\nfake newspaper article or provocative nudge capable of fooling only the most\ngullible or desperate. AI has the potential for cognitive hacks to be\nmicrotargeted: personalized, optimized, and individually delivered. Old-style\ncon games like the pigeon drop are individually crafted person-to-person\ncognitive hacks. Advertising messages are bulk-broadcast cognitive hacks. AI\ntechniques have the potential to blend aspects of both of those techniques.\n\nPeople have long ascribed human-like qualities to computer programs. In the\n1960s, programmer Joseph Weizenbaum created a primitive conversational program\ncalled ELIZA that mimicked the manner of a psychotherapist. Weizenbaum was\namazed that people would confide deeply personal secrets to what they knew was a\ndumb computer program. Weizenbaum’s secretary would even ask him to leave the\nroom so that she could talk to ELIZA in private. Today, people are often polite\nto voice assistants like Alexa and Siri as if they would actually care about\ntone. Siri even complains when you’re mean to it: “That’s not very nice,” it\nsays—because it’s programmed to, of course.\n\nNumerous experiments bear similar results. Research subjects would rate a\ncomputer’s performance less critically if they gave the rating on the computer\nthey were criticizing, indicating that they didn’t want to hurt its feelings. In\nanother experiment, if a computer told a research subject some obviously\nfictional piece of “personal information,” the subject was likely to reciprocate\nby sharing actual personal information. The power of reciprocation is something\nthat psychologists study. It’s a hack that people use, too—yet another cognitive\nhack that the scale and personalization of AI can supercharge.\n\nThe addition of robotics makes AI hacks more effective. We humans have developed\nsome pretty efficient cognitive shortcuts to recognize other people. We see\nfaces everywhere; two dots over a horizontal line registers as a face. This is\nwhy even minimalist illustrations are so effective. If something has a face,\nthen it’s a creature of some sort, with intentions, feelings, and everything\nelse that comes with real-world faces. If that something speaks or, even better,\nconverses, then we may believe it has intentions, desires, and agency. If it has\neyebrows, we’re even more likely to do so.\n\nRobots are no exception. Many people have quasi-social relationships with their\nrobot vacuums, even complaining if the company offers to replace rather than\nrepair “their” Roomba. A US Army–developed anti-landmine robot ran into problems\nwhen a colonel refused to allow the insect-shaped device to continue to harm\nitself by stepping on mines. A Harvard robot could convince students to buzz it\ninto dorms by pretending to be a food-delivery robot. And Boxie, a childlike\ntalking robot developed by researchers at MIT, could persuade people to answer\npersonal questions just by asking nicely.\n\nAt least some of our response to robots is similar to our response to the\nappearance and behavior of children. Children have large heads in proportion to\ntheir bodies, large eyes in proportion to their heads, and large lashes in\nproportion to their eyes. They have high-pitched voices. We respond to these\ncharacteristics with a sense of protectiveness.\n\nArtists have taken advantage of this phenomenon for generations to make their\ncreations appear more sympathetic. Children’s dolls are designed to evoke a\nloving, protective response. Cartoon characters are drawn this way, including\nBetty Boop in the 1930s and Bambi in 1942. The main character of the 2019\nlive-action movie Alita: Battle Angel had her eyes computer-enhanced so that\nthey would appear larger.\n\nIn 2016, the Georgia Institute of Technology published a study on human trust in\nrobots that employed a non-anthropomorphic robot to assist participants in\nnavigating through a building, providing directions such as “This way to the\nexit.” First, participants interacted with the robot in a normal setting to\nexperience its performance, which was deliberately poor. Then, they had to\ndecide whether or not to follow the robot’s commands in a simulated emergency.\nIn the latter situation, all twenty-six participants obeyed the robot’s\ndirectional advice, despite having observed just moments before that it had\nlousy navigational skills. The degree of trust they placed in this machine was\nstriking: when the robot pointed to a dark room with no clear exit, the majority\nof people obeyed it, rather than safely exiting by the door through which they\nhad entered. The researchers conducted similar experiments with other robots\nthat seemed to malfunction. Again, subjects followed these robots’ emergency\ndirections, apparently abandoning their common sense. It seems that robots can\nnaturally hack our trust.\n\nAnthropomorphic robots are an emotionally persuasive technology, and AI will\nonly amplify their attractiveness. As AI mimics humans, or even animals, it will\nhijack all the mechanisms that humans use to evaluate each other and come up\nwith new ways to hack those mechanisms. As psychologist Sherry Turkle wrote in\n2010: “When robots make eye contact, recognize faces, mirror human gestures,\nthey push our Darwinian buttons, exhibiting the kind of behavior people\nassociate with sentience, intentions, and emotions.” That is, they hack our\nbrains.\n\nWe won’t just treat AIs as people. They’ll also act like people in ways that\nwill be deliberately designed to fool us. They’ll employ cognitive hacks."},{"title":"Test Section Title","content":"54\n\nAI and Robots Hacking Us\n\nDuring the 2016 US election, about a fifth of all political tweets were posted\nby bots. For the UK Brexit vote of the same year, a third. An Oxford Internet\nInstitute report from 2019 found evidence of bots being used to spread\npropaganda in fifty countries. These tended to be simple programs mindlessly\nrepeating slogans. For example, a quarter-million pro-Saudi “We all have trust\nin [crown prince] Mohammed bin Salman” tweets were posted following the 2018\nmurder of Jamal Khashoggi.\n\nIn 2017, the Federal Communications Commission announced an online period of\npublic comment regarding its plans to repeal net neutrality. A staggering 22\nmillion comments were received. Many of them—maybe half—were submitted using\nstolen identities. These fake comments were crude; 1.3 million were generated\nfrom the same template, with some words altered to make them appear unique. They\ndidn’t stand up to even cursory scrutiny.\n\nEfforts like these will only grow in sophistication. For years, AI programs have\ncomposed news stories about sports and finance for real news organizations like\nthe Associated Press. The constrained nature of much reporting on those topics\nhas made them easier to adapt to AI. AI is now being used to write more general\nstories. Modern text-creation systems like Open AI’s GPT-3 can be fed facts and\nwrite true stories, but they can just as easily be fed untruths and write fake\nnews.\n\nIt doesn’t take much imagination to see how AI will degrade political discourse.\nAlready, AI-driven personas can write personalized letters to newspapers and\nelected officials, leave intelligible comments on news sites and message boards,\nand intelligently debate politics on social media. As these systems become more\narticulate and personal and harder to distinguish from real people, tactics that\nwere once obvious may become much harder to detect.\n\nIn a recent experiment, researchers used a text-generation program to submit\n1,000 comments in response to a government request for public input on a\nMedicaid issue. They all sounded unique, like real people advocating a specific\npolicy position. They fooled the Medicaid.gov administrators, who accepted the\nsubmissions as genuine concerns from actual human beings. The researchers\nsubsequently identified the comments and asked for them to be removed, so that\nno actual policy debate would be unfairly biased. Others won’t be as ethical.\n\nThese techniques are already being used to influence policy in the real world.\nAn online propaganda campaign has used AI-generated headshots to create fake\njournalists. China disseminated AI-generated text messages designed to influence\nthe 2020 Taiwanese election. Deep-fake technology—AI techniques to create real\nvideos of fake events, often with actual people saying things they didn’t\nactually say—are being used politically in countries such as Malaysia, Belgium,\nand the US.\n\nOne example of an extension of this technology is the “persona bot,” an AI\nposing as an individual on social media and other online groups. Persona bots\nhave histories, personalities, and communication styles. They don’t constantly\nspew propaganda. They hang out in various interest groups: gardening, knitting,\nmodel railroading, whatever. They act as normal members of those communities,\nposting and commenting and discussing. Systems like GPT-3 will make it easy for\nthose AIs to mine previous conversations and related Internet content and to\nappear knowledgeable. Then, once in a while, the AI might post something\nrelevant to a political issue, maybe an article about a healthcare worker having\nan allergic reaction to the COVID-19 vaccine, with worried commentary. Or maybe\nit might offer its developer’s opinions about a recent election, or racial\njustice, or any other polarizing subject. One persona bot can’t move public\nopinion, but what if there were thousands of them? Millions?\n\nThis has been called “computational propaganda,” and will change the way we view\ncommunication. AI has the potential to make the future supply of disinformation\nspreaders infinite. It may also break community discourse. In 2012, robotics\nethicist Kate Darling conducted an experiment with an animatronic plastic\ndinosaur named Cleo, a toy that responded to touch in various ways. After having\nparticipants at a science conference play with Cleo, she tried to persuade them\nto “hurt” it in various ways. People felt such strong empathy after only a short\ntime playing with Cleo that they refused to do so, even though it felt no pain.\nThis is a fundamentally human response. We might intuitively know that Cleo is\njust a plastic green dinosaur. But a large face paired with a small body makes\nus regard it as a child. It has a name that tells us it’s a she! And she reacts\nto our touch! Suddenly we’re thinking of her as a creature with feelings, and\nfeel compelled to protect her from harm. And while that reaction may be benign,\nwhat happens when that sweet little robot looks up at her human owners with her\nbig, sad eyes and pleads with them to buy her a software upgrade?\n\nBecause we humans are prone to making category errors and treating robots as\nliving creatures with feelings and intentions, we are vulnerable to being\nmanipulated by them. Robots could persuade us to do things we might not do\notherwise. They could scare us into not doing things we might otherwise do. In\none experiment, a robot was able to exert “peer pressure” on subjects,\nencouraging them to take more risks. How soon before a sex robot suggests in-app\npurchases in the heat of the moment?\n\nAIs will get better at this sort of persuasion. Researchers are already\ndesigning AIs that detect emotions by analyzing our writing, reading our facial\nexpressions, or monitoring our breathing and heart rate. They get it wrong a lot\nof the time, but this will change as technology advances. And AIs will\neventually surpass people in capability. This will allow more precise\nmanipulation, with the caveat about adaptability that I mentioned earlier.\n\nAIBO is a robot dog introduced by Sony in 1999. The company released new and\nimproved models every year through 2005, then over the next few years slowly\ndiscontinued support for older AIBOs. AIBO was pretty primitive by computing\nstandards, but that didn’t stop people from becoming emotionally attached to\ntheir AIBOs. In Japan, people held funerals for their “dead” AIBOs.\n\nIn 2018, Sony started selling a new generation of AIBO. What’s particularly\ninteresting here aren’t the software advances that make it more pet-like, but\nthe fact that AIBO now requires cloud data storage to function. This means that,\nunlike previous generations, Sony can modify or even remotely “kill” any AIBO.\nCloud storage costs $300 per year. If Sony had wanted to maximize its revenue,\nit should have made the first three years free and then—when owners had become\nemotionally attached to their pets—charged a lot more for subsequent years. One\nmight call this tactic “emotional lock-in.”\n\nAs AIs and autonomous robots take on more real-world tasks, human trust in\nautonomous systems will be hacked with dangerous and costly results. But never\nforget that humans control AIs. All AI systems are designed and bankrolled by\nhumans who want to manipulate other humans in a particular way for a particular\npurpose.\n\nCorporations like Sony, and other powerful actors, think long and hard about how\nto hack our emotions for power and profit. They invest heavily in research and\ntechnology to do it. And without an active effort to establish norms and\nregulations limiting these hacks, we’ll soon find the literally inhuman\ncapabilities of AI turned against ordinary people on behalf of their powerful\nmasters."},{"title":"Test Section Title","content":"55\n\nComputers and AI Are Accelerating Societal Hacking\n\nHacking is as old as humanity. We humans have been hacking systems for as long\nas there have been systems, and we’ve seen computer systems hacked for as long\nas there have been computers. Thanks to their complexity and programmable\ninterfaces, computers are uniquely hackable. And today, many consumer\nproducts—such as cars, appliances, and phones—are controlled by computers. All\nof our social systems—finance, taxation, regulatory compliance, elections—are\ncomplex sociotechnical systems involving computers, networks, people, and\ninstitutions. This makes all of these products and systems more susceptible to\nhacking.\n\nComputerization changes hacking, though. Especially when combined with\ntechniques of AI, it accelerates hacking across four dimensions: speed, scale,\nscope, and sophistication.\n\nSpeed is easy to explain; computers are much faster than people. They don’t need\nto sleep, and don’t get bored or distracted. Properly programmed, they make\nmistakes far less often than humans do. This means computers scale rote tasks\nmuch more efficiently than humans are capable of doing; a smartphone takes a\nfraction of the energy and a minute percentage of the time a person would take\nto make a correct mathematical calculation. By vastly reducing the labor\nrequired to perform rote tasks, computers turn certain hacks from practically\nimpossible to impossibly practical.\n\nWe’re already seeing evidence of these new capabilities. A free AI-driven\nservice called Donotpay.com automates the process of contesting parking tickets,\nhelping to overturn hundreds of thousands of citations issued in cities like\nLondon and New York. The service has expanded into other domains, helping users\nreceive compensation for delayed airline flights and cancel a variety of\nservices and subscriptions.\n\nAI speed also enables fast experimentation: computers can quickly try and\ndiscard countless variations of a product element to find the best one. A/B\ntesting, in which different users are randomly shown different versions of a\nproduct, is frequently employed by web developers to test the effectiveness of\ntheir webpage designs. For example, users may be randomly shown a “version A”\nwith a bigger “click here” button and a “version B” with a smaller one, with the\nwebsite automatically collecting data on which version results in more clicks.\nAutomated A/B testing enables developers to simultaneously test complex\ncombinations of variables (like button size, color, placement, and font),\nallowing an unprecedented variety of hacks that can be further personalized to\nfit specific users’ preferences and habits through the power of big data. The\nability to simulate thousands of variations of a hack also widens the scope of\nthe hacks that can be performed, both by commercial enterprises and by\ncriminals.\n\nThe next dimension to consider is the scale of AI. A human activity with a long\nhistory, like stock trading, becomes something different, with unintended and\nunanticipated qualities, when magnified through computer automation. AI systems\nmay engage in the same activities as their human creators, but they do so at an\nunprecedented scale.\n\nIt is more than possible that the persona bots discussed previously will be\ndeployed in bulk across social media. They will be able to engage on the issues\naround the clock, sending unlimited numbers of messages, long and short. If\nallowed to run rampant, they have the potential to overwhelm any actual online\ndebate. They’ll artificially influence what we think is normal, and what we\nthink others think, and their influence will be felt not just on social media\nbut also in every public square and every living room. This sort of manipulation\nis not healthy for the marketplace of ideas or any democratic political process.\nRecall that to function properly, democracy requires information, choice, and\nagency. Artificial personas can starve citizens of both information and agency.\n\nThe scope of AIs is inevitably going to grow. As computer systems become more\ncapable, society will delegate more—and more important—decisions to them. This\nmeans that hacks of these systems will cause more widespread damage and will\nhave greater potential to destroy underlying sociotechnical systems, even if\nthat isn’t the intent of those who deploy them.\n\nAI will exacerbate these trends. AI systems already make decisions that affect\nour lives, from the mundane to the life-defining. They give us turn-by-turn\ndriving directions. They decide whether you stay in jail and whether you get a\nbank loan. They screen job candidates, applicants for college admission, and\npeople who apply for government services. They make investment decisions and\nhelp shape decisions in criminal cases. They decide the news we see on social\nmedia, which candidates’ ads we see, and what people and topics are brought to\nour attention again and again. They make military targeting decisions. In the\nfuture, AIs might recommend politicians for a wealthy political donor to\nsupport. They might decide who is eligible to vote. They might translate desired\nsocial outcomes into tax policies or tweak the details of entitlement programs.\n\nHacks of these increasingly critical systems will become more damaging. (We’ve\nseen early examples of this with “flash crashes” of the stock market.) And for\nthe most part, we have little insight into how the systems are designed, made,\nor used.\n\nFinally, the sophistication of AIs means that they will increasingly replace\nhumans, since computers can often execute more complex and unanticipated\nstrategies than humans can. This capability will also only increase as computers\ngrow faster and more powerful, and networking grows more complex.\n\nMany algorithms are already beyond human understanding, whether they recommend\nwhat movies we want to watch, which investments to purchase, or what move to\nmake in the game of Go. This trend will only increase, potentially exponentially\nonce algorithms begin to design other algorithms.\n\nWith the ascendance of AI, computer hacking becomes one of the most powerful\nways to hack our social systems. When everything is a computer, software\ncontrols it all. Imagine a hacker inside a financial network, altering how money\nflows. Or inside legal databases—making small, substantive changes in laws and\ncourt rulings. (Will people notice, or know enough to verify the original\nwording?) Imagine a hacker altering Facebook’s algorithms from the inside,\nchanging the rules that govern whose post rises to the top of the feed, whose\nvoice is amplified, and who else hears it. When computer programs operate the\neveryday systems we use to work, spend, talk, organize, and live, technology\nbecomes the new policymaker. And for all the freedom that tech’s capabilities\ncan offer us, in the hands of a hacker they can transform into an unparalleled\narchitecture for social control.\n\nAll of these systems are vulnerable to hacking; in fact, current research\nindicates that all machine-learning systems can be undetectably compromised. And\nthose hacks will have increasingly large societal effects."},{"title":"Test Section Title","content":"56\n\nWhen AIs Become Hackers\n\nHacker “Capture the Flag” is basically the outdoor game played on computers.\nTeams defend their own networks while attacking those of the other teams. Played\nin a controlled setting, the game mirrors what computer hackers do in real life:\nfinding and fixing vulnerabilities in their own systems, and exploiting them in\nothers’.\n\nThe competition has been a mainstay at hacker conventions since the mid-1990s.\nThese days, dozens of teams from around the world compete in weekend-long\nmarathon events held all over the world. People train for months, and winning is\na big deal. If you’re into this sort of thing, it’s pretty much the most fun you\ncan possibly have on the Internet without committing multiple felonies.\n\nThe DARPA Cyber Grand Challenge was a similarly styled event for AI, run in\n2016. One hundred teams entered. After completing qualifying rounds, seven\nfinalists competed at the DEF CON convention in Las Vegas. The competition\noccurred in a specially designed test environment filled with custom software\nthat had never been analyzed or tested. The AIs were given ten hours to find\nvulnerabilities to exploit against the other AIs in the competition and to patch\nthemselves against exploitation. A system called Mayhem, created by a team of\nPittsburgh computer security researchers, won. The researchers have since\ncommercialized the technology, which is now busily defending networks for\ncustomers like the Department of Defense.\n\nThere was a human-team capture-the-flag event at DEF CON that same year. Mayhem\nwas invited to participate as the only non-human team. It finished last overall,\nbut it didn’t come in last in every category all the time. You can easily\nimagine how this mixed competition might unfold in the future. We saw the\ntrajectory with the game of chess, and then the game of Go. AI entrants will\nimprove every year, because the core technologies are all improving. The human\nteams will largely stay the same, because humans remain humans even as our tools\nand facility with using them improves. Eventually, it’s likely that the AIs will\nroutinely beat the humans. My guess is that it’ll take less than a decade.\n\nDARPA inexplicably never repeated its AI capture-the-flag event, but China has\nbeen holding them regularly ever since. They also host hybrid events, with\nhuman–computer teams competing against each other. Details are few because these\nevents are domestic only and increasingly hosted by the military, but—just as\nexpected—Chinese AI systems are improving.\n\nIt will be years before we have entirely autonomous AI cyberattack capabilities,\nbut AI technologies are already transforming the nature of cyberattacks in\nseveral dimensions. One area that seems particularly fruitful for AI systems is\nthat of finding vulnerabilities. Plowing through software code line by line is\nexactly the sort of tedious problem at which AIs excel, if they can only be\ntaught how to recognize a vulnerability. Many domain-specific challenges will\nneed to be addressed, of course, but there is a healthy amount of academic\nliterature on the topic, and research is continuing. There’s every reason to\nexpect AI systems will improve over time, and some reason to expect them to\neventually become very accomplished.\n\nThe implications of this potential extend far beyond computer networks. There’s\nno reason that AIs can’t find thousands of new vulnerabilities in many of the\nsystems I discussed in this book: the tax code, banking regulations, political\nprocesses. Whenever many rules interact with each other, we should expect AIs to\neventually be finding their vulnerabilities and creating exploits to compromise\nthem. AIs are already at work looking for loopholes in contracts.\n\nThis capability will improve with time. Hackers of any kind are only as good as\ntheir understanding of the system that they’re targeting and its interactions\nwith the rest of the world. AIs initially capture this understanding through the\ndata with which they’re trained, and they continue to improve as they are used.\nModern AIs are constantly evolving as they acquire new data and adjust their own\ninternal workings accordingly. The constant flow of data continues to train the\nAI as it operates and adds to its expertise. This is why designers of driverless\ncar systems brag about the number of road hours their creations have clocked.\n\nThe development of AIs capable of hacking other systems gives rise to two\ndifferent but related problems. First, an AI might be instructed to hack a\nsystem. Someone might feed an AI the world’s tax codes or the world’s financial\nregulations, in order to create a slew of profitable hacks. Second, an AI might\ninadvertently hack a system during the course of its operations. Both scenarios\nare dangerous, but the second is more dangerous because we might never know it\nhappened."},{"title":"Test Section Title","content":"57\n\nReward Hacking\n\nAs I’ve noted previously, AIs don’t solve problems in the same way that people\ndo. They will inevitably stumble on solutions that we humans might never have\nanticipated, and some will subvert the intent of the system they’re analyzing,\nbecause AIs don’t think in terms of the implications, context, norms, and values\nthat humans share and take for granted.\n\nReward hacking involves an AI achieving a goal in a way the AI’s designers\nneither wanted nor intended. Here are some great examples:\n\n•In a one-on-one soccer simulation, a player was supposed to score against the\ngoalie. Instead of trying to directly kick the ball into the goal, the AI system\nfigured out that if it kicked the ball out of bounds instead, the opponent\ngoalie would have to throw it back in, leaving the goal undefended.\n\n•An AI was instructed to stack blocks. Height was measured by the position of\nthe bottom face of one particular block. The AI learned to flip that block\nupside down so that its bottom faced up, rather than stack it on top of another\nblock with its bottom pointing downward. (Obviously, the rules failed to\nexplicitly state how the blocks should be oriented.)\n\n•In a simulated environment for “evolved” creatures, an AI was allowed to modify\nits own physical characteristics in order to better fulfill its objectives.\nGiven a goal of crossing a distant finish line as quickly as possible, you would\nexpect that the AI would grow longer legs, or stronger muscles, or greater lung\ncapacity. Instead, the AI grew tall enough to cross the finish line immediately\nby falling over it.\n\nThese are all hacks. You can blame them on poorly specified goals or rewards,\nand you would be correct. You can point out that they all occurred in simulated\nenvironments, and you would also be correct. But the problem they illustrate is\nmore general: AIs are designed to optimize their function in order to achieve a\ngoal. In so doing, they will naturally and inadvertently implement unexpected\nhacks.\n\nImagine a robotic vacuum assigned the task of cleaning up any mess it sees.\nUnless the goal is more precisely specified, it might disable its visual sensors\nso that it doesn’t see any messes—or just cover them up with opaque materials.\nIn 2018, an entrepreneurial—or perhaps just bored—programmer wanted his robot\nvacuum to stop bumping into furniture. He trained it by rewarding it for not\nhitting the bumper sensors. Instead of learning not to bump into things, the AI\nlearned to drive the vacuum backwards because there were no bumper sensors on\nthe back of the device.\n\nIf problems, inconsistencies, or loopholes exist in a set of rules, and if those\nproperties lead to an acceptable solution as defined by the rules, then AIs will\nfind them. We might look at the results and say, “Well, technically, the AI\nfollowed the rules.” Yet we humans nonetheless sense a deviation, a cheat, a\nhack—because we understand the social context of the problem in a way AIs don’t,\nand we have different expectations. AI researchers call this problem “goal\nalignment.”\n\nThis problem is well illustrated by the King Midas story. When the god Dionysus\ngrants him a single wish, Midas asks that everything he touches turn to gold.\nMidas ends up starving and miserable when his food, his drink, and his daughter\nall turn to inedible, unpotable, unlovable gold. That’s a goal alignment\nproblem: Midas programmed the wrong goal into his system of desires.\n\nGenies, too, are very precise about the wording of wishes, and can be\nmaliciously pedantic when granting them. But here’s the thing: there is no way\nto outsmart the genie. Whatever you wish for, the genie will always be able to\nfulfill it in a way that you wish he hadn’t. The genie will always be able to\nhack your wish.\n\nMore generally, in human language and thought, goals and desires are always\nunderspecified. We never conceive of all of the options. We never delineate all\nof the caveats and exceptions and provisos. We never close off all the avenues\nfor hacking. We can’t. Any goal we specify will necessarily be incomplete.\n\nThis is largely acceptable in human interactions, because people understand\ncontext and usually act in good faith. We are all socialized, and in the process\nof becoming so, we generally acquire common sense about the way people and the\nworld works. We fill any gaps in our understanding with both context and\ngoodwill.\n\nPhilosopher Abby Everett Jaques, then head of the Ethics of AI Project at MIT,\nexplained it something like this: If I asked you to get me some coffee, you\nwould probably go to the nearest coffeepot and pour me a cup, or maybe walk to\nthe corner coffee shop and buy one. You would not bring me a truckload of raw\nbeans. You would not buy a coffee plantation in Costa Rica. You would also not\nlook for the person closest to you holding a cup of coffee and rip it out of\ntheir hands. You wouldn’t bring me week-old cold coffee, or a used paper towel\nthat had wiped up a coffee spill. I wouldn’t have to specify any of that. You\nwould just know.\n\nSimilarly, if I ask you to develop a technology that would turn things to gold\non touch, you wouldn’t build it so that it starved the person using it. I\nwouldn’t have to specify that; you would just know.\n\nWe can’t completely specify goals to an AI, and AIs won’t be able to completely\nunderstand context. In a TED talk, AI researcher Stuart Russell joked about a\nfictional AI assistant causing an airplane delay in order to delay someone’s\narrival at a dinner engagement. The audience laughed, but how would a computer\nprogram know that causing an airplane computer malfunction is not an appropriate\nresponse to someone who wants to get out of dinner? Perhaps it learned its\nlesson from reports of airline passengers who engaged in similar behavior.\n(Internet joke from 2017: Jeff Bezos: “Alexa, buy me something at Whole Foods.”\nAlexa: “Okay, buying Whole Foods.”)\n\nIn 2015, Volkswagen was caught cheating on emissions control tests. The company\ndidn’t forge test results; instead, it designed its cars’ onboard computers to\ndo the cheating for it. Engineers programmed the software to detect when the car\nwas undergoing an emissions test. The computer activated the car’s emissions\ncontrol system for the duration of the test, then deactivated it once the test\nwas over. Volkswagen’s cars demonstrated superior performance on the road; they\nalso emitted up to forty times the permissible amount of nitrogen oxide\npollutants, but only when the US Environmental Protection Agency (EPA) wasn’t\nwatching.\n\nThe Volkswagen story doesn’t involve AI—human engineers programmed a regular\ncomputer system to cheat—but it illustrates the problem nonetheless. Volkswagen\ngot away with the fraud for over ten years because computer code is complex and\ndifficult to analyze. It’s hard to figure out exactly what it’s doing, and it’s\nsimilarly hard to look at a car and figure out what it’s doing. As long as the\nprogrammers keep their secret, a hack like that is likely to remain undetected\nfor a long time. In this case, the reason we now know about Volkswagen’s actions\nis that a group of scientists at West Virginia University tested the performance\nof Volkswagens on the road using an onboard emissions testing system different\nfrom the EPA’s. Since the software was specifically designed to evade the EPA’s\ntesting systems, the scientists succeeded in accurately measuring the cars’\nemissions without the software realizing it.\n\nIf I asked you to design a car’s engine control software to maximize performance\nwhile still passing emissions control tests, you wouldn’t design the software to\ncheat without comprehending that you were cheating. This simply isn’t true for\nan AI. It doesn’t instinctively understand the abstract concept of cheating. It\nwill think “outside the box” simply because it won’t have a conception of the\nbox, or of the limitations of existing human solutions. It also doesn’t\nunderstand abstract ethical concepts. It won’t understand that Volkswagen’s\nsolution harmed others, that it undermined the intent of the emissions control\ntests, or that the company’s solution was illegal, unless the data upon which\nthe AI relies includes the laws that pertain to emissions. The AI won’t even\nrealize that it’s hacking the system. And thanks to the explainability problem,\nwe humans might never realize it, either.\n\nUnless AI programmers specify that the system must not change its behavior when\nbeing tested, an AI might come up with the same cheat. The programmers will be\nsatisfied. The accountants will be ecstatic. And no one is likely to catch on.\nAnd yes, now that the Volkswagen scandal has been extensively documented, the\nprogrammers can set the explicit goal of avoiding that particular hack. However,\nthere will inevitably be other unanticipated actions that the programmers will\nnot anticipate. The lesson of the genie is that this will always be the case."},{"title":"Test Section Title","content":"58\n\nDefending against AI Hackers\n\nObvious hacks aren’t the only problem. If your driverless car navigation system\nsatisfies the goal of maintaining a high speed by spinning in circles,\nprogrammers will notice this behavior and modify the AI’s goal accordingly.\nWe’ll never see this behavior on the road. The greatest concern lies in the less\nobvious hacks that we won’t even notice because their effects are subtle.\n\nMuch has been written about recommendation engines—the first generation of\nsubtle AI hacks—and how they push people towards extreme content. They weren’t\nprogrammed to do this; it’s a property that naturally emerged as the systems\ncontinually tried things, saw the results, then modified themselves to do more\nof what increased user engagement and less of what didn’t. YouTube’s and\nFacebook’s recommendation algorithms learned to push more extreme content to\nusers because it provokes strong emotional reactions, and that’s what gets\npeople to spend more time on the platform. It didn’t take a bad actor to create\nthis hack: a pretty basic automated system found it on its own. And most of us\ndidn’t realize that it was happening at the time.\n\nSimilarly, in 2015, an AI taught itself to play the 1970s arcade video game\nBreakout. The AI wasn’t told anything about the game’s rules or strategy. It was\njust given the controls and was rewarded for maximizing its score. That it\nlearned how to play isn’t interesting; everyone expected that. But it\nindependently discovered, and optimized to a degree not seen in human players,\nthe tactic of “tunneling” through one column of bricks to bounce the ball off\nthe back wall.\n\nNothing I’m saying here will be news to AI researchers, and many are currently\nconsidering ways to defend against goal and reward hacking. One solution is to\nteach AIs context. Just as researchers must consider the problem of goal\nalignment, so too must they must consider the challenge of “value alignment,” to\ncreate AIs that mirror human values. Solutions to this challenge can be framed\nas two extremes. First, we can explicitly specify values pertinent to the\nendeavor. That can be done today, more or less, but is vulnerable to all of the\nhacking I just described. Alternatively, we can create AIs that learn our\nvalues, possibly by observing humans in action, or by taking as input all of\nhumanity’s writings: our history, our literature, our philosophy, and so on.\nThat is many years out, and probably a feature of general AI. Most current\nresearch oscillates between these two extremes.\n\nOne can easily imagine the problems that might arise by having AIs align\nthemselves to historical or observed human values. Whose values should an AI\nmirror? A Somali man? A Singaporean woman? The average of the two, whatever that\nmeans? We humans hold contradictory values, and we’re also not consistent about\nliving up to them. Any individual person’s values might be irrational, immoral,\nor based on false information. History, literature, and philosophy are full of\nirrationality, immorality, and error. Humans are often not very good examples of\nour ideals.\n\nThe most effective hacking defenses rely on identifying vulnerabilities: finding\nand patching hacks before they’re used to subvert systems. This is something\nthat AI technologies can substantially aid, especially since they can operate at\nsuperhuman speeds.\n\nThink back to computer systems. Once AIs become capable of discovering new\nsoftware vulnerabilities, government, criminal, and hobbyist hackers will all\nbenefit. They’ll be able to use those newly discovered vulnerabilities to\ncompromise computer networks around the world to great effect. It will put us\nall at risk.\n\nThe same technology will be more useful for defense, because once a\nvulnerability is discovered, it can be patched forever. Imagine how a software\ncompany might deploy an AI vulnerability detector on the company’s code. It\ncould locate, then patch, all of the vulnerabilities it finds before the\nsoftware is generally released. This testing might occur automatically as part\nof the development process. So while both the offense and defense would have\naccess to the same technology, the defense could use it to permanently improve\nthe security of its systems. We can imagine a future when software\nvulnerabilities are a thing of the past. “Remember the early decades of\ncomputing, when hackers would use software vulnerabilities to hack systems? Wow,\nwas that a crazy time.”\n\nOf course, the transition period will be fraught. New code might be secure, but\nlegacy code will still be vulnerable. AI tools will examine code that’s already\nreleased and that in many cases can’t be patched. In such cases, attackers will\nuse automatic vulnerability finding to their advantage. However, over the long\nrun, an AI technology that finds software vulnerabilities favors those who\ndefend systems from intrusion and corruption.\n\nThis will also hold true when AIs start finding hacks in broader social systems.\nPolitical, economic, and social vulnerabilities will be exposed, then exploited.\nWhat’s more, all of these hacks will further the interests of those who control\nthe AI systems. Not only will individually tailored advertisements persuade more\nsuccessfully; someone will pay for that added persuasive power because it works\nto their benefit. When the AI figures out a novel tax loophole, it will do so\nbecause someone with access to the AI system wants to exploit it in order to\nreduce their tax liability. Hacking largely reinforces existing power\nstructures, and AIs will further reinforce them, unless we learn to overcome the\nimbalance better than we have so far.\n\nThe same technology can also benefit the defense. While AI hackers might find\nthousands of vulnerabilities in the existing tax code, the same technology can\nbe used to evaluate potential vulnerabilities in any proposed tax law or tax\nruling. The implications are game changing. Imagine a new tax law being tested\nin this manner. A legislator, watchdog organization, journalist, or any\nconcerned citizen could analyze the text of a bill using AI to find all the\nexploitable vulnerabilities. This doesn’t mean that they’ll get fixed (remember,\npatching vulnerabilities is its own separate problem), but it does mean that\nthey can be publicly debated. In theory, they could also be patched before\nsomeone finds and exploits them. Here, too, the transition period will be\ndangerous because of all of our legacy laws and rules. But again, over the long\nrun, AI vulnerability-finding technology favors the defense.\n\nThis is both good and bad. It could be used by society to prevent the powerful\nfrom hacking systems, but it is more likely to be used by the powerful to\nprevent others from hacking systems as a way to resist social control and\naccelerate social change. Again, the structure of power matters."},{"title":"Test Section Title","content":"59\n\nA Future of AI Hackers\n\nHow realistic is a future of AI hacking?\n\nIts feasibility depends on the specific system being modeled and hacked. For an\nAI to even begin optimizing a solution, let alone developing a completely novel\none, all of the rules of the environment must be formalized in a way the\ncomputer can understand. Goals—known in AI as objective functions—need to be\nestablished. The AI needs some sort of feedback on how well it is doing so that\nit can improve its performance.\n\nSometimes this is a trivial matter. For a game like Go, it’s easy. The rules,\nobjective, and feedback—did you win or lose?—are all precisely specified, and\nthere’s nothing outside of those things to muddy the waters. The GPT-3 AI can\nwrite coherent essays because its “world” is just text. This is why most of the\ncurrent examples of goal and reward hacking come from simulated environments.\nThose are artificial and constrained, with all of the rules specified to the AI.\n\nWhat matters is the amount of ambiguity in a system. We can imagine feeding the\nworld’s tax laws into an AI, because the tax code consists of formulas that\ndetermine the amount of tax owed. There is even a programming language, Catala,\nthat is optimized to encode law. Even so, all law contains some ambiguity. That\nambiguity is difficult to translate into code, so an AI will have trouble\ndealing with it. AI notwithstanding, there will be full employment for tax\nlawyers for the foreseeable future.\n\nMost human systems are even more ambiguous. It’s hard to imagine an AI coming up\nwith a real-world sports hack like curving a hockey stick. An AI would have to\nunderstand not just the rules of the game but also human physiology, the\naerodynamics of the stick and the puck, and so on. It’s not impossible, but it\nwould be a lot more difficult than coming up with a novel Go move.\n\nThis latent ambiguity in complex societal systems offers a near-term security\ndefense against AI hacking. We won’t have AI-generated sports hacks until\nandroids actually play those sports, or until a generalized AI is developed that\nis capable of understanding the world broadly in all its intersecting\ndimensions. A similar challenge exists with casino game hacks or hacks of the\nlegislative process. (Could an AI independently discover gerrymandering?) It\nwill be a long time before AIs are capable of modeling and simulating the ways\nthat people work, individually and in groups, before they are as capable as\nhumans are of devising novel ways to hack legislative processes.\n\nBut while a world filled with AI hackers is still a science-fiction problem,\nit’s not a stupid science-fiction problem. Advances in AI are coming fast and\nfurious, and jumps in capability are erratic and discontinuous. Things we\nthought were hard turned out to be easy, and things we think should be easy turn\nout to be hard. When I was a college student in the early 1980s, we were taught\nthat the game of Go would never be mastered by a computer because of its\nenormous complexity: not the rules, but the number of possible moves. Today, AIs\nare Go grandmasters.\n\nSo while AI may primarily be tomorrow’s problem, we’re seeing precursors of it\ntoday. We need to start thinking about enforceable, understandable, and ethical\nsolutions, because if we can expect anything with AI, it’s that we’ll need those\nsolutions sooner than we might expect.\n\nProbably the first place to look for AI-generated hacks is in financial systems,\nsince those rules are designed to be algorithmically tractable. High-frequency\ntrading algorithms are a primitive example of this, and will become much more\nsophisticated in the future. We can imagine equipping an AI with all the world’s\nfinancial information in real time, plus all of the world’s laws and\nregulations, plus news feeds and anything else we think might be relevant, then\nassigning it the goal of “maximum legal profit” or maybe “maximum profit we can\nget away with.” My guess is that this isn’t very far off, and that the result\nwill be all sorts of novel and completely unexpected hacks. And there will\nprobably be some hacks that are simply beyond human comprehension, which means\nwe’ll never realize they’re happening.\n\nIn the short term, we’re more likely to see collaborative AI–human hacks. An AI\ncould identify an exploitable vulnerability that would potentially be a hack,\nand then an experienced accountant or tax attorney would use their experience\nand judgment to figure out if that vulnerability could be profitably exploited.\n\nFor almost all of history, hacking has exclusively been a human activity.\nSearching for new hacks requires expertise, time, creativity, and luck. When AIs\nstart hacking, that will change. AIs won’t be constrained in the same ways or\nhave the same limits as people. They won’t need to sleep. They’ll think like\naliens. And they’ll hack systems in ways we can’t anticipate.\n\nAs I said in Chapter 55, computers have accelerated hacking across four\ndimensions: speed, scale, scope, and sophistication. AI will exacerbate these\ntrends even more.\n\nFirst, speed: The human process of hacking, which sometimes takes months or\nyears, could become compressed to days, hours, or even seconds. What might\nhappen when you feed an AI the entire US tax code and command it to figure out\nall of the ways one can minimize one’s tax liability? Or, in the case of a\nmultinational corporation, analyze and optimize the entire planet’s tax codes?\nCould an AI figure out, without being prompted, that it’s smart to incorporate\nin Delaware and register a ship in Panama? How many\nvulnerabilities—loopholes—will it find that we don’t already know about? Dozens?\nHundreds? Thousands? We have no idea, but we’ll probably find out within the\nnext decade.\n\nNext, scale: Once AI systems begin to discover hacks, they’ll be capable of\nexploiting them at a scale for which we’re simply not prepared. So when AIs\nbegin to crunch financial systems, they will come to dominate that space.\nAlready our credit markets, tax codes, and laws in general are biased towards\nthe wealthy. AI will accelerate that inequity. The first AIs to hack finance in\npursuit of profit won’t be developed by equality-minded researchers; they’ll be\ndeveloped by global banks and hedge funds and management consultants.\n\nNow, scope: We have societal systems that deal with hacks, but those were\ndeveloped when hackers were humans, and hacks unfolded at a human pace. We have\nno system of governance that could quickly and efficiently adjudicate an\nonslaught of hundreds—let alone thousands—of newly discovered tax loopholes. We\nsimply can’t patch the tax code that quickly. We haven’t been able to prevent\nhumans’ use of Facebook to hack democracy; it’s a challenge to imagine what\ncould happen when an AI does it. If AIs begin to figure out unanticipated but\nlegal hacks of financial systems, then take the world’s economy for a wild ride,\nrecovery will be long and painful.\n\nAnd finally—sophistication: AI-assisted hacks open the door to complex\nstrategies beyond those that can be devised by the unaided human mind. The\nsophisticated statistical analyses of AIs can reveal relationships between\nvariables, and thus possible exploits, that the best strategists and experts\nmight never have recognized. That sophistication may allow AIs to deploy\nstrategies that subvert multiple levels of the target system. For example, an AI\ndesigned to maximize a political party’s vote share may determine a precise\ncombination of economic variables, campaign messages, and procedural voting\ntweaks that could make the difference between election victory and defeat,\nextending the revolution that mapping software brought to gerrymandering into\nall aspects of democracy. And that’s not even getting into the hard-to-detect\ntricks an AI could suggest for manipulating the stock market, legislative\nsystems, or public opinion.\n\nAt computer speed, scale, scope, and sophistication, hacking will become a\nproblem that we as a society can no longer manage.\n\nI’m reminded of a scene in the movie Terminator, in which Kyle Reese describes\nto Sarah Connor the cyborg that is hunting her: “It can’t be bargained with. It\ncan’t be reasoned with. It doesn’t feel pity, or remorse, or fear. And it\nabsolutely will not stop, ever . . .” We’re not dealing with literal cyborg\nassassins, but as AI becomes our adversary in the world of social hacking, we\nmight find it just as hard to keep up with its inhuman ability to hunt for our\nvulnerabilities.\n\nSome AI researchers do worry about the extent to which powerful AIs might\novercome their human-imposed constraints and—potentially—come to dominate\nsociety. Although this may seem like wild speculation, it’s a scenario worth at\nleast passing consideration and prevention.\n\nToday and in the near future, though, the hacking described in this book will be\nperpetrated by the powerful against the rest of us. All of the AIs out there,\nwhether on your laptop, online, or embodied in a robot, are programmed by other\npeople, usually in their interests and not yours. Although an Internet-connected\ndevice like Alexa can mimic being your trusted friend, never forget that it is\ndesigned to sell Amazon’s products. And just as Amazon’s website nudges you to\nbuy its house brands instead of competitors’ higher-quality goods, it won’t\nalways be acting in your best interest. It will hack your trust in Amazon for\nthe goals of its shareholders.\n\nIn the absence of any meaningful regulation, there really isn’t anything we can\ndo to prevent AI hacking from unfolding. We need to accept that it is\ninevitable, and build robust governing structures that can quickly and\neffectively respond by normalizing beneficial hacks into the system and\nneutralizing the malicious or inadvertently damaging ones.\n\nThis challenge raises deeper, harder questions than how AI will evolve or how\ninstitutions can respond to it: What hacks count as beneficial? Which are\ndamaging? And who decides? If you think government should be small enough to\ndrown in a bathtub, then you probably think hacks that reduce government’s\nability to control its citizens are usually good. But you still might not want\nto substitute technological overlords for political ones. If you believe in the\nprecautionary principle, you want as many experts testing and judging hacks as\npossible before they’re incorporated into our social systems. And you might want\nto apply that principle further upstream, to the institutions and structures\nthat make those hacks possible.\n\nThe questions continue. Should AI-created hacks be governed locally or globally?\nBy administrators or by referendum? Or is there some way we can let the market\nor civil society groups decide? (The current efforts to apply governance models\nto algorithms are an early indicator of how this will go.) The governing\nstructures we design will grant some people and organizations power to determine\nthe hacks that will shape the future. We’ll need to make sure that that power is\nexercised wisely."},{"title":"Test Section Title","content":"60\n\nGovernance Systems for Hacking\n\nDefensive AI is a potential response to AI hacking, but it’s not sufficiently\ndeveloped yet to be feasible. Today, we need humans working together to\nestablish governance structures to guide the development and deployment of this\ntechnology.\n\nHow those governance structures should look isn’t entirely clear yet, but a\nvariety of proposals have been forwarded for new models of regulation that might\neffectively address the problems posed by the speed, scale, scope, and\nsophistication of artificial intelligences. AI technologists and industry\nleaders like Nick Grossman have proposed that the Internet and big data\nenterprises switch from a “Regulation 1.0” paradigm, where new ventures are\ndeemed permissible and require no after-the-fact review or accountability, to a\n“Regulation 2.0” regime in which new ventures are subject to rigorous,\ndata-driven review and constraint. In Chapter 33, we saw the best governance\nsystem we have for general societal hacks: our common-law system of courtrooms,\njudges, juries, and continually evolving precedent. In the future, any system of\ngovernance to handle AI developments would need to be fast, inclusive,\ntransparent, and agile—like any good system of modern governance.\n\nWe can try to sketch what sort of governance system can defend society from the\npotential effects of both intentional and inadvertent AI hacking. (And while I\ntend to hate randomly invented acronyms, let me use “HGS” as an abbreviation for\n“hacking governance system” in the next few paragraphs. It’s an abstraction that\nwill make talking about that sort of thing easier.)\n\n•Speed: Most fundamentally, with the pace of technological and social change\naccelerating, any HGS would need to work with speed and precision to be\neffective. The Collingridge dilemma is an old observation of technological\nchange: by the time something new and disruptive is widespread enough for its\nsocial consequences to be clear, it’s too late to regulate it. By then, too many\nlives and livelihoods are built around the new technology to put the genie back\nin the bottle. This is nonsense—building trades, railroads, food, medicine,\nfactories, chemicals, nuclear energy all demonstrate otherwise—but it is\ndefinitely harder to regulate something already established. Hacks will move\nfaster than most governments can change their laws or rulings, and governments\nwill struggle to regulate them even when they could theoretically implement a\nresponse in time. Ideally, an HGS should be able to act faster than a hack can\nproliferate, and know quickly whether a new hack needs to be nurtured to\nmaturity or nipped in the bud.\n\n•Inclusivity: In order to identify whether a hack is good or bad, especially in\nits early stages, any HGS must be inclusive of as many perspectives as possible\nto ensure that no potential threat or advantage of a hack is overlooked. That\nmeans, at a minimum, that it includes a diverse multidisciplinary team that can\nexamine hacks and their effects from every angle, from sociology and law to\neconomics, design thinking, and ecology. The HGS would also need to proactively\nseek and incorporate input from outside groups, particularly affected\ncommunities underrepresented by its professional staff, but also from\nindependent researchers and experts, academics, unions, trade associations,\nlocal governments, and civic groups. These groups and individuals would not only\noffer their opinion at the occasional meeting; they would ideally be in\ncontinual dialogue with HGS staffers and with each other, so that the HGS\nassessment both evolves through deliberation with the public and helps the\npublic clarify its views on major hacks, setting up activism and lobbying to\nchange how politicians and other officials beyond the HGS control hacks.\n\n•Transparency: Because the HGS needs to incorporate a wide range of both experts\nand lay citizenry into its decision-making, its processes and rulings must be\npublicly transparent. An opaque HGS that can only be followed by insiders and\npeople with advanced degrees would close itself off to the whole-of-society\nfeedback critical to fully understanding social hacks and their side effects. An\nHGS with more transparent processes, and transparency about the rationales for\nits decisions, will also earn more trust from citizens. That extra trust will be\ncritical in maintaining political support for new and untested agencies managing\ntough trade-offs between innovation, system stability, and contested values like\nequity and fairness.\n\n•Agility: Lastly, as citizens’ political support shifts, or permitted hacks go\nhorribly wrong, or as academics and government learn more about how to\neffectively regulate hacks, any HGS needs mechanisms to rapidly evolve its\nstructure, capabilities, decisions, and approaches to succeed in a changing\nworld. Even with all the best information and input, social systems are complex\nand hard to predict, and attempts to block harmful social hacks will sometimes\nfail. And when the HGS finds an effective patch or other defense against a\nsocial hack, hackers will immediately begin working to undermine it. So to\nsucceed, an HGS needs to be iterative: to rapidly learn from its mistakes, test\nwhich approaches work best for controlling and incorporating each social hack,\nand continually improve its ability to implement those newly discovered best\npractices.\n\nThe overarching solution here is for all of us as citizens to think more\ndeliberately about the proper role of technology in our lives. To date, we have\nlargely been okay with allowing programmers to code the world as they see fit.\nWe’ve done this for several reasons: we didn’t want to unduly constrain the\nnascent technologies, legislators (limitedly) didn’t understand the technologies\nwell enough to regulate them, and—largely—it didn’t matter enough to worry\nabout. That’s changed. Computer systems affect more than computers, and when\nengineers make decisions about them, they are literally designing the world’s\nfuture.\n\nThe common-law system of judicial decisions is a good place to start. I don’t\nwant to minimize the tension between democracy and technology here. It simply\nisn’t true that everyone has the ability to understand or contribute to\nregulating AI. On the other hand, how do we find technocrats who can be trusted,\nand how do we ensure that that trust is shared? This is a more general, and very\nhard, problem of modern governance of our deeply information-rich, connected,\nand otherwise technologically powerful world: one that is well beyond the scope\nof this book. It also isn’t a substantially different problem than building\ngoverning structures that can operate at the speed of, and in the face of the\ncomplexity of, the information age. Legal scholars like Gillian Hadfield, Julie\nCohen, Joshua Fairfield, and Jamie Susskind are writing about this more general\nproblem, and much more work needs to be done.\n\nAgain, these solutions require us first to solve some larger problems in\nsociety. To put it another way: pervasive, predatory hacking is a symptom of a\nflawed system. Money is power, and there is different justice for rule breakers\nwho are powerful than for those who are not. If enforcement agencies don’t act\nequitably—consider that corporate crime is seldom prosecuted—then there’s no\nincentive for those who are powerful to follow the rules. That undermines\nsocietal trust in both the systems and the rules.\n\nThe stakes of inequitable enforcement are actually very high. Minimal regulation\nof the most privileged individuals or enterprises means that they get to set\npolicy: they become de facto governments. This means that we the people no\nlonger have a voice, which means that democracy dies. Yes, this is an extreme\nformulation of the problem, but it’s an end state that we can’t lose sight of.\n\nI’ve been describing the interplay between human and computer systems, and the\nrisks inherent when the computers begin to play the part of humans. This, too,\nis a more general problem than the use and misuse of AI. It’s also one that\ntechnologists and futurists are writing about. And while it’s easy to let\ntechnology lead us into the future, we’re much better off if citizens\ncollectively decide what technology’s role in our future should be—especially in\na world where so much technology is available to everyone.\n\nThere isn’t an HGS anywhere in the world right now, and there really isn’t any\ngovernment that is thinking about building one. It’s time we did."},{"title":"Test Section Title","content":"Concluding Thoughts\n\nWhile finishing up this book manuscript in the summer of 2022, I came across an\narticle in the Wall Street Journal describing a new financial hack. Importers\nhave to pay government tariffs—often considerable—on foreign goods. But there’s\na loophole, called the de minimis rule, which is intended to exempt American\ntourists bringing back souvenirs from overseas trips. But it’s now being abused\nby importers, who are having items shipped from overseas sellers directly to\ncustomers. “As a result, more than a tenth of Chinese imports by value now\narrives as de minimis shipments, up from under 1% a decade ago.” Total lost tax\nrevenue from this hack: $67 billion annually.\n\nIt’s hard not to be depressed about all of this societal hacking. It feels\ninevitable. It’s how systems are subverted to achieve the ends of a few, and it\nhas been going on since forever. The defenses we have are barely able to keep up\ntoday, and are woefully inadequate for the future—because societal hacking is\ngoing to get worse.\n\nAt its core, hacking is a balancing act. On the one hand, it’s an engine of\ninnovation. On the other, it subverts systems, reinforces existing inequitable\npower structures, and can be damaging to society. For most of our history, it\nwas easy to argue that the innovation was worth the risk. Sure, privileged\nindividuals hacked systems for their own benefit. But most of society was\nalready skewed in their favor. A little hacking didn’t make that much\ndifference.\n\nToday, that balance is changing for two reasons: one cultural and the other\ntechnological. And it’s worth laying them out in detail.\n\nHere’s the cultural reason. Over the long term—and by that I mean over the\ncenturies—our societal systems have typically become fairer, more democratic,\nand more just. And as systems evolve in this way, hacking becomes a more\nattractive means for privileged individuals and groups to subvert systems to\ntheir advantage. Very broadly, it’s easier to get what you want when you’re in\ncharge in an autocratic system. If you can make and break the rules with\nimpunity, there’s no need to hack. If, instead, you’re just as constrained by\nthe law as everyone else, it’s harder. Your best option may be to hack the\neconomic, social, and political systems that limit your behavior.\n\nI don’t have any proof, but I believe hacking has become more common in recent\ndecades because of this dynamic. It’s my personal explanation of “late-stage\ncapitalism” and all the problems it brings: finding loopholes in the rules is\nnow regularly the path of least resistance. When those with means or technical\nability realized that they could profitably hack systems, they quickly developed\nthe resources and expertise to do so. They learned to exploit vulnerabilities.\nThey learned to move up and down the hacking hierarchy to achieve their goals.\nThey learned how to get their hacks normalized, declared legal, and adopted into\nthe system.\n\nThis is being made even worse by income inequality. The economist Thomas Piketty\nexplains that inequality produces surplus resources for the winners, and that\nthat surplus can be mobilized to create even more inequality. Much of that\nmobilization is hacking.\n\nNow we have more people with more knowledge of hacking and more resources to\nhack with than ever before, and with that knowledge and resources comes power.\nOur social systems are becoming overwhelmed by the kludged-together hacks\nresulting from generations of tussles over power and prestige. And as cloud\ncomputing, viral media, and AI make new hacks more accessible and powerful than\never, the instability and innovation they breed seems set to grow\nexponentially—to the benefit of those who design or control them, even as more\npeople in general use them.\n\nSocietal systems rely on trust, and hacking undermines that. It might not matter\nat small scales, but when it’s pervasive, trust breaks down—and eventually\nsociety ceases to function as it should. A tax loophole only available to the\nwealthy will generate resentment and erode trust in the entire system of\ntaxation. The tsunami of hacks in our society reflects an absence of trust,\nsocial cohesion, and civic engagement.\n\nThe second reason is technological. Our societal systems, in general, may have\ngrown fairer and more just over the centuries, but progress isn’t linear or\nequitable. The trajectory may appear to be upwards when viewed in hindsight, but\nfrom a more granular point of view there are a lot of ups and downs. It’s a\n“noisy” process.\n\nTechnology changes the amplitude of the noise. Those near-term ups and downs are\ngetting more severe. And while that might not affect the long-term trajectories,\nthey drastically affect all of us living in the short term. This is how the\ntwentieth century could—statistically—both be the most peaceful in human history\nand also contain the most deadly wars.\n\nIgnoring this noise was only possible when the damage wasn’t potentially fatal\non a global scale; that is, if a world war didn’t have the potential to kill\neverybody or destroy society, or occur in places and to people that the West\nwasn’t especially worried about. We can’t be sure of that anymore. The risks we\nface today are existential in a way they never have been before. The magnifying\neffects of technology enable short-term damage to cause long-term planet-wide\nsystemic damage. We’ve lived for half a century under the potential specter of\nnuclear war and the life-ending catastrophe that could have been. Fast global\ntravel allowed local outbreaks to quickly become the COVID-19 pandemic, costing\nmillions of lives and billions of dollars while increasing political and social\ninstability. Our rapid, technologically enabled changes to the atmosphere,\ncompounded through feedback loops and tipping points, may make Earth much less\nhospitable for the coming centuries. Today, individual hacking decisions can\nhave planet-wide effects. Sociobiologist Edward O. Wilson once described the\nfundamental problem with humanity is that “we have Paleolithic emotions,\nmedieval institutions, and godlike technology.”\n\nImagine a Volkswagen-like hack to receive credit for more carbon emissions\nreductions than are actually being realized. If too many companies were to do\nthat, then we would promptly barrel over a two degrees Celsius global\ntemperature increase, and life on Earth could become impossible. Or imagine an\napocalyptic terrorist group hacking the nuclear command structure and launching\nmissiles—or biohacking and releasing a new disease. We could see mass death and\nworldwide government breakdowns that could lead to downward spirals more rapidly\nand more permanently than the slow and painful upwards struggles humanity has\nseen so far.\n\nFor those two reasons, hacking now poses an existential risk. We can hack more,\nfaster, better. Our social and technical systems are evolving rapidly into\nbattlefields of constant subversion and countersubversion, mutating into\nentirely new forms in the process. And between its bias in favor of the top of\nthe food chain and the instability it breeds, all this hacking will come at the\nexpense of the rest of us, and maybe all of us.\n\nAt the same time, I think there is cause for optimism. The technological\nadvances that will exacerbate hacking also have the potential to make things\nbetter, by defending against bad hacks while finding and promoting the good\nones. The trick is going to be getting the governance systems right. The hard\npart of the trick is that we need to figure it out soon.\n\nTo turn hacks—both today’s human-generated hacks and tomorrow’s AI-generated\nhacks—into social innovation means separating the good hacks from the bad ones,\nscaling up the former, and containing the effects of the latter. This is a lot\nmore than the hacking defenses I talked about in Part 2. It also means\ngovernance systems that can keep pace with rapid change, and weigh the\nconflicting interests and interpretations of each hack’s risks, benefits, and\npotential.\n\nWe must build resilient governing structures that can quickly and effectively\nrespond to hacks. It won’t do any good if it takes years to patch the tax code,\nor if a legislative hack becomes so entrenched that it can’t be patched for\npolitical reasons. We need society’s rules and laws to be as patchable as your\ncomputers and phones.\n\nUnless we can hack the process of hacking itself, keeping its benefits and\nmitigating its costs and inequities, we may struggle to survive this\ntechnological future."},{"title":"Test Section Title","content":"Acknowledgments\n\nThis book was born during a global pandemic and a personal life upheaval, and\nsuffered from the effects of both. After writing 86,000 words in 2020, I largely\nignored the manuscript in 2021—missing a deadline—and didn’t pick it up again\nuntil the spring of 2022. Then, with the help of Evelyn Duffy at Open Boat\nEditing, I trimmed 20,000 words and reorganized the book into the sixty-plus\nsmall chapters you’ve (hopefully) just read.\n\nA lot of people helped with this book during those two years. I would like to\nthank my research assistants: Nicholas Anway, Justin DeShazor, Simon Dickson,\nDerrick Flakoll, David Leftwich, and Vandinika Shukla. These were all Harvard\nKennedy School students who worked with me for a few months, either over a\nsummer or a semester. Ross Anderson, Steve Bass, Ben Buchanan, Nick Couldry,\nKate Darling, Jessica Dawson, Cory Doctorow, Tim Edgar, FC (aka freakyclown),\nAmy Forsyth, Brett Frischmann, Bill Herdle, Trey Herr, Campbell Howe, David S.\nIsenberg, Dariusz Jemielniak, Richard Mallah, Will Marks, Aleecia McDonald,\nRoger McNamee, Jerry Michalski, Peter Neumann, Craig Newmark, Cirsten Paine,\nDavid Perry, Nathan Sanders, Marietje Schaake, Martin Schneier, James Shires,\nErik Sobel, Jamie Susskind, Rahul Tongia, Arun Vishwanath, Jim Waldo, Rick Wash,\nSara M. Watson, Tarah Wheeler, Josephine Wolff, and Ben Wizner all read the book\nsomewhere in the draft stage, and all made helpful comments that\nI—mostly—listened to. Kathleen Seidel gave the book a very close edit. As did my\nlongtime assistant and copyeditor, Beth Friedman.\n\nThank you to my editor, Brendan Curry, and everyone else at Norton who had a\nhand in turning my manuscript into a finished product. Also my agent, Sue\nRabiner. Also to my new community here in Cambridge: the Harvard Kennedy School,\nthe Berkman Klein Center, Inrupt (and the Solid project), and my many colleagues\nand friends. And Tammy: thank you for everything."},{"title":"Test Section Title","content":"ALSO BY BRUCE SCHNEIER\n\nWe Have Root\n\nClick Here to Kill Everybody\n\nData and Goliath\n\nCarry On\n\nLiars and Outliers\n\nCryptography Engineering\n\nSchneier on Security\n\nPractical Cryptography\n\nBeyond Fear\n\nSecrets and Lies\n\nThe Twofish Encryption Algorithm\n\nThe Electronic Privacy Papers\n\nE-Mail Security\n\nProtect Your Macintosh\n\nApplied Cryptography"},{"title":"Test Section Title","content":"Copyright © 2023 by Bruce Schneier\n\nAll rights reserved\n\nFirst Edition\n\nFor information about permission to reproduce selections from this book, write\nto Permissions, W. W. Norton & Company, Inc., 500 Fifth Avenue, New York, NY\n10110\n\nFor information about special discounts for bulk purchases, please contact W. W.\nNorton Special Sales at specialsales@wwnorton.com or 800-233-4830\n\nJacket design: Pete Garceau\n\nJacket photograph: dra_schwartz / iStock PhotoBook design by Daniel Lagin\n\nProduction manager: Lauren Abbate\n\nLibrary of Congress Cataloging-in-Publication Data is available\n\nISBN 978-0-393-86666-7\n\nISBN 978-0-393-86667-4 (ebk)\n\nW. W. Norton & Company, Inc., 500 Fifth Avenue, New York, N.Y. 10110\n\nwww.wwnorton.com\n\nW. W. Norton & Company Ltd., 15 Carlisle Street, London W1D 3BS"},{"title":"Test Section Title","content":"Index\n\nPage numbers listed correspond to the print edition of this book. You can use\nyour device’s search function to locate particular terms in the text.\n\nA/B testing, 225\n\nabortion, 133–34\n\nAbrams, Stacey, 167\n\naddiction, 185–87\n\nAdelson, Sheldon, 169\n\nadministrative burdens, 132–34, 163, 164, 165\n\nadministrative state, 154\n\nadversarial machine-learning, 209–10\n\nadvertising\n\nattention and, 183, 184–85\n\nfear and, 197\n\npersuasion and, 188–89\n\ntrust and, 194\n\nAI hacking\n\nability to find vulnerabilities and, 229–30\n\ncognitive hacks and, 181–82, 201–2, 216, 218–19\n\ncompetitions for, 228–29\n\ncomputer acceleration of, 224–26, 242–43\n\ndefenses against, 236–39\n\nexperimentation and, 225\n\nfear and, 197\n\nfinancial systems and, 241–43, 275n\n\nfuture of, 4–5, 205–6, 240–44, 272n, 275n\n\ngoals and, 231–35, 240\n\ngovernance systems for, 245–48\n\nhumanization and, 216–19\n\npersuasion and, 188, 218–19, 220–23\n\npolitics and, 220–22, 225–26\n\nscale and, 225–26, 242–43, 274n\n\nscope and, 226, 243\n\nsophistication and, 226, 243\n\nspeed and, 224–25, 242\n\ntrust and, 193, 194, 218\n\nAI systems\n\nability to find vulnerabilities, 229–30, 238–39\n\nambiguity and, 240–41\n\ndefined, 206\n\nexplainability problem, 212–15, 234\n\nhacking vulnerabilities of, 4, 209–11, 226–27\n\nqualities of, 207–8\n\nspecialized vs. general, 206–7, 272n\n\nvalue alignment and, 237\n\nAIBO, 222–23\n\nAir Bud, 259n\n\nAirbnb, 124\n\nairline frequent-flier hacks, 38–40, 46\n\nAlexa, 217\n\nAlita: Battle Angel, 218\n\nAlphaGo, 212\n\nAlternative Minimum Tax (AMT), 61\n\nAmazon, 124–25\n\nambiguity, 240–41\n\nAmerican Jobs Creation Act (2004), 157\n\nAnonymous, 103\n\nant farms, 1–2\n\nantitrust laws, 185\n\narchitecture, 109\n\nartificial intelligence. See AI hacking; AI systems\n\nATM hacks, 31–34, 46, 47, 63\n\nattention, 183–87\n\nauthoritarian governments, 174–75\n\nAutoRun, 58, 68\n\nBank Holding Company Act (1956), 75\n\nbanking hacks, 74–78, 119, 260n\n\nBarrett, Amy Coney, 121\n\nbeneficial ownership, 86, 88\n\nBerkoff, David, 42\n\nBiden, Joseph, 129, 130\n\nBig Lie technique, 189\n\nbiological systems, 19–20\n\nBipartisan Campaign Reform Act (2002), 169\n\nBlack Codes, 162–63\n\nBoeing 737 MAX, 116–17\n\nBongo, Ali, 193\n\nborder closures, 126\n\nBorodin, Andrey, 87\n\nbots, 188, 210, 220, 221–22, 225–26, 274n\n\nBoxie, 218\n\nbrands, 194\n\nBreaking Bad, 32\n\nBreakout, 236–37\n\nBriffault, Richard, 151\n\nbug bounties, 56–57\n\nbugs, 14–15\n\nbureaucracy hacks, 115–18\n\nBurr, Aaron, 155\n\nbusiness email compromise, 53–54, 192\n\nbuyers’ agency, 99\n\ncapitalism. See market hacks\n\nCappiello, Leonetto, 184\n\ncard counting, 36–37\n\nCARES Act (2020), 147, 149\n\ncartoon characters, 218\n\ncasino hacks, 35–37, 46, 51\n\ncategory errors, 222\n\nCato the Younger, 155\n\ncertificates of deposit (CDs), 75\n\nchatbots, 188, 210\n\nChatmost, 190\n\nChéret, Jules, 184\n\nchildren as hackers, 3, 25–26\n\nCitizens United, 169\n\nclaims-authorization decisions, 210\n\nClinton, Bill, 151, 196\n\ncloture rule, 155\n\nClub Penguin, 25–26, 46, 47\n\ncognitive hacks, 179–82\n\naddiction as, 185–87\n\nAI hacking and, 181–82, 201–2, 216, 218–19\n\nattention and, 183–87\n\ndefenses against, 53–54, 182, 185, 198–99\n\ndisinformation as, 81, 181\n\nfear and, 195–97\n\ngeneral nature of, 181\n\nhacking hierarchy and, 201–2\n\npersuasion, 188–90, 218–19, 220–23\n\ntrust and, 191–94, 218\n\nCohen, Julie, 121, 248\n\nCollingridge dilemma, 246\n\ncolonialism, 197\n\nCombined Reporting Systems for State Corporate Income Tax, 128–29\n\nCommodities Futures Trading Commission, 76–77\n\ncommon law hacks, 135–38\n\ncompartmentalization, 60\n\ncomplexity\n\ndesign process and, 59\n\nas system characteristic, 17, 20\n\nin tax and computer codes, 13–14\n\nvulnerabilities and, 28\n\ncomputational propaganda, 222\n\ncomputer code, 13–14, 15\n\nComputer Fraud and Abuse Act (1986), 18, 65\n\ncomputerization, 224–27, 242–43\n\ncontext, 157–60, 237\n\ncorporate personhood, 141\n\nCOVID-19 pandemic, 27, 45, 110–11, 196\n\ncreative hackers, 22\n\ncredit cards, 39\n\ncustomer reviews, 194\n\ndark patterns, 182, 189–90\n\nDarling, Kate, 222\n\nDARPA Cyber Grand Challenge, 228–29\n\nde minimis rule, 249\n\ndebt financing, 101–2\n\ndecoy prices, 189\n\ndeep-fake technology, 192–93, 221\n\nDeep Patient, 213\n\ndefense in depth, 59–60\n\nDelaware Loophole, 130\n\nDeSantis, Ron, 132–33\n\ndesign process, 58–61\n\nfinancial exchange hacks and, 85\n\nsimplicity in, 59, 80\n\nthreat modeling, 62–63, 64\n\ndestruction as result of hacking, 172–75\n\ndisinformation, 80–81, 181\n\nDoctorow, Cory, 181\n\nDodd-Frank Wall Street Reform and Consumer Protection Act (2010), 76–77, 80, 82,\n97, 98\n\ndolls, 218\n\ndomestic production activities deduction, 157–58\n\nDonotpay.com, 225\n\nDoorDash, 99, 124, 125\n\ndot-com bubble (2001), 99–100\n\n“Double Irish with a Dutch Sandwich” tax loophole, 15–16, 22, 128\n\ndrip pricing, 189\n\ndry sea loans, 91\n\ndue process, 213\n\nelection hacks, 164–67\n\nadvertising and, 185\n\nAI and, 220, 221\n\nauthoritarian governments and, 174–75\n\nfear and, 197\n\n“independent spoiler,” 169–70\n\ntrust and, 193\n\nvoter eligibility and, 161–63\n\nwealth and, 168–71\n\nELIZA, 217\n\nemissions control tests, 234\n\nemotional lock-in, 223\n\nEntick, John, 135–36\n\nEquifax, 49–50\n\nequitable ownership, 138\n\nEternalBlue, 21–22\n\nEurodollar accounts, 75\n\nEvans v. Cornman, 113\n\nexplainability problem, 212–15, 234\n\nexploits, 21, 22\n\nexternalities, 63–64\n\nFacebook, 184, 236, 243\n\nfacial recognition, 210, 217\n\nfail-safes, 61, 67\n\nFairfield, Joshua, 248\n\nfake news, 81\n\nFate of the Good Soldier Švejk during the World War, The (Hašek), 116\n\nfear, 195–97\n\nFederal Deposit Insurance Corporation (FDIC), 96\n\nFederal Election Campaign Act (1972), 169\n\nfederal enclaves, 113–14\n\nFifteenth Amendment, 161, 164\n\nfilibuster, 154–55\n\nfinancial exchange hacks, 79–82, 83–85\n\nFinancial Industry Regulatory Authority, 84\n\nfinancial system hack normalization\n\nas subversive, 90–91\n\nbanking, 75, 76–77, 119, 260n\n\nfinancial exchange hacks, 84, 85\n\nindex funds, 262n\n\ninnovation and, 72, 90\n\nwealth/power and, 119\n\nfinancial system hacks\n\nAI and, 241–43, 275n\n\nbanking, 74–78, 119, 260n\n\nfinancial exchanges, 79–82, 83–85\n\nidentifying vulnerabilities and, 77–78\n\nmedieval usury, 91\n\nSee also financial system hack normalization\n\nFischer, Deb, 190\n\nFitting, Jim, 1\n\nflags of convenience, 130\n\nfoie gras bans, 113–14\n\nfoldering, 26\n\nfood delivery apps, 99, 124\n\nFord, Martin, 272n\n\nforeknowledge, 54\n\nFourteenth Amendment, 141\n\nFourth Amendment, 136\n\nFox News, 197\n\nfrequent-flier hacks, 38–40, 46\n\nFriess, Foster, 169\n\nfront running, 80, 82\n\nFukuyama, Francis, 140\n\nGaedel, Ed, 41\n\ngambling, 186\n\ngambrel roof, 109\n\nGameStop, 81\n\nGarcia, Ileana, 170\n\nGarland, Merrick, 121\n\nGeneral Motors, 104\n\ngenies, 232–33\n\ngeographic targeting orders, 87–88\n\ngerrymandering, 165–66\n\n“get out of jail free” card, 260n\n\nGetty, Paul, 95\n\nGhostwriter, 201\n\ngig economy, 99, 100, 101, 116, 123–25, 264n\n\nGo, 212, 241\n\nGödel, Kurt, 25, 27\n\nGoebbels, Joseph, 181\n\nGoldin, Daniel, 115\n\nGoodhart’s law, 115\n\nGoogle, 185\n\nGPT-3, 220\n\nGreat Depression, 74\n\nGreat Recession, 96, 173–74\n\nGreensill Capital, 102\n\nGrossman, Nick, 245\n\nGrubhub, 99\n\nHacker Capture the Flag, 228\n\nhackers\n\ncompetitions for, 228\n\nmotivations of, 47\n\ntypes, 22\n\nhacking\n\nas parasitical, 45–47, 84, 173\n\nby the disempowered, 103, 119, 120, 121–22, 141\n\ncheating as practicing for, 2–3\n\ncontext of, 157–60, 237\n\ndefined, 1–2, 9–12, 255n\n\ndestruction as result of, 172–75\n\nexistential risks of, 251–52\n\nhierarchy of, 200–202\n\ninnovation and, 139–42, 158–59, 249–50, 252\n\nlife cycle of, 21–24\n\npublic knowledge of, 23, 256n\n\nubiquity of, 25–28\n\nhacking defenses, 48–52, 53–57\n\naccountability and, 67–68\n\nAI hacking and, 236–39\n\ncognitive hacks and, 53–54, 182, 185, 198–99\n\ndetection/recovery, 54–56\n\neconomic considerations, 63\n\ngovernance systems, 245–48\n\nidentifying vulnerabilities, 56–57, 77–78, 237–38\n\nlegislative process hacks and, 147–49, 151, 154, 156\n\nreducing effectiveness, 53–54, 61\n\ntax hacks and, 15–16\n\nthreat modeling, 62–63, 64\n\nSee also patching\n\nhacking normalization\n\nas subversive, 90–91\n\ncasino hacks, 35–36, 37\n\nhacking as innovation and, 158–59\n\n“too big to fail” hack, 97–98\n\nwealth/power and, 73, 104, 119, 120, 122\n\nSee also financial system hack normalization\n\nHadfield, Gillian, 248\n\nHan, Young, 170\n\nHandy, 124\n\nHarkin, Tom, 146\n\nHarris, Richard, 35\n\nHašek, Jaroslav, 116\n\nHaselton, Ronald, 75\n\nhedge funds, 82, 275n\n\nHerd, Pamela, 132\n\nHFT (high-frequency trading), 83–85\n\nhierarchy of hacking, 200–202\n\nhigh-frequency trading (HFT), 83–85\n\nhijacking, 62\n\nHolmes, Elizabeth, 101\n\nhotfixes, 52\n\nHuntsman, Jon, Sr., 169\n\nillusory truth effect, 189\n\nIndependent Payment Advisory Board (IPAB), 153–54\n\n“independent spoiler” hack, 169–70\n\nindex funds, 262n\n\nindulgences, 71–72, 73, 85, 260n\n\ninnovation, 101, 139–42, 158–59, 249–50, 252\n\ninsider trading, 79–80\n\nintention\n\nATM hacks and, 32\n\ndefinition of hacking and, 2, 10, 16\n\ndefinition of system and, 19\n\nInternet, 64–65\n\nSee also social media\n\nInternet of Things (IoT) devices\n\nbugs in, 14\n\npatching for, 23, 49\n\nreducing hack effectiveness in, 54\n\nIntuit, 190\n\nInvestment Company Act (1940), 82\n\nJack, Barnaby, 34\n\njackpotting, 33–34\n\nJaques, Abby Everett, 233\n\nJoseph Weizenbaum, 217\n\njurisdictional rules, 112–13, 128–31\n\nKemp, Brian, 167\n\nKeynes, John Maynard, 95\n\nKhashoggi, Jamal, 220\n\nKing Midas, 232\n\nlabor organizing, 115–16, 121–22\n\nLaw, John, 174\n\nlaws\n\naccountability and, 68\n\ndefinition of hacking and, 12\n\nmarket and, 93\n\nrules and, 18, 19\n\nthreat model shifts and, 65\n\nSee also legal hacks; tax code\n\nlegal hacks, 109–11\n\nbureaucracy and, 115–18\n\ncommon law as, 135–38\n\nCovid-19 payroll loans and, 110–11\n\nloopholes and, 112–14\n\ntax code and, 109–10\n\nlegislative process hacks, 145–49\n\ndefenses against, 147–49, 151, 154, 156\n\ndelay and delegation, 153–56\n\nlobbying and, 146–47\n\nmust-pass bills, 150–52\n\nvulnerabilities and, 147–48, 267n\n\nLessig, Lawrence, 169\n\nLevitt, Arthur, 80\n\nliteracy tests, 162\n\nlobbying, 77, 78, 146–47, 158\n\nlock-in, 94\n\nloopholes\n\ndeliberate, 146\n\nlegal hacks and, 112–14\n\nsystems and, 18\n\ntax code and, 15, 16, 120\n\nSee also regulation avoidance\n\nloot boxes, 186\n\nLuther, Martin, 72\n\nluxury real estate hacks, 86–88\n\nLyft, 101, 123, 125\n\nmachine learning (ML) systems, 209\n\nMalaysian sharecropping hacks, 116\n\nManafort, Paul, 26\n\nMandatory Worldwide Combined Reporting (MWCR), 129\n\nmansard roof, 109\n\nmarket hacks\n\ncapitalism and, 92–93\n\nmarket elements and, 93–94\n\nprivate equity, 101–2\n\n“too big to fail,” 95–98\n\nventure capital as, 99–101\n\nMayhem, 228–29\n\nMcSorley, Marty, 44\n\nmedical diagnosis, 213\n\nmedieval usury hacks, 91\n\nMeltdown, 48\n\nMercExchange, 137\n\nmicrotargeting, 184, 185, 216\n\nMihon, Jude (St. Jude), 255n\n\nmileage runs, 38–39\n\nmilitary enlistment, 188\n\nMinsky, Hyman, 260n\n\nMinsky, Marvin, 206\n\nML (machine learning) systems, 209–10\n\nmoney laundering, 86–87\n\nmoney market funds, 75\n\nmonopolies, 93–94\n\nMonopoly, 260n\n\nMoynihan, Donald, 132\n\nmultifactor authentication, 59–60\n\nMusk, Elon, 81\n\nmust-pass bills, 150–52\n\nNader, Ralph, 170\n\nNational Hockey League, 158\n\nNative lands, 113\n\n9/11 terrorist attacks, 10–11, 26\n\nnormalization. See hacking normalization\n\nnorms, 19, 66\n\nNOW accounts, 74–75\n\nOne Subject at a Time Act, 151\n\nonline games, 186\n\nOrganization for Economic Co-operation and Development (OECD), 129–30\n\nOrnstein, Norm, 156\n\noutrage, 184\n\n“ox walking,” 156\n\nPacific Investment Management Company, 111–12\n\nPalin, Sarah, 154\n\npaper money, 174\n\npatching, 49–52\n\nAI hacking and, 238–39, 240\n\nautomatic, 50\n\ncognitive hacks and, 182\n\nfor ATM hacks, 32, 33\n\nfinancial exchange hacks and, 80, 85\n\nhacking hierarchy and, 201\n\nhacking life cycle and, 23–24\n\nhacking normalization and, 77\n\nhotfixes, 52\n\nimpossibility of, 53–54\n\nregulation avoidance and, 125\n\ntax hacks and, 15–16, 51\n\ntechnology and, 50–51\n\npatent law, 137\n\npayday loans, 125–26\n\npersona bots, 221–22, 225–26, 274n\n\npersuasion, 188–90, 218–19, 220–23\n\nPetraeus, David, 26\n\nPhillips, David, 38, 39–40\n\nphishing, 192, 216\n\nPiketty, Thomas, 250\n\nPitts, Billy, 267n\n\nPodesta, John, 191\n\npoint-of-purchase placement, 184\n\npolarization, 185, 196, 197\n\npolicy hacks. See administrative burdens\n\npolitical hacks\n\nAI hacking and, 220–22, 225–26, 274n\n\ndesign process and, 60\n\nfear and, 196, 197\n\nlobbying as, 77, 78, 146–47\n\nnorms and, 66–67\n\nSee also election hacks; legislative process hacks\n\npoll taxes, 164\n\npop-up ads, 183, 184\n\nPowell, Colin, 192\n\npower advantages. See wealth/power\n\nprivate equity, 101–2\n\nProtestant Reformation, 72\n\npsychotherapy, 217\n\npump-and-dump, 80–81\n\nQuibi, 100–101\n\nranked-choice voting, 171\n\nreal estate hacks, 86–88\n\nreciprocation, 217\n\nrecommendation engines, 236\n\nReconstruction, 161–62\n\nred-teaming, 56, 77, 126–27, 149\n\nRedeemers, 161–62\n\nregulation\n\naccountability and, 68\n\nbanking, 74\n\nfinancial exchange hacks and, 84\n\ngovernance systems, 245–48\n\nmarket hacks and, 94\n\nreal estate hacks and, 87–88\n\nSee also regulation avoidance\n\nregulation avoidance, 123–27\n\nfinancial exchange hacks and, 82\n\ngig economy and, 123–25, 264n\n\njurisdictional rules and, 131\n\nregulatory capture, 75–77, 91, 116–18\n\nride-sharing apps and, 123–24, 264n\n\n“too big to fail” hack and, 97\n\nwealth/power advantages and, 121\n\nRegulation Q, 74, 75\n\nregulatory capture, 75–77, 91, 116–18\n\nreligious hacks, 71–72, 73, 85, 111, 139–40, 260n\n\nresilience, 28, 67–68\n\nresponsible disclosure, 89–90\n\nrewards, 184, 186, 231–35, 240\n\nride-sharing apps, 99, 100, 101, 116, 123–25, 264n\n\nRiegle-Neal Interstate Banking and Branching Efficiency Act (1994), 75\n\nrisk analysis, 195–96\n\nrobotics, 208, 217–19, 222–23\n\nSee also AI hacking; AI systems\n\nRodriguez, Alex, 170\n\nRodríguez, Jose, 170\n\nRoombas, 217\n\nRosenblum, Jeremy, 126–27\n\nrules, 18–19, 25, 232\n\nRussell, Stuart, 233\n\nSahu, Lakhan, 170–71\n\nSaunders, Don, 31\n\nscript kiddies, 22\n\nsecure systems design, 59, 85\n\nSecurities Act (1933), 82\n\nSecurities Exchange Act (1934), 80\n\nSedol, Lee, 212\n\nsegmentation, 60\n\nself-driving cars, 209–10\n\nSGT STAR, 188\n\nshoplifting, 63, 68\n\nSIM swapping, 191\n\nsimplicity, 59, 80\n\nSiri, 217\n\nskimming, 33\n\nSmith, Adam, 93\n\nsocial engineering, 191–92, 216\n\nsocial media, 184–85, 186–87\n\nsoft money, 169\n\nSoftBank, 99\n\nSolarWinds, 54–55, 60, 145\n\nSouth Carolina v. Katzenbach, 164\n\nspam, 46–47\n\nspear phishing, 192\n\nSpectre, 48\n\nsponsored content, 194\n\nspoofing, 81, 82\n\nsports hacks, 41–44, 46, 103, 259n\n\nSummers, Larry, 97\n\nsumptuary laws, 110\n\nsupply chain attacks, 145\n\nSusskind, Jamie, 248\n\nSuzuki, Daichi, 42\n\nsystems\n\nadditional for hacking defense, 54, 60\n\nbiological, 19–20\n\ndefined, 17–18, 19\n\nhierarchy and, 200\n\nmultiple levels of, 32\n\nnorms and, 66–67\n\nresilience in, 152\n\nrigidity of, 27\n\nrules and, 18–19\n\nthinking based on, 20\n\nTaskRabbit, 124\n\nTata, Anthony, 160\n\ntax code\n\nbugs in, 14–15\n\ncomplexity of, 13–14\n\nSee also tax hacks\n\nTax Cuts and Jobs Act (2017), 14, 15–16, 129, 146–47, 149\n\ntax hacks\n\narchitecture and, 109\n\ncreative hackers and, 22\n\ncum-ex trading, 104–5\n\nde minimis rule and, 249\n\ndefenses against, 15–16, 51, 61\n\njurisdictional rules and, 128–31\n\nmorality and, 263n\n\nwealth/power advantages and, 120\n\ntax havens, 128–31\n\nTay (chatbot), 210\n\ntechnological change, 251–52\n\ntelephone hacks, 26–27, 46\n\nTerminator, 243\n\nterrorism, 196\n\nTetzel, Johann, 72, 260n\n\nTheranos, 101\n\nThiel, Peter, 3, 4\n\nthreat modeling, 62–63, 64–65, 96\n\ntitle-only bills, 154\n\n“too big to fail” hack, 95–98\n\ntravel hacks, 179–80\n\ntrespass law, 135–36\n\ntribal courts, 113\n\ntribalism, 196–97\n\nTroubled Asset Relief Program, 96\n\nTrump, Donald\n\nbanking hacks and, 77\n\ncognitive hacks and, 182\n\ndestruction as result of hacking and, 173\n\nlegislative process hacks and, 147\n\nnorms and, 66–67\n\npayday loans and, 126\n\nsocial media and, 185\n\ntax hacks and, 105\n\ntrust hacking, 27, 191–94, 218\n\nTurboTax, 190\n\nturducken, 110, 263n\n\nTurkle, Sherry, 218–19\n\nTwenty-Fourth Amendment, 164\n\nTwitter, 81\n\ntypos, 84–85\n\nUber, 99, 100, 101, 116, 123, 125, 264n\n\nunemployment insurance, 132–33\n\nUnited Nations Convention on the Law of the Sea (1994), 130\n\nuser interface design, 189–90\n\nVacancies Reform Act (1998), 160\n\nvariable rewards, 186\n\nventure capital (VC), 99–101, 125\n\nViolence Against Women Act (2013), 114\n\nvoice assistants, 217\n\nVolcker Rule, 77\n\nVolkswagen, 234\n\nVoltaire, 172\n\nvoter eligibility hacks, 161–63\n\nvoter ID laws, 164–65\n\nVoting Rights Act (1965), 164\n\nvulnerabilities\n\nacceptance of, 16\n\nAI ability to find, 229–30, 238–39\n\nATM hacks and, 31, 33, 34\n\nbugs as, 14–15\n\nhacking as parasitical and, 48, 49\n\nhacking hierarchy and, 201\n\nhacking life cycle and, 21\n\nidentifying, 56–57, 77–78, 237–38\n\nlegislative process hacks and, 147–48, 267n\n\nof AI systems, 4, 209–11, 226–27\n\nreal estate hacks and, 86\n\nresponsible disclosure, 89–90\n\nsecure systems design and, 59\n\nzero-day, 90\n\nSee also patching\n\nWalker, Scott, 166–67\n\nWannaCry, 50\n\nWarner, Mark, 190\n\nWatts, Duncan, 97\n\nwealth/power\n\naccess and, 22\n\nadministrative burdens and, 134\n\ndemocratic growth and, 250\n\nelection hacks and, 168–71\n\nhacking advantages of, 103–4, 119–22\n\nhacking governance systems and, 248\n\nhacking normalization and, 73, 104, 119, 120, 122\n\nimpact on vulnerability patches and, 24\n\nmarket hacks and, 97\n\ntrust breakdown and, 251\n\nWest, Kanye, 170\n\nWestphal, Paul, 41\n\nWeWork, 100\n\nWikiLeaks, 191\n\nWilson, Edward O., 251\n\nWinston, Patrick, 206\n\nWomen, Infants, and Children (WIC) program, 134\n\nwork-to-rule, 115–16, 121\n\nYouTube, 185, 236\n\nZelenskyy, Volodymyr, 193\n\nzero-day vulnerabilities, 90\n\nZone of Death jurisdictional loophole, 112–13\n\nZuckerberg, Mark, 94\n\nZuckerman, Ethan, 183"},{"title":"Test Section Title","content":"Notes\n\nINTRODUCTION\n\n1“They say that water”: Massimo Materni (1 May 2012), “Water never runs uphill /\nSession Americana,” YouTube, https://www.youtube.com/watch?v=0Pe9XdFr_Eo.\n\n2I announce a surprise quiz: I did not invent this exercise. Gregory Conti and\nJames Caroland (Jul-Aug 2011), “Embracing the Kobayashi Maru: Why you should\nteach your students to cheat,” IEEE Security & Privacy 9,\nhttps://www.computer.org/csdl/magazine/sp/2011/04/msp2011040048/13rRUwbs1Z3.\n\n3But billionaire Peter Thiel found a hack: Justin Elliott, Patricia Callahan,\nand James Bandler (24 Jun 2021), “Lord of the Roths: How tech mogul Peter Thiel\nturned a retirement account for the middle class into a $5 billion tax-free\npiggy bank,” ProPublica,\nhttps://www.propublica.org/article/lord-of-the-roths-how-tech-mogul-peter-thiel-turned-a-retirement-account-for-the-middle-class-into-a-5-billion-dollar-tax-free-piggy-bank.\n\n5I wish I could remember where: If anyone knows, please email me.\n\n1. WHAT IS HACKING?\n\n9these terms are overloaded: Finn Brunton has assembled a list of “significant\nmeanings” of the term. Finn Brunton (2021), “Hacking,” in Leah Lievrouw and\nBrian Loader, eds., Routledge Handbook of Digital Media and Communication,\nRoutledge, pp. 75–86, http://finnb.net/writing/hacking.pdf.\n\n9Def: Hack /hak/ (noun): The late hacker Jude Mihon (St. Jude) liked this\ndefinition: “Hacking is the clever circumvention of imposed limits, whether\nthose limits are imposed by your government, your own personality, or the laws\nof Physics.” Jude Mihon (1996), Hackers Conference, Santa Rosa, CA.\n\n10In my 2003 book: Bruce Schneier (2003), Beyond Fear: Thinking Sensibly About\nSecurity in an Uncertain World, Copernicus Books.\n\n11someone used a drone: Lauren M. Johnson (26 Sep 2019), “A drone was caught on\ncamera delivering contraband to an Ohio prison yard,” CNN,\nhttps://www.cnn.com/2019/09/26/us/contraband-delivered-by-drone-trnd/index.html.\n\n11someone using a fishing rod: Selina Sykes (2 Nov 2015), “Drug dealer uses\nfishing rod to smuggle cocaine, alcohol and McDonald’s into jail,” Express,\nhttps://www.express.co.uk/news/uk/616494/Drug-dealer-used-fishing-rod-to-smuggle-cocaine-alcohol-and-McDonald-s-into-jail.\n\n11also about a cat: Telegraph staff (3 Aug 2020), “Detained ‘drug smuggler’ cat\nescapes Sri Lanka prison,” Telegraph,\nhttps://www.telegraph.co.uk/news/2020/08/03/detained-drug-smuggler-cat-escapes-sri-lanka-prison.\n\n12traces its origins: Jay London (6 Apr 2015), “Happy 60th birthday to the word\n‘hack,’ ” Slice of MIT,\nhttps://alum.mit.edu/slice/happy-60th-birthday-word-hack.\n\n2. HACKING SYSTEMS\n\n13The tax laws themselves: Dylan Matthews (29 Mar 2017), “The myth of the\n70,000-page federal tax code,” Vox,\nhttps://www.vox.com/policy-and-politics/2017/3/29/15109214/tax-code-page-count-complexity-simplification-reform-ways-means.\n\n13Microsoft Windows 10: Microsoft (12 Jan 2020), “Windows 10 lines of code,”\nhttps://answers.microsoft.com/en-us/windows/forum/all/windows-10-lines-of-code/a8f77f5c-0661-4895-9c77-2efd42429409.\n\n14surprise tax bills: Naomi Jagoda (14 Nov 2019), “Lawmakers under pressure to\npass benefits fix for military families,” The Hill,\nhttps://thehill.com/policy/national-security/470393-lawmakers-under-pressure-to-pass-benefits-fix-for-military-families.\n\n15Here’s how it worked: New York Times (28 Apr 2012), “Double Irish with a Dutch\nSandwich” (infographic),\nhttps://archive.nytimes.com/www.nytimes.com/interactive/2012/04/28/business/Double-Irish-With-A-Dutch-Sandwich.html.\n\n15US companies avoided paying: Niall McCarthy (23 Mar 2017), “Tax avoidance\ncosts the U.S. nearly $200 billion every year” (infographic), Forbes,\nhttps://www.forbes.com/sites/niallmccarthy/2017/03/23/tax-avoidance-coststhe-u-s-nearly-200-billion-every-year-infographic.\n\n15income tax deductions for property taxes: US Internal Revenue Services (27 Dec\n2017), “IRS Advisory: Prepaid real property taxes may be deductible in 2017 if\nassessed and paid in 2017,”\nhttps://www.irs.gov/newsroom/irs-advisory-prepaid-real-property-taxes-may-be-deductible-in-2017-if-assessed-and-paid-in-2017.\n\n16its fix won’t be complete: Jim Absher (29 Jan 2021), “After years of fighting,\nthe military has started phasing out ‘Widow’s Tax,’ ” Military.com,\nhttps://www.military.com/daily-news/2021/01/19/after-years-of-fighting-military-has-started-phasing-out-widows-tax.html.\n\n4. THE HACKING LIFE CYCLE\n\n23selling their knowledge: I remember reading about one tax loophole that was\nonly shown to prospective investors after they signed an NDA, and even then,\nthey weren’t given all the details. I would love to have a reference to that\nstory.\n\n5. THE UBIQUITY OF HACKING\n\n26Kids have hacked them all: Stephanie M. Reich, Rebecca W. Black, and Ksenia\nKorobkova (Oct 2016), “Connections and communities in virtual worlds designed\nfor children,” Journal of Community Psychology 42, no. 3,\nhttps://sites.uci.edu/disc/files/2016/10/Reich-Black-Korobkova-2014-JCOP-community-in-virtual-worlds.pdf.\n\n26foldering: Steven Melendez (16 Jun 2018), “Manafort allegedly used ‘foldering’\nto hide emails. Here’s how it works,” Fast Company,\nhttps://www.fastcompany.com/40586130/manafort-allegedly-used-foldering-to-hide-emails-heres-how-it-works.\n\n27In Nigeria, it’s called “flashing”: Cara Titilayo Harshman (22 Dec 2010),\n“Please don’t flash me: Cell phones in Nigeria,” North of Lagos,\nhttps://northoflagos.wordpress.com/2010/12/22/please-dont-flash-me-cell-phones-in-nigeria.\n\n27also huge in India: Atul Bhattarai (5 April 2021), “Don’t pick up! The rise\nand fall of a massive industry based on missed call,” Rest of World,\nhttps://restofworld.org/2021/the-rise-and-fall-of-missed-calls-in-india/.\n\n27Homeschooling during the: Tribune Web Desk (14 May 2020), “Students find\n‘creative’ hacks to get out of their Zoom classes, video goes viral,” Tribune of\nIndia,\nhttps://www.tribuneindia.com/news/lifestyle/students-find-creative-hacks-to-get-out-of-their-zoom-classes-video-goes-viral-84706.\n\n27one-star reviews: Anthony Cuthbertson (9 Mar 2020), “Coronavirus: Quarantined\nschool children in China spam homework app with 1-star reviews to get it off app\nstore,” Independent,\nhttps://www.independent.co.uk/life-style/gadgets-and-tech/news/coronavirus-quarantine-children-china-homework-app-dingtalk-a9387741.html.\n\n27Recall Gödel: Kimberly D. Krawiec and Scott Baker (2006), “Incomplete\ncontracts in a complete contract world,” Florida State University Law Review 33,\nhttps://scholarship.law.duke.edu/faculty_scholarship/2038.\n\n27systems of trust: Bruce Schneier (2012), Liars and Outliers: Enabling the\nTrust that Society Needs to Thrive, John Wiley & Sons.\n\n28complexity is the worst enemy of security: Bruce Schneier (19 Nov 1999), “A\nplea for simplicity: You can’t secure what you don’t understand,” Information\nSecurity,\nhttps://www.schneier.com/essays/archives/1999/11/a_plea_for_simplicit.html.\n\n6. ATM HACKS\n\n31Saunders withdrew $1.6 million: Jack Dutton (7 Apr 2020), “This Australian\nbartender found an ATM glitch and blew $1.6 million,” Vice,\nhttps://www.vice.com/en_au/article/pa5kgg/this-australian-bartender-dan-saunders-found-an-atm-bank-glitch-hack-and-blew-16-million-dollars.\n\n33changes in ATM design: Z. Sanusi, Mohd Nor Firdaus Rameli, and Yusarina Mat\nIsa (13 Apr 2015), “Fraud schemes in the banking institutions: Prevention\nmeasures to avoid severe financial loss,” Procedia Economics and Finance,\nhttps://www.semanticscholar.org/paper/Fraud-Schemes-in-the-Banking-Institutions%3A-Measures-Sanusi-Rameli/681c06a647cfef1e90e52ccbf829438016966c44.\n\n33this is known as “jackpotting”: Joseph Cox (14 Oct 2019), “Malware that spits\ncash out of ATMs has spread across the world,” Vice Motherboard,\nhttps://www.vice.com/en_us/article/7x5ddg/malware-that-spits-cash-out-of-atms-has-spread-across-the-world.\n\n33Another attack: Dan Goodin (22 Jul 2020), “Thieves are emptying ATMs using a\nnew form of jackpotting,” Wired,\nhttps://www.wired.com/story/thieves-are-emptying-atms-using-a-new-form-of-jackpotting.\n\n34US Secret Service began warning: Brian Krebs (27 Jan 2018), “First\n‘jackpotting’ attacks hit U.S. ATMs,” Krebs on Security,\nhttps://krebsonsecurity.com/2018/01/first-jackpotting-attacks-hit-u-s-atms.\n\n34Barnaby Jack demonstrated: Kim Zetter (28 Jul 2010), “Researcher demonstrates\nATM ‘jackpotting’ at Black Hat conference,” Wired,\nhttps://www.wired.com/2010/07/atms-jackpotted.\n\n7. CASINO HACKS\n\n35He modified over thirty machines: Las Vegas Sun (21 Feb 1997), “Slot cheat,\nformer casino regulator, reputed mob figure added to Black Book,”\nhttps://lasvegassun.com/news/1997/feb/21/slot-cheat-former-casino-regulator-reputed-mob-fig.\n\n36wearable computer with toe switches: Paul Halpern (23 May 2017), “Isaac Newton\nvs. Las Vegas: How physicists used science to beat the odds at roulette,”\nForbes,\nhttps://www.forbes.com/sites/startswithabang/2017/05/23/how-physicists-used-science-to-beat-the-odds-at-roulette.\n\n36Nevada banned the use of devices: Don Melanson (18 Sep 2013), “Gaming the\nsystem: Edward Thorp and the wearable computer that beat Vegas,” Engadget,\nhttps://www.engadget.com/2013-09-18-edward-thorp-father-of-wearable-computing.html.\n\n36Casinos have responded: Grant Uline (1 Oct 2016), “Card counting and the\ncasino’s reaction,” Gaming Law Review and Economics,\nhttps://www.liebertpub.com/doi/10.1089/glre.2016.2088.\n\n37Laws were passed banning: David W. Schnell-Davis (Fall 2012), “High-tech\ncasino advantage play: Legislative approaches to the threat of predictive\ndevices,” UNLV Gaming Law Journal 3,\nhttps://scholars.law.unlv.edu/cgi/viewcontent.cgi?article=1045&context=glj.\n\n37casinos are private business: New Jersey is an exception to this. Atlantic\nCity casinos cannot ban card counters. Donald Janson (6 May 1982), “Court rules\ncasinos cannot bar card counters,” New York Times,\nhttps://www.nytimes.com/1982/05/06/nyregion/court-rules-casinos-may-not-bar-card-counters.html.\n\n37MIT and Harvard academics invented: Ben Mezrich (Dec 2002), Bringing Down the\nHouse: The Inside Story of Six MIT Students Who Took Vegas for Millions, Atria\nBooks.\n\n37an estimated $10 million: Janet Ball (26 May 2014), “How a team of students\nbeat the casinos,” BBC World Service,\nhttps://www.bbc.com/news/magazine-27519748.\n\n8. AIRLINE FREQUENT-FLIER HACKS\n\n39airlines started changing: Josh Barro (12 Sep 2014), “The fadeout of the\nmileage run,” New York Times,\nhttps://www.nytimes.com/2014/09/14/upshot/the-fadeout-of-the-mileag-run.html.\n\n39ways to accrue points: Darius Rafieyan (23 Sep 2019), “How one man used miles\nto fulfill his dream to visit every country before turning 40,” NPR,\nhttps://www.npr.org/2019/09/23/762259297/meet-the-credit-card-obsessives-who-travel-the-world-on-points.\n\n39Chase instituted a rule: Gina Zakaria (25 Feb 2020), “If you’re interested in\na Chase card like the Sapphire Preferred you need to know about the 5/24 rule\nthat affects whether you’ll be approved,” Business Insider,\nhttps://www.businessinsider.com/personal-finance/what-is-chase-524-rule.\n\n39American Express now revokes: Nicole Dieker (2 Aug 2019), “How to make sure\nyou don’t lose your credit card rewards when you close the card,” Life Hacker,\nhttps://twocents.lifehacker.com/how-to-make-sure-you-dont-lose-your-credit-card-rewards-1836913367.\n\n39back to the Pudding Guy: Carla Herreria Russo (3 Oct 2016), “Meet David\nPhillips, the guy who earned 1.2 million airline miles with chocolate pudding,”\nHuffington Post,\nhttps://www.huffpost.com/entry/david-philipps-pudding-guy-travel-deals_n_577c9397e4b0a629c1ab35a7.\n\n9. SPORTS HACKS\n\n41St. Louis Browns: Associated Press (20 Aug 1951), “Brownies hit all-time low;\nUse 3-foot 7-inch player,” Spokesman-Review,\nhttps://news.google.com/newspapers?id=rS5WAAAAIBAJ&sjid=3uUDAAAAIBAJ&pg=4920%2C3803143.\n\n41the Suns would get the ball: Presh Talwalkar (6 Jun 2017), “Genius strategic\nthinking in the 1976 NBA Finals,” Mind Your Decisions,\nhttps://mindyourdecisions.com/blog/2017/06/06/genius-strategic-thinking-in-the-1976-nba-finals-game-theory-tuesdays.\nSecret Base (5 Feb 2019), “The infinite timeout loophole that almost broke the\n1976 NBA Finals,” YouTube, https://www.youtube.com/watch?v=Od2wgHLq69U.\n\n42hacked the backstroke: John Lohn (24 Sep 2021), “Seoul Anniversary: When the\nbackstroke went rogue: How David Berkoff and underwater power changed the\nevent,” Swimming World,\nhttps://www.swimmingworldmagazine.com/news/seoul-anniversary-when-the-backstroke-went-rogue-how-david-berkoff-and-underwater-power-changed-the-event.\n\n42New England Patriots used: Rodger Sherman (10 Jan 2015), “The Patriots’ trick\nplay that got John Harbaugh mad,” SB Nation,\nhttps://www.sbnation.com/nfl/2015/1/10/7526841/the-patriots-trick-play-that-got-john-harbaugh-mad-ravens.\n\n42the league amended its rules: Ben Volin (26 Mar 2015), “NFL passes rule aimed\nat Patriots’ ineligible receiver tactic,” Boston Globe,\nhttps://www.bostonglobe.com/sports/2015/03/25/nfl-passes-rule-change-aimed-patriots-ineligible-receiver-tactic/uBqPWS5dKYdMYMcIiJ3sKO/story.html.\n\n42dunking was once a hack: The plot of the 1997 movie Air Bud involves hacking\nthe rules to pro basketball. In the movie, at least, there is no rule preventing\na dog from playing on a basketball team. (No, the movie isn’t any good.)\n\n42a few cricketers realized: Manish Verma (7 Jan 2016), “How Tillakaratne\nDilshan invented the ‘Dilscoop,’ ” SportsKeeda,\nhttps://www.sportskeeda.com/cricket/how-tillakaratne-dilshan-invented-dilscoop.\n\n43Tyrell team built a six-wheeled: Jordan Golson (17 Dec 2014), “Well that\ndidn’t work: The crazy plan to bring 6-wheeled cars to F1,” Wired,\nhttps://www.wired.com/2014/12/well-didnt-work-crazy-plan-bring-6-wheeled-cars-f1.\n\n43Brabham team skirted the rule: Gordon Murray (23 Jul 2019), “Gordon Murray\nlooks back at the notorious Brabham fan car,” Motor Sport,\nhttps://www.motorsportmagazine.com/articles/single-seaters/f1/gordon-murray-looks-back-notorious-brabham-fan-car.\n\n43two brake pedals: McLaren (1 Nov 2017), “The search for the extra pedal,”\nhttps://www.mclaren.com/racing/inside-the-mtc/mclaren-extra-pedal-3153421.\n\n44a hole in the cockpit: Matt Somerfield (20 Apr 2020), “Banned: The 2010\nFormula 1 season’s F-duct,” AutoSport,\nhttps://www.autosport.com/f1/news/149090/banned-the-f1-2010-season-fduct.\n\n44its Formula One engine’s turbo charger: Laurence Edmondson (6 Feb 2016),\n“Mercedes F1 engine producing over 900bhp with more to come in 2016,” ESPN,\nhttps://www.espn.com/f1/story/_/id/14724923/mercedes-f1-engine-producing-900bhp-more-come-2016.\n\n44a feature to the steering wheel: Laurence Edmondson (21 Feb 2020), “Mercedes’\nDAS system: What is it? And is it a 2020 game-changer?” ESPN,\nhttps://www.espn.com/f1/story/_/id/28749957/mercedes-das-device-and-2020-game-changer.\n\n44illegally curved stick: Dave Stubbs (2 Jun 2017), “Marty McSorley’s illegal\nstick still part of Stanley Cup Final lore,” National Hockey League,\nhttps://www.nhl.com/news/marty-mcsorleys-illegal-stick-still-part-of-stanley-cup-final-lore/c-289749406.\n\n12. MORE SUBTLE HACKING DEFENSES\n\n56red team was the pretend enemy: University of Foreign Military and Cultural\nStudies Center for Applied Critical Thinking (5 Oct 2018), The Red Team\nHandbook: The Army’s Guide to Making Better Decisions, US Army Combined Arms\nCenter,\nhttps://usacac.army.mil/sites/default/files/documents/ufmcs/The_Red_Team_Handbook.pdf.\n\n56“We argue that red teaming”: Defense Science Board (Sep 2003), “Defense\nScience Board Task Force on the Role and Status of DoD Red Teaming Activities,”\nOffice of the Under Secretary of Defense for Acquisition, Technology, and\nLogistics, https://apps.dtic.mil/dtic/tr/fulltext/u2/a430100.pdf.\n\n13. REMOVING POTENTIAL HACKS IN THE DESIGN PHASE\n\n61my 2000 book: Bruce Schneier (2000), Secrets and Lies: Digital Security in a\nNetworked World, John Wiley & Sons.\n\n14. THE ECONOMICS OF DEFENSE\n\n62all the threats to a system: Adam Shostack (2014), Threat Modeling: Designing\nfor Security, John Wiley & Sons.\n\n16. HACKING HEAVEN\n\n71What started as a system of redemption: R. N. Swanson (2011), Indulgences in\nLate Medieval England: Passports to Paradise? Cambridge University Press.\n\n72Johann Tetzel, a Dominican friar: Ray Cavanaugh (31 Oct 2017), “Peddling\npurgatory relief: Johann Tetzel,” National Catholic Reporter,\nhttps://www.ncronline.org/news/people/peddling-purgatory-relief-johann-tetzel.\n\n72indulgences for deceased friends: He supposedly even had an advertising\njingle: “As soon as the gold in the casket rings / The rescued soul to heaven\nsprings.”\n\n72a “get out of hell free” card: Totally unrelated, but the “get out of jail\nfree” card can be used in the game of Monopoly to hack the rule that players are\nnot allowed to lend money to each other. It’s not worth much, but players can\nsell it to each other for any amount of money—making it a useful cash transfer\ndevice. Jay Walker and Jeff Lehman (1975), 1000 Ways to Win Monopoly Games, Dell\nPublishing,\nhttp://www.lehman-intl.com/jeffreylehman/1000-ways-to-win-monopoly.html.\n\n17. HACKING BANKING\n\n74Regulation Q is a security measure: R. Alton Gilbert (Feb 1986), “Requiem for\nRegulation Q: What it did and why it passed away,” Federal Reserve Bank of St.\nLouis,\nhttps://files.stlouisfed.org/files/htdocs/publications/review/86/02/Requiem_Feb1986.pdf.\n\n75NOW accounts were legalized: Joanna H. Frodin and Richart Startz (Jun 1982),\n“The NOW account experiment and the demand for money,” Journal of Banking and\nFinance 6, no. 2,\nhttps://www.sciencedirect.com/science/article/abs/pii/0378426682900322. Paul\nWatro (10 Aug 1981), “The battle for NOWs,” Federal Reserve Bank of Cleveland,\nhttps://www.clevelandfed.org/en/newsroom-and-events/publications/economic-commentary/economic-commentary-archives/1981-economic-commentaries/ec-19810810-the-battle-for-nows.aspx.\n\n76we’ll see it again and again: Although he never used the word “hacking,” Hyman\nMinsky discussed this. Hyman Minsky (May 1992), “The financial instability\nhypothesis,” Working Paper No. 74, The Jerome Levy Economics Institute of Bard\nCollege, https://www.levyinstitute.org/pubs/wp74.pdf.\n\n76banks had moved 95%: Charles Levinson (21 Aug 2015), “U.S. banks moved\nbillions of dollars in trades beyond Washington’s reach,” Reuters,\nhttps://www.reuters.com/investigates/special-report/usa-swaps. Marcus Baram (29\nJun 2018), “Big banks are exploiting a risky Dodd-Frank loophole that could\ncause a repeat of 2008,” Fast Company,\nhttps://www.fastcompany.com/90178556/big-banks-are-exploiting-a-risky-dodd-frank-loophole-that-could-cause-a-repeat-of-2008.\n\n77financial services industry spent $7.4 billion: Deniz O. Igan and Thomas\nLambert (9 Aug 2019), “Bank lobbying: Regulatory capture and beyond,” IMF\nWorking Paper No. 19/171, International Monetary Fund,\nhttps://www.imf.org/en/Publications/WP/Issues/2019/08/09/Bank-Lobbying-Regulatory-Capture-and-Beyond-45735.\n\n77Some countries: Several banking regulators, including the Office of the\nComptroller of the Currency and the Consumer Financial Protection Bureau, offer\nopportunities to comment, at least on some occasions, see\nhttps://www.occ.treas.gov/about/connect-with-us/public-comments/index-public-comments.html.\nConsumer Financial Protection Bureau (last updated 7 Apr 2022), “Notice and\nopportunities to comment,”\nhttps://www.consumerfinance.gov/rules-policy/notice-opportunities-comment.\n\n18. HACKING FINANCIAL EXCHANGES\n\n80three people were charged: US Securities and Exchange Commission (9 Jul 2021),\n“SEC charges three individuals with insider trading,”\nhttps://www.sec.gov/news/press-release/2021-121.\n\n80“want these laws purposely vague”: Knowledge at Wharton staff (11 May 2011),\n“Insider trading 2011: How technology and social networks have ‘friended’ access\nto confidential information,” Knowledge at Wharton,\nhttps://knowledge.wharton.upenn.edu/article/insider-trading-2011-how-technology-and-social-networks-have-friended-access-to-confidential-information.\n\n80the SEC indicted two Ukrainian hackers: US Securities and Exchange Commission\n(11 Aug 2015), “SEC charges 32 defendants in scheme to trade on hacked news\nreleases,” https://www.sec.gov/news/pressrelease/2015-163.html.\n\n19. HACKING COMPUTERIZED FINANCIAL EXCHANGES\n\n83the rise of computerization: Atlantic Re:think (21 Apr 2015), “The day social\nmedia schooled Wall Street,” Atlantic,\nhttps://www.theatlantic.com/sponsored/etrade-social-stocks/the-day-social-media-schooled-wall-street/327.\nJon Bateman (8 Jul 2020), “Deepfakes and synthetic media in the financial\nsystem: Assessing threat scenarios,” Carnegie Endowment,\nhttps://carnegieendowment.org/2020/07/08/deepfakes-and-synthetic-media-in-financial-system-assessing-threat-scenarios-pub-82237.\n\n20. LUXURY REAL ESTATE\n\n87160 UK properties: Matteo de Simone et al. (Mar 2015), “Corruption on your\ndoorstep: How corrupt capital is used to buy property in the U.K.,” Transparency\nInternational,\nhttps://www.transparency.org.uk/sites/default/files/pdf/publications/2016CorruptionOnYourDoorstepWeb.pdf.\n\n87owned by shell corporations: Louise Story and Stephanie Saul (7 Feb 2015),\n“Stream of foreign wealth flows to elite New York real estate,” New York Times,\nhttps://www.nytimes.com/2015/02/08/nyregion/stream-of-foreign-wealth-flows-to-time-warner-condos.html.\n\n88geographic targeting orders: Michael T. Gershberg, Janice Mac Avoy, and\nGregory Bernstein (2 May 2022), “FinCEN renews and expands geographic targeting\norders for residential real estate deals,” Lexology,\nhttps://www.lexology.com/library/detail.aspx?g=065ffb4d-f737-42dc-b759-ef5c4d010404.\n\n88could get rid of: Max de Haldevang (22 Jun 2019), “The surprisingly effective\npilot program stopping real estate money laundering in the US,” Quartz,\nhttps://qz.com/1635394/how-the-us-can-stop-real-estate-money-laundering.\n\n21. SOCIETAL HACKS ARE OFTEN NORMALIZED\n\n89Cisco announced multiple vulnerabilities: Michael Cooney (5 May 2022), “Cisco\nwarns of critical vulnerability in virtualized network software,” Network World,\nhttps://www.networkworld.com/article/3659872/cisco-warns-of-critical-vulnerability-in-virtualized-network-software.html.\n\n89F5 warned its customers: Harold Bell (5 May 2022), “F5 warns of BIG-IP\niControl REST vulnerability,” Security Boulevard,\nhttps://securityboulevard.com/2022/05/f5-warns-of-big-ip-icontrol-rest-vulnerability.\n\n89AVG Corporation announced: Charlie Osborne (5 May 2022), “Decade-old bugs\ndiscovered in Avast, AVG antivirus software,” ZD Net,\nhttps://www.zdnet.com/article/decade-old-bugs-discovered-in-avast-avg-antivirus-software.\n\n90a history of normalization: I could have written much the same story about\nindex funds. Annie Lowrey (Apr 2021), “Could index funds be ‘worse than\nMarxism’?” Atlantic,\nhttps://www.theatlantic.com/ideas/archive/2021/04/the-autopilot-economy/618497.\n\n91Normalization isn’t a new phenomenon: Robert Sabatino Lopez and Irving W.\nRaymond (2001), Medieval Trade in the Mediterranean World: Illustrative\nDocuments, Columbia University Press.\n\n22. HACKING THE MARKET\n\n92trucks would shuffle: David Kocieniewski (20 Jun 2013), “A shuffle of\naluminum, but to banks, pure gold,” New York Times,\nhttps://www.nytimes.com/2013/07/21/business/a-shuffle-of-aluminum-but-to-banks-pure-gold.html.\n\n93the economic interests of businessmen: Adam Smith (1776), The Wealth of\nNations, William Strahan, pp. 138, 219–220.\n\n23. “TOO BIG TO FAIL”\n\n98bail them out again if needed: Michael Greenberger (Jun 2018), “Too big to\nfail U.S. banks’ regulatory alchemy: Converting an obscure agency footnote into\nan ‘at will’ nullification of Dodd-Frank’s regulation of the multi-trillion\ndollar financial swaps market,” Institute for New Economic Thinking,\nhttps://www.ineteconomics.org/uploads/papers/WP_74.pdf.\n\n24. VENTURE CAPITAL AND PRIVATE EQUITY\n\n100We don’t want some central planner: Eric Levitz (3 Dec 2020), “America has\ncentral planners. We just call them ‘venture capitalists,’ ” New York Magazine,\nhttps://nymag.com/intelligencer/2020/12/wework-venture-capital-central-planning.html.\n\n102the case of Greensill Capital: Eshe Nelson, Jack Ewing, and Liz Alderman (28\nMarch 2021), “The swift collapse of a company built on debt,” New York Times,\nhttps://www.nytimes.com/2021/03/28/business/greensill-capital-collapse.html.\n\n25. HACKING AND WEALTH\n\n104cum-ex trading: David Segal (23 Jan 2020), “It may be the biggest tax heist\never. And Europe wants justice,” New York Times,\nhttps://www.nytimes.com/2020/01/23/business/cum-ex.html.\n\n104Germany recently sentenced: Karin Matussek (1 Jun 2021), “A banker’s long\nprison sentence puts industry on alert,” Bloomberg,\nhttps://www.bloomberg.com/news/articles/2021-06-01/prosecutors-seek-10-years-for-banker-in-398-million-cum-ex-case.\n\n104Two London bankers: Olaf Storbeck (19 Mar 2020), “Two former London bankers\nconvicted in first cum-ex scandal trial,” Financial Times,\nhttps://www.ft.com/content/550121de-69b3-11ea-800d-da70cff6e4d3.\n\n104A former senior German tax inspector: Olaf Storbeck (4 Apr 2022), “Former\nGerman tax inspector charged with €279mn tax fraud,” Financial Times,\nhttps://www.ft.com/content/e123a255-bc52-48c4-9022-ac9c4be06daa.\n\n104Frankfurt offices of Morgan Stanley bank: Agence France-Presse (3 May 2022),\n“German prosecutors raid Morgan Stanley in cum-ex probe,” Barron’s,\nhttps://www.barrons.com/news/german-prosecutors-raid-morgan-stanley-in-cum-ex-probe-01651575308.\n\n105Donald Trump famously said: Daniella Diaz (27 Sep 2016), “Trump: ‘I’m smart’\nfor not paying taxes,” CNN,\nhttps://www.cnn.com/2016/09/26/politics/donald-trump-federal-income-taxes-smart-debate/index.html.\n\n105if he only exploited legal loopholes: A 1935 US Supreme Court ruling\nconfirmed this: “Anyone may so arrange his affairs that his taxes shall be as\nlow as possible; he is not bound to choose that pattern which will best pay the\nTreasury; there is not even a patriotic duty to increase one’s taxes.” US\nSupreme Court (7 Jan 1935), Gregory v. Helvering, 293 US 465,\nhttps://www.courtlistener.com/opinion/102356/gregory-v-helvering.\n\n26. HACKING LAWS\n\n110the turducken was originally: That’s a turkey stuffed with a duck stuffed\nwith a chicken. The particulars are modern, dreamed up by chef Paul Prudhomme. I\ntried making it once; it’s not worth the work.\n\n110emergency loan program: Jeanna Smialek (30 Jul 2020), “How Pimco’s\nCayman-based hedge fund can profit from the Fed’s rescue,” New York Times,\nhttps://www.nytimes.com/2020/07/30/business/economy/fed-talf-wall-street.html.\n\n27. LEGAL LOOPHOLES\n\n112“Zone of Death”: Brian C. Kalt (2005), “The perfect crime,” Georgetown Law\nJournal 93, no. 2, https://fliphtml5.com/ukos/hbsu/basic.\n\n113his lawyers used this hack: Clark Corbin (3 Feb 2022), “Idaho legislator asks\nU.S. Congress to close Yellowstone’s ‘zone of death’ loophole,” Idaho Capital\nSun,\nhttps://idahocapitalsun.com/2022/02/03/idaho-legislator-asks-u-s-congress-to-close-yellowstones-zone-of-death-loophole.\n\n113A more sinister version of this hack: Louise Erdrich (26 Feb 2013), “Rape on\nthe reservation,” New York Times,\nhttps://www.nytimes.com/2013/02/27/opinion/native-americans-and-the-violence-against-women-act.html.\n\n113state taxes being applied: US Supreme Court (6 Dec 1937), James v. Dravo\nContracting Co. (Case No. 190), 302 U.S. 134,\nhttps://tile.loc.gov/storage-services/service/ll/usrep/usrep302/usrep302134/usrep302134.pdf.\n\n113residents of federal enclaves: US Supreme Court (15 Jun 1970), Evans v.\nCornman (Case No. 236), 398 U.S. 419,\nhttps://www.justice.gov/sites/default/files/osg/briefs/2000/01/01/1999-2062.resp.pdf.\n\n114owners of a San Francisco restaurant: Andrew Lu (16 Jul 2012), “Foie gras ban\ndoesn’t apply to SF Social Club?” Law and Daily Life, FindLaw,\nhttps://www.findlaw.com/legalblogs/small-business/foie-gras-ban-doesnt-apply-to-sf-social-club.\n\n114a 2019 reauthorization was derailed: Indian Law Resource Center (Apr 2019),\n“VAWA reauthorization bill with strengthened tribal provisions advances out of\nthe House,” https://indianlaw.org/swsn/VAWA_Bill_2019. Indian Law Resource\nCenter (2019), “Ending violence against Native women,”\nhttps://indianlaw.org/issue/ending-violence-against-native-women.\n\n28. HACKING BUREAUCRACY\n\n115those who must comply with them: C. A. E. Goodhart (1984), Monetary Theory\nand Practice: The UK Experience, Springer,\nhttps://link.springer.com/book/10.1007/978-1-349-17295-5.\n\n115more, and cheaper, space probes: Howard E. McCurdy (2001), Faster, Better,\nCheaper: Low-Cost Innovation in the U.S. Space Program, Johns Hopkins University\nPress.\n\n116rents were collected after the harvest: James C. Scott (1985), Weapons of the\nWeak: Everyday Forms of Peasant Resistance, Yale University Press.\n\n116paying for rat tails: Michael G. Vann (2003), “Of rats, rice, and race: The\nGreat Hanoi Rat Massacre, an episode in French colonial history,” French\nColonial History 4, https://muse.jhu.edu/article/42110/pdf.\n\n116cars with even and odd license plates: Lucas W. Davis (2 Feb 2017), “Saturday\ndriving restrictions fail to improve air quality in Mexico City,” Scientific\nReports 7, article 41652, https://www.nature.com/articles/srep41652.\n\n116Uber drivers in Nairobi: Sean Cole (7 Aug 2020), “Made to be broken,” This\nAmerican Life, https://www.thisamericanlife.org/713/made-to-be-broken. Gianluca\nIazzolino (19 Jun 2019), “Going Karura. Labour subjectivities and contestation\nin Nairobi’s gig economy,” DSA2019: Opening Up Development, Open University,\nMilton Keynes,\nhttps://www.devstud.org.uk/past-conferences/2019-opening-up-development-conference.\n\n117FAA managers took Boeing’s side: Natalie Kitroeff, David Gelles, and Jack\nNicas (27 Jun 2019), “The roots of Boeing’s 737 Max crisis: A regulator relaxes\nits oversight,” New York Times,\nhttps://www.nytimes.com/2019/07/27/business/boeing-737-max-faa.html.\n\n117The FAA even waived: Gary Coglianese, Gabriel Scheffler, and Daniel E.\nWalters (30 Oct 2020), “The government’s hidden superpower: ‘Unrules,’ ”\nFortune,\nhttps://fortune.com/2020/10/30/federal-law-regulations-loopholes-waivers-unrules.\n\n29. HACKING AND POWER\n\n121“power interprets regulation as damage”: Julie Cohen and Chris Bavitz (21 Nov\n2019), “Between truth and power: The legal constructions of informational\ncapitalism,” Berkman Klein Center for Internet and Society at Harvard\nUniversity,\nhttps://cyber.harvard.edu/sites/default/files/2019-12/2019_11_21_Berkman_Julie_Cohen_NS.pdf.\n\n30. UNDERMINING REGULATIONS\n\n123Uber is a taxi service: The company was initially named UberCab but changed\nit for precisely this reason.\n\n123a hack of the taxi industry: Ruth Berens Collier, Veena Dubal, and\nChristopher Carter (Mar 2017), “The regulation of labor platforms: The politics\nof the Uber economy,” University of California Berkeley,\nhttps://brie.berkeley.edu/sites/default/files/reg-of-labor-platforms.pdf.\n\n123Uber has since leveraged: Uber Technologies, Inc. (2021), “2021 Form 10-K\nAnnual Report,” US Securities and Exchange Commission,\nhttps://www.sec.gov/ix?doc=/Archives/edgar/data/1543151/000154315122000008/uber-20211231.htm.\n\n124It has 3.5 million drivers: Brian Dean (23 Mar 2021), “Uber statistics 2022:\nHow many people ride with Uber?” Backlinko, https://backlinko.com/uber-users.\n\n124Airbnb is a similar hack: Paris Martineau (20 Mar 2019), “Inside Airbnb’s\n‘guerilla war’ against local governments,” Wired,\nhttps://www.wired.com/story/inside-Airbnbs-guerrilla-war-against-local-governments.\n\n125Payday loans are short-term loans: Carter Dougherty (29 May 2013), “Payday\nlenders evading rules pivot to installment loans,” Bloomberg,\nhttps://www.bloomberg.com/news/articles/2013-05-29/payday-lenders-evading-rules-pivot-to-installmant-loans.\n\n126They also operate as loan brokers: S. Lu (22 Aug 2018), “How payday lenders\nget around interest rate regulations,” WRAL (originally from the MagnifyMoney\nblog),\nhttps://www.wral.com/how-payday-lenders-get-around-interest-rate-regulations/17788314.\n\n126moved to Indian reservations: Liz Farmer (4 May 2015), “After payday lenders\nskirt state regulations, Feds step in,” Governing,\nhttps://www.governing.com/topics/finance/gov-payday-lending-consumer-crackdown.html.\n\n126there was a loophole: Dave McKinley and Scott May (30 Nov 2020), “Canadians\nbuzz through Buffalo as a way to beat border closure,” WGRZ,\nhttps://www.wgrz.com/article/news/local/canadians-buzz-through-buffalo-as-a-way-to-beat-border-closure/71-07c93156-1365-46ab-80c1-613e5b1d7938.\n\n126the industry needs to constantly work: Carter Dougherty (29 May 2013),\n“Payday lenders evading rules pivot to installment loans,” Bloomberg,\nhttps://www.bloomberg.com/news/articles/2013-05-29/payday-lenders-evading-rules-pivot-to-installmant-loans.\n\n31. JURISDICTIONAL INTERACTIONS\n\n128Global tax avoidance: Alex Cobham and Petr Jansky (Mar 2017), “Global\ndistribution of revenue loss from tax avoidance,” United Nations University\nWIDER Working Paper 2017/55,\nhttps://www.wider.unu.edu/sites/default/files/wp2017-55.pdf.\n\n128Total cost to global tax revenue: Ernesto Crivelli, Ruud A. de Mooij, and\nMichael Keen (29 May 2015), “Base erosion, profit shifting and developing\ncountries,” International Monetary Fund Working Paper 2015118,\nhttps://www.imf.org/en/Publications/WP/Issues/2016/12/31/Base-Erosion-Profit-Shifting-and-Developing-Countries-42973.\n\n128Combined Reporting Systems: Center for Budget and Policy Priorities (2019),\n“28 states plus D.C. require combined reporting for the state corporate income\ntax,”\nhttps://www.cbpp.org/27-states-plus-dc-require-combined-reporting-for-the-state-corporate-income-tax.\n\n130the “Delaware Loophole”: The Institute on Taxation and Economic Policy (Dec\n2015), “Delaware: An onshore tax haven,”\nhttps://itep.org/delaware-an-onshore-tax-haven/.\n\n130This allows companies to shift: Patricia Cohen (7 Apr 2016), “Need to hide\nsome income? You don’t have to go to Panama,” New York Times,\nhttps://www.nytimes.com/2016/04/08/business/need-to-hide-some-income-you-dont-have-to-go-to-panama.html.\n\n130the other forty-nine states: Leslie Wayne (30 Jun 2012), “How Delaware\nthrives as a corporate tax haven,” New York Times,\nhttps://www.nytimes.com/2012/07/01/business/how-delaware-thrives-as-a-corporate-tax-haven.html.\n\n32. ADMINISTRATIVE BURDENS\n\n132named this phenomenon: Pamela Herd and Donald P. Moynihan (2019),\nAdministrative Burden: Policymaking by Other Means, Russell Sage Foundation.\n\n132Florida’s unemployment insurance scheme: Rebecca Vallas (15 Apr 2020),\n“Republicans wrapped the safety net in red tape. Now we’re all suffering.”\nWashington Post,\nhttps://www.washingtonpost.com/outlook/2020/04/15/republicans-harder-access-safety-net.\n\n133prevent the submission: Vox staff (10 Jun 2020), “Why it’s so hard to get\nunemployment benefits,” Vox, https://www.youtube.com/watch?v=ualUPur6iks.\n\n133only accessible at specific hours: Emily Stewart (13 May 2020), “The American\nunemployment system is broken by design,” Vox,\nhttps://www.vox.com/policy-and-politics/2020/5/13/21255894/unemployment-insurance-system-problems-florida-claims-pua-new-york.\n\n133many people spent hours: Palm Beach Post Editorial Board (30 Nov 2020),\n“Where is that probe of the broken Florida unemployment system, Governor?”\nFlorida Today,\nhttps://www.floridatoday.com/story/opinion/2020/11/30/where-probe-broken-florida-unemployment-system-governor/6439594002.\n\n134The biggest offender was Louisiana: Elizabeth Nash (11 Feb 2020), “Louisiana\nhas passed 89 abortion restrictions since Roe: It’s about control, not health,”\nGuttmacher Institute,\nhttps://www.guttmacher.org/article/2020/02/louisiana-has-passed-89-abortion-restrictions-roe-its-about-control-not-health.\n\n134When the US Supreme Court ruled: US Supreme Court (29 Jun 1992), Planned\nParenthood of Southern Pennsylvania v. Casey, 505 U.S. 833 (1992),\nhttps://www.oyez.org/cases/1991/91-744.\n\n134less than half of families: L. V. Anderson (17 Feb 2015), “The Federal\nNutrition Program for Pregnant Women is a bureaucratic nightmare,” Slate,\nhttps://slate.com/human-interest/2015/02/the-wic-potato-report-a-symptom-of-the-bureaucratic-nightmare-that-is-americas-welfare-system.html.\n\n33. HACKING COMMON LAW\n\n135too complex for traditional analysis: Jon Kolko (6 Mar 2012), “Wicked\nproblems: Problems worth solving,” Stanford Social Innovation Review,\nhttps://ssir.org/books/excerpts/entry/wicked_problems_problems_worth_solving.\n\n136The English courts decided: England and Wales High Court (King’s Bench),\nEntick v. Carrington (1765), EWHC KB J98 1066.\n\n137patent injunction hack was adjudicated: US Supreme Court (15 May 2006), eBay\nInc. v. MercExchange, LLC, 547 U.S. 388,\nhttps://www.supremecourt.gov/opinions/05pdf/05-130.pdf.\n\n34. HACKING AS EVOLUTION\n\n139an unbroken piece of wire: M. Olin (2019), “The Eruv: From the Talmud to\nContemporary Art,” in S. Fine, ed., Jewish Religious Architecture: From Biblical\nIsrael to Modern Judaism, Koninklijke Brill NV.\n\n140just automatically stop: Elizabeth A. Harris (5 Mar 2012), “For Jewish\nSabbath, elevators do all the work,” New York Times,\nhttps://www.nytimes.com/2012/03/06/nyregion/on-jewish-sabbath-elevators-that-do-all-the-work.html.\n\n140there’s a Bluetooth device: JC staff (12 Aug 2010), “Israeli soldiers get\nShabbat Bluetooth phone,”\nhttps://www.thejc.com/news/israel/israeli-soldiers-get-shabbat-bluetooth-phone-1.17376.\n\n140states and institutions are developed: Francis Fukuyama (2014), Political\nOrder and Political Decay: From the Industrial Revolution to the Globalization\nof Democracy, Farrar, Straus & Giroux.\n\n140when conservative groups: Yoni Appelbaum (Dec 2019), “How America ends,”\nAtlantic,\nhttps://www.theatlantic.com/magazine/archive/2019/12/how-america-ends/600757.\nUri Friedman (14 Jun 2017), “Why conservative parties are central to democracy,”\nAtlantic,\nhttps://www.theatlantic.com/international/archive/2017/06/ziblatt-democracy-conservative-parties/530118.\nDavid Frum (20 Jun 2017), “Why do democracies fail?” Atlantic,\nhttps://www.theatlantic.com/international/archive/2017/06/why-do-democracies-fail/530949.\n\n141concept of corporate personhood: Adam Winkler (5 Mar 2018), “ ‘Corporations\nare people’ is built on an incredible 19th-century lie,” Atlantic,\nhttps://www.theatlantic.com/business/archive/2018/03/corporations-people-adam-winkler/554852.\n\n35. HIDDEN PROVISIONS IN LEGISLATION\n\n145intercepting network equipment: S. Silbert (16 May 2014), “Latest Snowden\nleak reveals the NSA intercepted and bugged Cisco routers,” Engadget,\nhttps://www.engadget.com/2014-05-16-nsa-bugged-cisco-routers.html.\n\n146lobbied for by Starbucks: Ben Hallman and Chris Kirkham (15 Feb 2013), “As\nObama confronts corporate tax reform, past lessons suggest lobbyists will fight\nfor loopholes,” Huffington Post,\nhttps://www.huffpost.com/entry/obama-corporate-tax-reform_n_2680880.\n\n146exemptions for “natural monopolies”: Leah Farzin (1 Jan 2015), “On the\nantitrust exemption for professional sports in the United States and Europe,”\nJeffrey S. Moorad Sports Law Journal 75,\nhttps://digitalcommons.law.villanova.edu/cgi/viewcontent.cgi?article=1321&context=mslj.\n\n146over 6,000 lobbyists: Taylor Lincoln (1 Dec 2017), “Swamped: More than half\nthe members of Washington’s lobbying corps have plunged into the tax debate,”\nPublic Citizen,\nhttps://www.citizen.org/wp-content/uploads/migration/swamped-tax-lobbying-report.pdf.\n\n146gift for Teach For America: Valerie Strauss (16 Oct 2013), “The debt deal’s\ngift to Teach For America (yes, TFA),” Washington Post,\nhttps://www.washingtonpost.com/news/answer-sheet/wp/2013/10/16/the-debt-deals-gift-to-teach-for-america-yes-tfa.\n\n147how real estate investors could offset: Jesse Drucker (26 Mar 2020), “Bonanza\nfor rich real estate investors, tucked into stimulus package,” New York Times,\nhttps://www.nytimes.com/2020/03/26/business/coronavirus-real-estate-investors-stimulus.html.\nNicholas Kristof (23 May 2020), “Crumbs for the hungry but windfalls for the\nrich,” New York Times,\nhttps://www.nytimes.com/2020/05/23/opinion/sunday/coronavirus-economic-response.html.\n\n147Republican staffers added the provision: Akela Lacy (19 Apr 2020), “Senate\nFinance Committee Democrats tried to strike millionaire tax break from\ncoronavirus stimulus—then failed to warn others about it,” Intercept,\nhttps://theintercept.com/2020/04/19/coronavirus-cares-act-millionaire-tax-break.\n\n147This kind of thing is so common: GOP congressional aide Billy Pitts said in\n2017: “What got snuck into there? What got airdropped into there in conference\nor whatever? That’s always the threat of a big, fat bill—there’s always\nsomething hidden inside of it.”\nhttps://www.npr.org/2017/03/11/519700465/when-it-comes-to-legislation-sometimes-bigger-is-better.\n\n147Krusty the Clown gets elected to Congress: Matt Groening and J. L. Brooks (11\nFeb 1996), “Bart the fink,” The Simpsons, Season 7, episode 15, Fox Broadcasting\nCompany/YouTube, https://www.youtube.com/watch?v=hNeIkS9EMV0.\n\n148part of its ninety-seven recommendations: Select Committee on the\nModernization of Congress (2019), “116th Congress recommendations,”\nhttps://modernizecongress.house.gov/116th-recommendations.\n\n148goal would be to make it easier: Select Committee on the Modernization of\nCongress (2019), “Finalize a new system that allows the American people to\neasily track how amendments change legislation and the impact of proposed\nlegislation to current law,” Final Report,\nhttps://modernizecongress.house.gov/final-report-116th/chapter/recommendation/finalize-a-new-system-that-allows-the-american-people-to-easily-track-how-amendments-change-legislation-and-the-impact-of-proposed-legislation-to-current-law.\n\n149the CARES Act was released: Mia Jankowicz (22 Dec 2020), “ ‘It’s\nhostage-taking.’ AOC lashed out after lawmakers got only hours to read and pass\nthe huge 5,593-page bill to secure COVID-19 relief,” Business Insider,\nhttps://www.businessinsider.com/aoc-angry-representatives-2-hours-read-covid-19-stimulus-bill-2020-12.\n\n149The measure contained $110 billion: Yeganeh Torbati (22 Dec 2020), “Tucked\ninto Congress’s massive stimulus bill: Tens of billions in special-interest tax\ngiveaways,” Washington Post,\nhttps://www.washingtonpost.com/business/2020/12/22/congress-tax-breaks-stimulus.\n\n149Many lawmakers were unaware: Akela Lacy (19 Apr 2020), “Senate Finance\nCommittee Democrats tried to strike millionaire tax break from coronavirus\nstimulus—then failed to warn others about it,” Intercept,\nhttps://theintercept.com/2020/04/19/coronavirus-cares-act-millionaire-tax-break.\n\n36. MUST-PASS LEGISLATION\n\n151the logic behind single-subject laws: US Congress (10 Apr 2019; latest action\n20 May 2019), H.R. 2240: One Subject at a Time Act, 116th Congress,\nhttps://www.congress.gov/bill/116th-congress/house-bill/2240.\n\n151Minnesota’s constitution: State of Minnesota (13 Oct 1857; revised 5 Nov\n1974), Constitution of the State of Minnesota, Article IV: Legislative\nDepartment, https://www.revisor.mn.gov/constitution/#article_4.\n\n152an older Pennsylvania Supreme Court case: Richard Briffault (2019), “The\nsingle-subject rule: A state constitutional dilemma,” Albany Law Review 82,\nhttps://scholarship.law.columbia.edu/cgi/viewcontent.cgi?article=3593&context=faculty_scholarship.\n\n152several organizations have proposed: Committee for a Responsible Federal\nBudget (17 Sep 2020), “Better Budget Process Initiative: Automatic CRs can\nimprove the appropriations process,”\nhttp://www.crfb.org/papers/better-budget-process-initiative-automatic-crs-can-improve-appropriations-process.\n\n37. DELEGATING AND DELAYING LEGISLATION\n\n154between 3,000 and 4,000 new administrative rules: Clyde Wayne Crews and Kent\nLassman (30 Jun 2021), “New Ten Thousand Commandments report evaluates the\nsweeping hidden tax of regulation; Provides definitive assessment of Trump\nderegulatory legacy,” Competitive Enterprise Institute,\nhttps://cei.org/studies/ten-thousand-commandments-2020.\n\n155filibuster was most often used: Zack Beauchamp (25 Mar 2021), “The\nfilibuster’s racist history, explained,” Vox,\nhttps://www.vox.com/policy-and-politics/2021/3/25/22348308/filibuster-racism-jim-crow-mitch-mcconnell.\n\n156misused as a delaying tactic: Lauren C. Bell (14 Nov 2018), “Obstruction in\nparliaments: A cross-national perspective,” Journal of Legislative Studies,\nhttps://www.tandfonline.com/doi/full/10.1080/13572334.2018.1544694.\n\n156In the Japanese Diet: Michael Macarthur Bosack (31 Jan 2020), “Ox walking,\nheckling and other strange Diet practices,” Japan Times,\nhttps://www.japantimes.co.jp/opinion/2020/01/31/commentary/japan-commentary/ox-walking-heckling-strange-diet-practices.\n\n156a 2016 constitutional reform bill: Gazetta del Sud staff (11 April 2016),\n“Democracy doesn’t mean obstructionism says Renzi,”\nhttps://www.ansa.it/english/news/2016/04/11/democracy-doesnt-mean-obstructionism-says-renzi-2_e16b1463-aa10-432a-b40e-28a00354b182.html.\n\n38. THE CONTEXT OF A HACK\n\n157Loose language in the: Natalie Kitroeff (27 Dec 2017), “In a complex tax\nbill, let the hunt for loopholes begin,” New York Times,\nhttps://www.nytimes.com/2017/12/27/business/economy/tax-loopholes.html.\n\n158It’s impossible to know for sure: Edmund L. Andrews (13 Oct 2004), “How tax\nbill gave business more and more,” New York Times,\nhttps://www.nytimes.com/2004/10/13/business/how-tax-bill-gave-business-more-and-more.html.\n\n158Curved sticks make for a faster puck: National Hockey League (accessed 11 May\n2022), “Historical rule changes,”\nhttps://records.nhl.com/history/historical-rule-changes.\n\n158opposition to private ownership: Donald Clarke (19 Jan 2017), “The paradox at\nthe heart of China’s property regime,” Foreign Policy,\nhttps://foreignpolicy.com/2017/01/19/the-paradox-at-the-heart-of-chinas-property-regime-wenzhou-lease-renewal-problems.\nSebastian Heilmann (2008), “Policy experimentation in China’s economic rise,”\nStudies in Comparative International Development 43,\nhttps://link.springer.com/article/10.1007/s12116-007-9014-4.\n\n160Trump withdrew his nomination: Lara Seligman (2 Aug 2020), “Trump skirts\nSenate to install nominee under fire for Islamaphobic tweets in Pentagon post,”\nPolitico,\nhttps://www.politico.com/news/2020/08/02/donald-trump-anthony-tata-pentagon-390851.\n\n160It depends on your opinion: Kevin Drum (3 Aug 2020), “Do we really need\nSenate confirmation of 1,200 positions?” Mother Jones,\nhttps://www.motherjones.com/kevin-drum/2020/08/do-we-really-need-senate-confirmation-of-1200-positions.\n\n39. HACKING VOTING ELIGIBILITY\n\n161a coalition of conservative Democrats: Joshua Shiver (16 Apr 2020), “Alabama\nConstitution of 1875,” Encyclopedia of Alabama,\nhttp://encyclopediaofalabama.org/article/h-4195.\n\n162These efforts culminated: Alabama Legislature (22 May 1901), “Constitutional\nConvention, second day,”\nhttp://www.legislature.state.al.us/aliswww/history/constitutions/1901/proceedings/1901_proceedings_vol1/day2.html.\n\n162The constitution introduced or entrenched: John Lewis and Archie E. Allen (1\nOct 1972), “Black voter registration efforts in the South,” Notre Dame Law\nReview 48, no. 1, p. 107,\nhttps://scholarship.law.nd.edu/cgi/viewcontent.cgi?article=2861&context=ndlr.\n\n162In 1903, fewer than 3,000: Rachel Knowles (10 February 2020), “Alive and\nwell: Voter suppression and election mismanagement in Alabama,” Southern Poverty\nLaw Center,\nhttps://www.splcenter.org/20200210/alive-and-well-voter-suppression-and-election-mismanagement-alabama#Disenfranchisement.\n\n162The 1964 Louisiana literacy test: Open Culture staff (16 Nov 2014), “Watch\nHarvard students fail the literacy test Louisiana used to suppress the Black\nvote in 1964,” Open Culture,\nhttp://www.openculture.com/2014/11/harvard-students-fail-the-literacy-test.html.\n\n40. OTHER ELECTION HACKS\n\n164these hacks were only banned: Constitutional Rights Foundation (n.d.,\naccessed 1 Jun 2022), “Race and voting,”\nhttps://www.crf-usa.org/brown-v-board-50th-anniversary/race-and-voting.html. US\nSupreme Court (7 Mar 1966), South Carolina v. Katzenbach (Case No. 22), 383 U.S.\n301, http://cdn.loc.gov/service/ll/usrep/usrep383/usrep383301/usrep383301.pdf.\n\n165people can be denied the right to vote: Peter Dunphy (5 Nov 2018), “When it\ncomes to voter suppression, don’t forget about Alabama,” Brennan Center,\nhttps://www.brennancenter.org/our-work/analysis-opinion/when-it-comes-voter-suppression-dont-forget-about-alabama.\n\n41. MONEY IN POLITICS\n\n169a 1976 ruling excluded money spent: Yasmin Dawood (30 Mar 2015), “Campaign\nfinance and American democracy,” Annual Review of Political Science,\nhttps://www.annualreviews.org/doi/pdf/10.1146/annurev-polisci-010814-104523.\n\n169Lawrence Lessig argues: Lawrence Lessig (2014), The USA Is Lesterland,\nCreateSpace Independent Publishing Platform.\n\n169in the 2012 Republican primary: Kenneth P. Vogel (12 Jan 2012), “3\nbillionaires who’ll drag out the race,” Politico,\nhttps://www.politico.com/story/2012/01/meet-the-3-billionaires-wholl-drag-out-the-race-071358.\n\n170take advantage of Green Party candidates: Sam Howe Verhovek (8 Aug 2001),\n“Green Party candidate finds he’s a Republican pawn,” New York Times,\nhttps://www.nytimes.com/2001/08/08/us/green-party-candidate-finds-he-s-a-republican-pawn.html.\n\n170Alex Rodriguez ran against: Sun-Sentinel Editorial Board (25 Nov 2020),\n“Evidence of fraud in a Florida election. Where’s the outrage?” South Florida\nSun-Sentinel,\nhttps://www.sun-sentinel.com/opinion/editorials/fl-op-edit-florida-election-fraud-20201125-ifg6ssys35bjrp7bes6xzizon4-story.html.\n\n170a person with the same name: Rama Lakshmi (23 Apr 2014), “Sahu vs. Sahu vs.\nSahu: Indian politicians run ‘clone’ candidates to trick voters,” Washington\nPost,\nhttps://www.washingtonpost.com/world/sahu-vs-sahu-vs-sahu-indian-politicians-run-clone-candidates-to-trick-voters/2014/04/23/613f7465-267e-4a7f-bb95-14eb9a1c6b7a_story.html.\n\n42. HACKING TO DESTRUCTION\n\n172he formed a syndicate: Andy Williamson (16 May 2013), “How Voltaire made a\nfortune rigging the lottery,” Today I Found Out,\nhttp://www.todayifoundout.com/index.php/2013/05/how-voiltaire-made-a-fortune-rigging-the-lottery.\n\n173automatically submitted fake reports: Janus Rose (8 May 2020), “This script\nsends junk data to Ohio’s website for snitching on workers,” Vice,\nhttps://www.vice.com/en_us/article/wxqemy/this-script-sends-junk-data-to-ohios-website-for-snitching-on-workers.\n\n173fake ticket requests: Taylor Lorenz, Kellen Browning, and Sheera Frenkel (21\nJun 2020), “TikTok teens and K-Pop stans say they sank Trump rally,” New York\nTimes, https://www.nytimes.com/2020/06/21/style/tiktok-trump-rally-tulsa.html.\n\n174Zimbabwe experienced hyperinflation: Janet Koech (2012), “Hyperinflation in\nZimbabwe,” Federal Reserve Bank of Dallas Globalization and Monetary Policy\nInstitute 2011 Annual Report,\nhttps://www.dallasfed.org/~/media/documents/institute/annual/2011/annual11b.pdf.\n\n174In Venezuela, hyperinflation began: Patricia Laya and Fabiola Zerpa (5 Oct\n2020), “Venezuela mulls 100,000 Bolivar bill. Guess how much it’s worth?,”\nBloomberg,\nhttps://www.bloombergquint.com/onweb/venezuela-planning-new-100-000-bolivar-bills-worth-just-0-23.\nGonzalo Huertas (Sep 2019), “Hyperinflation in Venezuela: A stabilization\nhandbook,” Peterson Institute for International Economics Policy Brief 19-13,\nhttps://www.piie.com/sites/default/files/documents/pb19-13.pdf.\n\n43. COGNITIVE HACKS\n\n181Goebbels, Hitler’s propaganda minister: Jason Stanley (2016), How Propaganda\nWorks, Princeton University Press,\nhttps://press.princeton.edu/books/paperback/9780691173429/how-propaganda-works.\n\n181Cory Doctorow cautions us: Cory Doctorow (26 Aug 2020), “How to destroy\nsurveillance capitalism,” OneZero,\nhttps://onezero.medium.com/how-to-destroy-surveillance-capitalism-8135e6744d59.\n\n44. ATTENTION AND ADDICTION\n\n183Everyone hates pop-up ads: Ethan Zuckerman (14 Aug 2014), “The internet’s\noriginal sin,” Atlantic,\nhttps://www.theatlantic.com/technology/archive/2014/08/advertising-is-the-internets-original-sin/376041.\n\n184Jules Chéret invented a new form: Richard H. Driehaus Museum (14 Mar 2017),\n“Jules Chéret and the history of the artistic poster,”\nhttp://driehausmuseum.org/blog/view/jules-cheret-and-the-history-of-the-artistic-poster.\n\n45. PERSUASION\n\n188people often resist attempts: Marieke L. Fransen, Edith G. Smit, and Peeter\nW. J. Verlegh (14 Aug 2015), “Strategies and motives for resistance to\npersuasion: an integrative framework,” Frontiers in Psychology 6, article 1201,\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC4536373.\n\n189drip pricing resulted in people spending: Morgan Foy (9 Feb 2021), “Buyer\nbeware: Massive experiment shows why ticket sellers hit you with last-second\nfees,” Haas School of Business, University of California, Berkeley,\nhttps://newsroom.haas.berkeley.edu/research/buyer-beware-massive-experiment-shows-why-ticket-sellers-hit-you-with-hidden-fees-drip-pricing.\n\n46. TRUST AND AUTHORITY\n\n191“Only amateurs attack machines”: Bruce Schneier (15 Oct 2000), “Semantic\nattacks: The third wave of network attacks,” Crypto-Gram,\nhttps://www.schneier.com/crypto-gram/archives/2000/1015.html#1.\n\n191One victim lost $24 million: Joeri Cant (22 Oct 2019), “Victim of $24 million\nSIM swap case writes open letter to FCC chairman,” Cointelegraph,\nhttps://cointelegraph.com/news/victim-of-24-million-sim-swap-case-writes-open-letter-to-fcc-chairman.\n\n192the 2020 Twitter hackers: Twitter (18 Jul 2020; updated 30 Jul 2020), “An\nupdate on our security incident,” Twitter blog,\nhttps://blog.twitter.com/en_us/topics/company/2020/an-update-on-our-security-incident.\n\n192the CEO of an unnamed UK energy company: Nick Statt (5 Sep 2019), “Thieves\nare now using AI deepfakes to trick companies into sending them money,” Verge,\nhttps://www.theverge.com/2019/9/5/20851248/deepfakes-ai-fake-audio-phone-calls-thieves-trick-companies-stealing-money.\n\n192one scam artist has used a silicone mask: Hugh Schofield (20 Jun 2019), “The\nfake French minister in a silicone mask who stole millions,” BBC News,\nhttps://www.bbc.com/news/world-europe-48510027.\n\n193a video of Gabon’s long-missing president: Drew Harwell (12 Jun 2019), “Top\nAI researchers race to detect ‘deepfake’ videos: ‘We are outgunned,’ ”\nWashington Post,\nhttps://www.washingtonpost.com/technology/2019/06/12/top-ai-researchers-race-detect-deepfake-videos-we-are-outgunned.\n\n193BuzzFeed found 140 fake news websites: Craig Silverman and Lawrence Alexander\n(3 Nov 2016), “How teens in the Balkans are duping Trump supporters with fake\nnews,” BuzzFeed,\nhttps://www.buzzfeednews.com/article/craigsilverman/how-macedonia-became-a-global-hub-for-pro-trump-misinfo.\n\n47. FEAR AND RISK\n\n195very basic brain functions: Bruce Schneier (3 Apr 2000), “The difference\nbetween feeling and reality in security,” Wired,\nhttps://www.wired.com/2008/04/securitymatters-0403.\n\n196Terrorism directly hacks: Bruce Schneier (17 May 2007), “Virginia Tech\nlesson: Rare risks breed irrational responses,” Wired,\nhttps://www.wired.com/2007/05/securitymatters-0517.\n\n196“When people are insecure”: Nate Silver (1 Feb 2010), “Better to be strong\nand wrong—especially when you’re actually right,” FiveThirtyEight,\nhttps://fivethirtyeight.com/features/better-to-be-strong-and-wrong.\n\n197“immigrants are going to take your jobs”: Fox News (26 Jan 2017), “The truth\nabout jobs in America,” The O’Reilly Factor (transcript),\nhttps://www.foxnews.com/transcript/the-truth-about-jobs-in-america.\n\n197“[this or that city] is crime-ridden”: Audrey Conklin (21 Feb 2022),\n“Homicides, rapes in Atlanta soar despite other decreasing violent crime,” Fox\nNews, https://www.foxnews.com/us/homicides-rapes-atlanta-soar-2022.\n\n197“ISIS is a threat to Americans”: Ronn Blitzer (26 Oct 2021), “Top Pentagon\nofficial confirms ISIS-K could have capability to attack US in ‘6 to 12 months,’\n” Fox News,\nhttps://www.foxnews.com/politics/pentagon-official-isis-k-us-attack-6-to-12-months.\n\n197“Democrats are going to take your guns”: Tucker Carlson (9 Apr 2021), “Biden\nwants to take your guns, but leave criminals with theirs,” Fox News,\nhttps://www.foxnews.com/opinion/tucker-carlson-biden-gun-control-disarm-trump-voters.\n\n48. DEFENDING AGAINST COGNITIVE HACKS\n\n199Foreknowledge only goes so far: Leah Savion (Jan 2009), “Clinging to\ndiscredited beliefs: The larger cognitive story,” Journal of the Scholarship of\nTeaching and Learning 9, no. 1, https://files.eric.ed.gov/fulltext/EJ854880.pdf.\n\n49. A HIERARCHY OF HACKING\n\n201Jeff Bezos had no problem: Sam Dangremond (4 Apr 2019), “Jeff Bezos is\nrenovating the biggest house in Washington, D.C.,” Town and Country,\nhttps://www.townandcountrymag.com/leisure/real-estate/news/a9234/jeff-bezos-house-washington-dc.\n\n201Ghostwriter, a collective: Lee Foster et al. (28 Jul 2020), “ ‘Ghostwriter’\ninfluence campaign: Unknown actors leverage website compromises and fabricated\ncontent to push narratives aligned with Russian security interests,” Mandiant,\nhttps://www.fireeye.com/blog/threat-research/2020/07/ghostwriter-influence-campaign.html.\n\n50. ARTIFICIAL INTELLIGENCE AND ROBOTICS\n\n206Marvin Minsky described AI: Marvin Minsky (1968), “Preface,” in Semantic\nInformation Processing, MIT Press.\n\n206Patrick Winston, another AI pioneer: Patrick Winston (1984), Artificial\nIntelligence, Addison-Wesley.\n\n206probably decades away: Futurist Martin Ford surveyed twenty-three prominent\nAI researchers and asked them by what year is there at least a 50% chance of\ngeneralized AI being built. The answers ranged between 2029 and 2200, with the\naverage answer being 2099: which I’m guessing is a cop-out “before the end of\nthe century” answer. Martin Ford (2018), Architects of Intelligence: The Truth\nAbout AI from the People Building It, Packt Publishing.\n\n208Def: Robot /bät/ (noun): Kate Darling (2021), The New Breed: What Our History\nwith Animals Reveals about Our Future with Robots, Henry Holt.\n\n52. THE EXPLAINABILITY PROBLEM\n\n212Deep Thought informs them: Douglas Adams (1978), The Hitchhiker’s Guide to\nthe Galaxy, BBC Radio 4.\n\n212AlphaGo won a five-game match: Cade Metz (16 Mar 2016), “In two moves,\nAlphaGo and Lee Sedol redefined the future,” Wired,\nhttps://www.wired.com/2016/03/two-moves-alphago-lee-sedol-redefined-future.\n\n213“the magical number seven”: George A. Miller (1956), “The magical number\nseven, plus or minus two: Some limits on our capacity for processing\ninformation,” Psychological Review 63, no. 2,\nhttp://psychclassics.yorku.ca/Miller.\n\n214explainability is especially important: J. Fjeld et al. (15 Jan 2020),\n“Principled artificial intelligence: Mapping consensus in ethical and\nrights-based approaches to principled AI,” Berkman Klein Center for Internet and\nSociety, https://cyber.harvard.edu/publication/2020/principled-ai.\n\n214if an AI system: Select Committee on Artificial Intelligence (16 Apr 2018),\n“AI in the UK: Ready, willing and able?” House of Lords,\nhttps://publications.parliament.uk/pa/ld201719/ldselect/ldai/100/100.pdf.\n\n215Amazon executives lost enthusiasm: Jeffrey Dastin (10 Oct 2018), “Amazon\nscraps secret AI recruiting tool that shows bias against women,” Reuters,\nhttps://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G.\n\n215multiple contradictory definitions of fairness: David Weinberger (accessed 11\nMay 2022), “Playing with AI fairness,” What-If Tool,\nhttps://pair-code.github.io/what-if-tool/ai-fairness.html. David Weinberger (6\nNov 2019), “How machine learning pushes us to define fairness,” Harvard Business\nReview,\nhttps://hbr.org/2019/11/how-machine-learning-pushes-us-to-define-fairness.\n\n53. HUMANIZING AI\n\n217program called ELIZA: Joseph Weizenbaum (Jan 1966), “ELIZA: A computer\nprogram for the study of natural language communication between man and\nmachine,” Communications of the ACM,\nhttps://web.stanford.edu/class/linguist238/p36-weizenabaum.pdf.\n\n217voice assistants like Alexa and Siri: James Vincent (22 Nov 2019), “Women are\nmore likely than men to say ‘please’ to their smart speaker,” Verge,\nhttps://www.theverge.com/2019/11/22/20977442/ai-politeness-smart-speaker-alexa-siri-please-thank-you-pew-gender-sur.\n\n217they didn’t want to hurt its feelings: Clifford Nass, Youngme Moon, and Paul\nCarney (31 Jul 2006), “Are people polite to computers? Responses to\ncomputer-based interviewing systems,” Journal of Applied Social Psychology,\nhttps://onlinelibrary.wiley.com/doi/abs/10.1111/j.1559-1816.1999.tb00142.x.\n\n217the subject was likely to reciprocate: Youngme Moon (Mar 2000), “Intimate\nexchanges: Using computers to elicit self-disclosure from consumers,” Journal of\nConsumer Research, https://www.jstor.org/stable/10.1086/209566?seq=1.\n\n217robot ran into problems: Joel Garreau (6 May 2007), “Bots on the ground,”\nWashington Post,\nhttps://www.washingtonpost.com/wp-dyn/content/article/2007/05/05/AR2007050501009_pf.html.\n\n218a study on human trust in robots: Paul Robinette et al. (Mar 2016),\n“Overtrust of robots in emergency evacuation scenarios,” 2016 ACM/IEEE\nInternational Conference on Human-Robot Interaction,\nhttps://www.cc.gatech.edu/~alanwags/pubs/Robinette-HRI-2016.pdf.\n\n218“When robots make eye contact”: Sherry Turkle (2010), “In good company,” in\nYorick Wilks, ed., Close Engagements with Artificial Companions, John Benjamin\nPublishing.\n\n54. AI AND ROBOTS HACKING US\n\n220bots being used to spread propaganda: Samantha Bradshaw and Philip N. Howard\n(2019), “The global disinformation order: 2019 global inventory of organised\nsocial media manipulation,” Computational Propaganda Research Project,\nhttps://comprop.oii.ox.ac.uk/wp-content/uploads/sites/93/2019/09/CyberTroop-Report19.pdf.\n\n220Modern text-creation systems: Tom Simonite (22 Jul 2020), “Did a person write\nthis headline, or a machine?” Wired,\nhttps://www.wired.com/story/ai-text-generator-gpt-3-learning-language-fitfully.\n\n221public input on a Medicaid issue: Max Weiss (17 Dec 2019), “Deepfake bot\nsubmissions to federal public comment websites cannot be distinguished from\nhuman submissions,” Technology Science, https://techscience.org/a/2019121801.\n\n222an animatronic plastic dinosaur named Cleo: Kate Darling (2021), The New\nBreed: What Our History with Animals Reveals about Our Future with Robots, Henry\nHolt.\n\n222a creature with feelings: Woodrow Hartzog (4 May 2015), “Unfair and deceptive\nrobots,” Maryland Law Review,\nhttps://papers.ssrn.com/sol3/papers.cfm?abstract_id=2602452.\n\n222a robot was able to exert “peer pressure”: Yaniv Hanoch et al. (17 May 2021),\n“The robot made me do it: Human–robot interaction and risk-taking behavior,”\nCyberpsychology, Behavior, and Social Networking,\nhttps://www.liebertpub.com/doi/10.1089/cyber.2020.0148.\n\n55. COMPUTERS AND AI ARE ACCELERATING SOCIETAL HACKING\n\n224computers scale rote tasks: Karlheinz Meier (31 May 2017), “The brain as\ncomputer: Bad at math, good at everything else,” IEEE Spectrum,\nhttps://spectrum.ieee.org/the-brain-as-computer-bad-at-math-good-at-everything-else.\n\n225Donotpay.com automates the process: Samuel Gibbs (28 Jun 2016), “Chatbot\nlawyer overturns 160,000 parking tickets in London and New York,” Guardian,\nhttps://www.theguardian.com/technology/2016/jun/28/chatbot-ai-lawyer-donotpay-parking-tickets-london-new-york.\n\n225Automated A/B testing: Amy Gallo (28 Jun 2017), “A refresher on A/B testing,”\nHarvard Business Review, https://hbr.org/2017/06/a-refresher-on-ab-testing.\n\n225they have the potential to overwhelm: California has a law requiring bots to\nidentify themselves. Renee DiResta (24 Jul 2019), “A new law makes bots identify\nthemselves—that’s the problem,” Wired,\nhttps://www.wired.com/story/law-makes-bots-identify-themselves.\n\n226“flash crashes” of the stock market: Laim Vaughan (2020), Flash Crash: A\nTrading Savant, a Global Manhunt, and the Most Mysterious Market Crash in\nHistory, Doubleday.\n\n226these systems are vulnerable to hacking: Shafi Goldwasser et al. (14 Apr\n2022), “Planting undetectable backdoors in machine learning models,” arXiv,\nhttps://arxiv.org/abs/2204.06974.\n\n56. WHEN AIs BECOME HACKERS\n\n228a similarly styled event for AI: Jia Song and Jim Alves-Foss (Nov 2015), “The\nDARPA Cyber Grand Challenge: A competitor’s perspective,” IEEE Security and\nPrivacy Magazine 13, no. 6,\nhttps://www.researchgate.net/publication/286490027_The_DARPA_cyber_grand_challenge_A_competitor%27s_perspective.\n\n229Chinese AI systems are improving: Dakota Cary (Sep 2021), “Robot hacking\ngames: China’s competitions to automate the software vulnerability lifecycle,”\nCenter for Security and Emerging Technology,\nhttps://cset.georgetown.edu/wp-content/uploads/CSET-Robot-Hacking-Games.pdf.\n\n229research is continuing: Bruce Schneier (18 Dec 2018) “Machine learning will\ntransform how we detect software vulnerabilities,” Security Intelligence,\nhttps://securityintelligence.com/machine-learning-will-transform-how-we-detect-software-vulnerabilities/.\n\n230looking for loopholes in contracts: Economist staff (12 Jun 2018), “Law firms\nclimb aboard the AI wagon,” Economist,\nhttps://www.economist.com/business/2018/07/12/law-firms-climb-aboard-the-ai-wagon.\n\n57. REWARD HACKING\n\n231AI achieving a goal in a way: A list of examples is here. Victoria Krakovna\n(2 Apr 2018), “Specification gaming examples in AI,”\nhttps://vkrakovna.wordpress.com/2018/04/02/specification-gaming-examples-in-ai.\n\n231if it kicked the ball out of bounds: Karol Kurach et al. (25 Jul 2019),\n“Google research football: A novel reinforcement learning environment,” arXiv,\nhttps://arxiv.org/abs/1907.11180.\n\n231AI was instructed to stack blocks: Ivaylo Popov et al. (10 Apr 2017),\n“Data-efficient deep reinforcement learning for dexterous manipulation,” arXiv,\nhttps://arxiv.org/abs/1704.03073.\n\n232the AI grew tall enough: David Ha (10 Oct 2018), “Reinforcement learning for\nimproving agent design,” https://designrl.github.io.\n\n232Imagine a robotic vacuum: Dario Amodei et al. (25 Jul 2016), “Concrete\nproblems in AI safety,” arXiv, https://arxiv.org/pdf/1606.06565.pdf.\n\n232robot vacuum to stop bumping: Custard Smingleigh (@Smingleigh) (7 Nov 2018),\nTwitter, https://twitter.com/smingleigh/status/1060325665671692288.\n\n233goals and desires are always underspecified: Abby Everett Jaques (2021), “The\nUnderspecification Problem and AI: For the Love of God, Don’t Send a Robot Out\nfor Coffee,” unpublished manuscript.\n\n233a fictional AI assistant: Stuart Russell (Apr 2017), “3 principles for\ncreating safer AI,” TED2017,\nhttps://www.ted.com/talks/stuart_russell_3_principles_for_creating_safer_ai.\n\n233reports of airline passengers: Melissa Koenig (9 Sep 2021), “Woman, 46, who\nmissed her JetBlue flight ‘falsely claimed she planted a BOMB on board’ to delay\nplane so her son would not be late to school,” Daily Mail,\nhttps://www.dailymail.co.uk/news/article-9973553/Woman-46-falsely-claims-planted-BOMB-board-flight-effort-delay-plane.html.\nElla Torres (18 Jan 2020), “London man reports fake bomb threat to delay flight\nhe was running late for: Police,” ABC News,\nhttps://abcnews.go.com/International/london-man-reports-fake-bomb-threat-delay-flight/story?id=68369727.\nPeter Stubley (16 Aug 2018), “Man makes hoax bomb threat to delay his flight,”\nIndependent,\nhttps://www.independent.co.uk/news/uk/crime/man-late-flight-hoax-bomb-threat-gatwick-airport-los-angeles-jacob-meir-abdellak-hackney-a8494681.html.\nReuters (20 Jun 2007), “Woman delays Turkish plane with fake bomb warning,”\nhttps://www.reuters.com/article/us-turkey-plane-bomb-idUSL2083245120070620.\n\n58. DEFENDING AGAINST AI HACKERS\n\n236recommendation engines: Zeynep Tufekci (10 Mar 2018), “YouTube, the great\nequalizer,” New York Times,\nhttps://www.nytimes.com/2018/03/10/opinion/sunday/youtube-politics-radical.html.\nRenee DiResta (11 Apr 2018), “Up next: A better recommendation system,” Wired,\nhttps://www.wired.com/story/creating-ethical-recommendation-engines.\n\n237can also benefit the defense: One example: Gregory Falco et al. (28 Aug\n2018), “A master attack methodology for an AI-based automated attack planner for\nsmart cities,” IEEE Access 6, https://ieeexplore.ieee.org/document/8449268.\n\n59. A FUTURE OF AI HACKERS\n\n242novel and completely unexpected hacks: Hedge funds and investment firms are\nalready using AI to inform investment decisions. Luke Halpin and Doug\nDannemiller (2019), “Artificial intelligence: The next frontier for investment\nmanagement firms,” Deloitte,\nhttps://www2.deloitte.com/content/dam/Deloitte/global/Documents/Financial-Services/fsi-artificial-intelligence-investment-mgmt.pdf.\nPeter Salvage (March 2019), “Artificial intelligence sweeps hedge funds,” BNY\nMellon,\nhttps://www.bnymellon.com/us/en/insights/all-insights/artificial-intelligence-sweeps-hedge-funds.html.\n\n244the precautionary principle: Maciej Kuziemski (1 May 2018), “A precautionary\napproach to artificial intelligence,” Project Syndicate,\nhttps://www.project-syndicate.org/commentary/precautionary-principle-for-artificial-intelligence-by-maciej-kuziemski-2018-05.\n\n60. GOVERNANCE SYSTEMS FOR HACKING\n\n245AI technologists and industry leaders: Nick Grossman (8 Apr 2015),\n“Regulation, the internet way,” Data-Smart City Solutions, Harvard University,\nhttps://datasmart.ash.harvard.edu/news/article/white-paper-regulation-the-internet-way-660.\n\n246The Collingridge dilemma: Adam Thierer (16 Aug 2018), “The pacing problem,\nthe Collingridge dilemma and technological determinism,” Technology Liberation\nFront,\nhttps://techliberation.com/2018/08/16/the-pacing-problem-the-collingridge-dilemma-technological-determinism.\n\n247its processes and rulings: Stephan Grimmelikhuijsen et al. (Jan 2021), “Can\ndecision transparency increase citizen trust in regulatory agencies? Evidence\nfrom a representative survey experiment,” Regulation and Governance 15, no. 1,\nhttps://onlinelibrary.wiley.com/doi/full/10.1111/rego.12278.\n\n248Gillian Hadfield: Gillian K. Hadfield (2016), Rules for a Flat World: Why\nHumans Invented Law and How to Reinvent It for a Complex Global Economy, Oxford\nUniversity Press.\n\n248Julie Cohen: Julie E. Cohen (2019), Between Truth and Power: The Legal\nConstructions of Informational Capitalism, Oxford University Press.\n\n248Joshua Fairfield: Joshua A. T. Fairfield (2021), Runaway Technology: Can Law\nKeep Up? Cambridge University Press.\n\n248Jamie Susskind: Jamie Susskind (2022), The Digital Republic: On Freedom and\nDemocracy in the 21st Century, Pegasus.\n\nCONCLUDING THOUGHTS\n\n249But there’s a loophole: Josh Zumbrun (25 Apr 2022), “The $67 billion tariff\ndodge that’s undermining U.S. trade policy,” Wall Street Journal,\nhttps://www.wsj.com/articles/the-67-billion-tariff-dodge-thats-undermining-u-s-trade-policy-di-minimis-rule-customs-tourists-11650897161.\n\n250inequality produces surplus resources: Thomas Piketty (2017), Capital in the\nTwenty-First Century, Harvard University Press.\n\n251the fundamental problem with humanity: Tristan Harris (5 Dec 2019), “Our\nbrains are no match for our technology,” New York Times,\nhttps://www.nytimes.com/2019/12/05/opinion/digital-technology-brain.html."}],"media":[{"format":4,"width":540,"height":556,"data":"data:image/jpeg;base64,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"}]}